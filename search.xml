<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Gitlab CE 服务部署及简单使用]]></title>
    <url>%2F2020%2F01%2F07%2Fgitlab-ce-service-setup-and-trial%2F</url>
    <content type="text"><![CDATA[安装Docker123456789sudo docker run --detach \ --hostname gitlab.example.com \ --publish 9443:443 --publish 9080:80 --publish 9022:22 \ --name gitlab \ --restart always \ --volume /opt/gitlab/config:/etc/gitlab \ --volume /opt/gitlab/logs:/var/log/gitlab \ --volume /opt/gitlab/data:/var/opt/gitlab \ gitlab/gitlab-ce:latest DNS Or hosts配置域名解析或在客户端配置主机别名。 主机别名示例： 1172.16.18.143 gitlab.example.com 访问首次登录 浏览器打开: http://gitlab.example.com:9080 重置管理员root密码(e.g. admin123) 登录 启用双重认证（可选）Two-Factor Authentication在个人设置中启用双重认证，手机端使用 FreeOTP 生成认证码。 功能 User Group Repository TLS &amp; SSH Settings…]]></content>
      <categories>
        <category>SCM</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020 书单]]></title>
    <url>%2F2020%2F01%2F01%2Fbooklist-2020%2F</url>
    <content type="text"><![CDATA[「罗伯特议事规则」第 11 版]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>Booklist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[证书常用命令]]></title>
    <url>%2F2019%2F09%2F13%2Ftls-certification-common-commands%2F</url>
    <content type="text"><![CDATA[证书介绍证书生成与格式转换Opensslpfx -&gt; pem12345openssl pkcs12 -clcerts -nokeys -out one123456.pem -in one123456.pfxopenssl pkcs12 -nocerts -out one123456.key.pem -in one123456.pfxopenssl pkcs12 -clcerts -nokeys -out two123456.pem -in two123456.pfxopenssl pkcs12 -nocerts -out two123456.key.pem -in two123456.pfx crt + key -&gt; p1212openssl pkcs12 -export -in dop.crt -inkey dop.key -out dop.p12 -name dop -password pass:abcdefopenssl pkcs12 -export -in wiki.crt -inkey wiki.key -out wiki.p12 -name wiki -password pass:abcdef Keytoolcer -&gt; jks12345keytool -importcert -file CFCA_RSA_TEST_OCA21.cer -keystore cfca.jks -alias cfcakeytool -importcert -file ca.cer -keystore cfca.jks -alias cfcakeytool -import -alias cfcaalias -file cfca.cer -keystore trusted.keystore crt -&gt; jkskeytool -import -alias alias -file ca.crt -keypass keypass -keystore ca.jks -storepass 123456 -noprompt p12 -&gt; jks 1keytool -importkeystore -srckeystore ca.p12 -srcstoretype PKCS12 -destkeystore ca.jks -deststoretype JKS 客户端认证curl123curl -k -v --cert ./tls.crt --key ./tls.key https://qmsauthn.paas.service.sd/logincurl -k -v --cert ./authn.crt --key ./authn.key https://qmsauthn.pditdop:6443/login]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Certification</tag>
        <tag>TLS</tag>
        <tag>SSL</tag>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB Quickstart]]></title>
    <url>%2F2019%2F09%2F01%2Fmongodb-quickstart%2F</url>
    <content type="text"><![CDATA[Install环境：Ubuntu 16.04用户：root官方手册： https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/ 准备1234567wget -qO - https://www.mongodb.org/static/pgp/server-4.0.asc | apt-key add -echo &quot;deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.0 multiverse&quot; | tee /etc/apt/sources.list.d/mongodb-org-4.0.listapt-get install apt-transport-httpsapt-get update 安装安装最新1apt-get install -y mongodb-org 安装指定版本1apt-get install -y mongodb-org=4.0.11 mongodb-org-server=4.0.11 mongodb-org-shell=4.0.11 mongodb-org-mongos=4.0.11 mongodb-org-tools=4.0.11 Usage连接远程连接示例 1mongo --host qloudmongodb.pditdapps:27017 -u &quot;qloudwiki&quot; -p &quot;qloudwiki&quot; --authenticationDatabase &quot;wiki&quot; 数据库 xxx 为数据库名称 数据库列表 show dbs 切换数据库 use xxx 集合 xxx 为集合名称 集合列表 show collections 查询 db.xxx.find() 删除 db.xxx.drop()]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 命令行笔记]]></title>
    <url>%2F2019%2F06%2F03%2Fjava-cmd-notes%2F</url>
    <content type="text"><![CDATA[运行1java -jar XXX.jar 查看文件1jar tf XXX.jar 更新文件1jar uf XXX.jar /path/of/jar/file]]></content>
      <categories>
        <category>Program</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Jar</tag>
        <tag>War</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logstash 笔记]]></title>
    <url>%2F2019%2F05%2F31%2Felk-logstash-notes%2F</url>
    <content type="text"><![CDATA[Input PluginsTcp input plugin logstash:6.5.3 创建配置文件到 /usr/local/logstash/pipeline/tcp.conf 12345678910111213141516171819202122input &#123; tcp &#123; port =&gt; 9600 codec =&gt; json &#125;&#125;filter &#123; json &#123; source =&gt; "message" &#125; mutate &#123; copy =&gt; &#123; "message" =&gt; "messageContent" &#125; &#125; mutate &#123; remove_field =&gt; [ "message"] &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动 Logstash 容器，并挂载 tcp pipeline 配置 1docker run -d --rm -it --name logstash -p 9600:9600 -v /usr/local/logstash/pipeline/:/usr/share/logstash/pipeline/ logstash:6.5.3 Configuring Logstash for Docker 准备测试数据 test.json 1&#123;"message":&#123;"someField":"someValue"&#125;&#125; 发送 1nc localhost 9600 &lt; test.json]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>ELK</tag>
        <tag>Logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019 书单]]></title>
    <url>%2F2019%2F01%2F01%2Fbooklist-2019%2F</url>
    <content type="text"><![CDATA[「追寻历史：一个记者和他的20世纪」 「乔布斯传」 「硅谷钢铁侠」 「奈飞文化手册」 「看见」 「三体」1、2、3]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>Booklist</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 1604 TLS Server 上的 openssh-server]]></title>
    <url>%2F2018%2F03%2F12%2Fopenssh-server-at-ubuntu-1604-tls-server%2F</url>
    <content type="text"><![CDATA[环境： Unbuntu 16.04 TLS Server SSH 简介 Secure Shell（安全外壳协议，简称SSH）是一种加密的网络传输协议，可在不安全的网络中为网络服务提供安全的传输环境。 安装 openssh-server123sudo apt-get install openssh-serversudo /etc/init.d/ssh start 启用 root 用户 SSH 登录 设置 root 密码 1sudo passwd root 启用 root 登录 1vi /etc/ssh/sshd_config 将 PermitRootLogin prohibit-password 修改为 PermitRootLogin yes 。 重启 ssh 服务 1sudo service ssh restart 验证 root 用户 SSH 登录在终端命令行输入以下命令，其中 server-host 为服务器地址。按照提示输入密码，登录成功即可。 1ssh root@server-host 常见错误ssh: connect to host 172.16.18.131 port 22: Connection refused原因是Ubuntu没有默认提供ssh服务，因此首先安装ssh服务： 1sudo apt-get install openssh-server 如果安装完后该服务没有自动启动，则手工启动： 1sudo /etc/init.d/ssh start Write failed Broken pipe 问题解决问题用 ssh 命令连接服务器之后，如果一段时间不操作，再次进入 Terminal 时会有一段时间没有响应，然后就出现错误提示： Write failed: Broken pipe 只能重新用 ssh 命令进行连接。 解决 如果你有多台服务器，不想在每台服务器上设置，只需在客户端的 ~/.ssh/ 文件夹中添加 config 文件，并添加下面的配置： ServerAliveInterval 60 如果你有多个人管理服务器，不想在每个客户端进行设置，只需在服务器的 /etc/ssh/sshd_config 中添加如下的配置： ClientAliveInterval 60 如果您只想让当前的 ssh 保持连接，可以使用以下的命令： $ ssh -o ServerAliveInterval=60 user@sshserver 参考原文]]></content>
      <categories>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 1604 TLS Server 安装 Docker CE]]></title>
    <url>%2F2018%2F03%2F12%2Fdocker-ce-at-ubuntu-1604-tls-server%2F</url>
    <content type="text"><![CDATA[环境： Unbuntu 16.04 TLS Server Docker Docker CE: Docker Community Edition Docker EE: Docker Enterprise Edition 准备sudo apt-get update 可能出现错误： 1234567891011Ign:1 cdrom://Ubuntu-Server 16.04.3 LTS _Xenial Xerus_ - Release amd64 (20170801) xenial InReleaseErr:2 cdrom://Ubuntu-Server 16.04.3 LTS _Xenial Xerus_ - Release amd64 (20170801) xenial Release Please use apt-cdrom to make this CD-ROM recognized by APT. apt-get update cannot be used to add new CD-ROMsHit:3 http://security.ubuntu.com/ubuntu xenial-security InReleaseHit:4 http://us.archive.ubuntu.com/ubuntu xenial InReleaseHit:5 http://us.archive.ubuntu.com/ubuntu xenial-updates InReleaseHit:6 http://us.archive.ubuntu.com/ubuntu xenial-backports InReleaseReading package lists... DoneE: The repository &apos;cdrom://Ubuntu-Server 16.04.3 LTS _Xenial Xerus_ - Release amd64 (20170801) xenial Release&apos; does not have a Release file.N: Updating from such a repository can&apos;t be done securely, and is therefore disabled by default.N: See apt-secure(8) manpage for repository creation and user configuration details. 解决： 1sudo vi /etc/apt/sources.list 注释掉 deb cdrom 打头的部分 deb cdrom:[Ubuntu-Server 16.04.3 LTS Xenial Xerus - Release amd64 (20170801)]/ xenial main restricted 保存后退出再次尝试 sudo apt-get update 安装Install from a package下载 docker-ce-18.06（获取更多版本） 123cd /usr/local/dockerwget https://download.docker.com/linux/ubuntu/dists/artful/pool/stable/amd64/docker-ce_18.06.3~ce~3-0~ubuntu_amd64.deb 安装 1sudo dpkg -i /usr/local/docker/docker-ce_18.06.3~ce~3-0~ubuntu_amd64.deb 验证 1docker version 其他方式 通过 rancher 提供的安装脚本在线安装 curl https://releases.rancher.com/install-docker/17.06.sh | sh 安装完成后，通过以下命令验证安装结果 sudo docker version 或 sudo docker info 卸载卸载Docker CE sudo apt-get purge docker-ce 删除Docker镜像、容器、数据卷等文件 sudo rm -rf /var/lib/docker]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「区块链技术指南」书摘]]></title>
    <url>%2F2018%2F01%2F22%2Fexcerpts-of-blockchain-guide%2F</url>
    <content type="text"><![CDATA[本书适用于对区块链技术感兴趣，且具备一定信息和金融基础知识的读者；无技术背景的读者也可以从中了解到区块链的应用现状。 「区块链技术指南」在线阅读：https://www.gitbook.com/book/yeasy/blockchain_guide/details 以下为书摘（为了保持前后连贯顺畅，部分内容经过简单重组，仍与原文含义保持一致）： 区块链技术的概念与展望无论是货币，还是信用卡模式，都需要额外的系统（例如银行）来完成生产、分发、管理等操作，带来很大的额外成本和使用风险。诸如伪造、信用卡诈骗、盗刷、转账等安全事件屡见不鲜。 很自然的，如果能实现一种数字货币，保持既有货币的这些特性，消除纸质货币的缺陷，无疑将带来巨大的社会变革，极大提高经济活动的运作效率。 比特币是首次从实践意义上实现了一套去中心化的数字货币系统。 最早区块链技术雏形出现在比特币项目中。作为比特币背后的分布式记账平台，在无集中式管理的情况下，比特币网络稳定运行了近八年时间，支持了海量的交易记录，并未出现严重的漏洞。 公认的最早关于区块链的描述性文献是中本聪所撰写的「比特币：一种点对点的电子现金系统」，但该文献重点在于讨论比特币系统，实际上没有明确提出区块链的定义和概念。在其中，区块链被描述为用于记录比特币交易的账目历史。 从记账的角度来看，区块链是首个自带对账功能的数字记账技术实现。 区块链的基本概念包括： 交易（Transaction）：一次操作，导致账本状态的一次改变，如添加一条记录； 区块（Block）：记录一段时间内发生的交易和状态结果，是对当前账本状态的一次共识； 链（Chain）：由一个个区块按照发生顺序串联而成，是整个状态变化的日志记录。 如果把区块链作为一个状态机，则每次交易就是试图改变一次状态，而每次共识生成的区块，就是参与者对于区块中所有交易内容导致状态改变的结果进行确认。 区块链不是数据库。虽然区块链也可以用来存储数据，但它要解决的问题是多方的互信问题。单纯从存储数据角度，它的效率可能不高，笔者也不推荐把大量的原始数据放到区块链上。区块链不是要颠覆现有技术，作为基于多项已有技术而出现的新事物，区块链跟现有技术的关系是一脉相承的。 商业价值现代商业的典型模式为，交易方通过协商和执行合约，完成交易过程。区块链擅长的正是如何管理合约，确保合约的顺利执行。 从技术特点上，区块链一般被认为具有： 分布式容错性：网络极其鲁棒，容错 1/3 左右节点的异常状态。 不可篡改性：一致提交后的数据会一致存在，不可被销毁或修改。 隐私保护性：密码学保证了未经授权者能访问到数据，但无法解析。 随之带来的业务特性将可能包括： 可信任性：区块链技术可以提供天然可信的分布式账本平台，不需要额外第三方中介机构。 降低成本：跟传统技术相比，区块链技术可能带来更短的时间、更少的人力和维护成本。 增强安全：区块链技术将有利于安全可靠的审计管理和账目清算，减少犯罪可能性和各种风险。 区块链并非凭空诞生的新技术，更像是技术演化到一定程度突破应用阈值后的产物，因此，其商业应用场景也跟促生其出现的环境息息相关。基于区块链技术，任何基于数字交易的活动成本和追踪成本都会降低，并且能提高安全性。笔者认为，能否最终带来成本的降低，将是一项技术能否被深入应用的关键。 区块链系统跟传统的分布式系统不同，其处理性能无法通过单纯增加节点数来进行扩展，实际上，很大程度上取决于单个节点的处理能力。高性能、安全、稳定性、硬件辅助加解密能力，都将是考察节点性能的核心要素。 世界上并没有绝对安全的系统。系统是由人设计的，系统也是由人来运营的，只要有人参与的系统，就容易出现漏洞。 最早出现的未必是先驱，也可能是先烈。创新固然很好，但过早播撒的种子，没有合适的土壤，往往也难长大。技术创新与科研创新很不同的一点便是，技术创新必须立足于需求，过早过晚都会错失良机。科研创新则要越早越好，最好像二十世纪那批物理巨匠们一样，让后人吃了一百多年老本。 区块链种类根据参与者的不同，可以分为公开链、联盟链和私有链。 从功能上看，可以分为以货币交易为主的初代区块链（如比特币网络）、支持智能合约的二代区块链（如以太坊网络）、面向复杂商业应用场景支持链上代码的新一代区块链或分布式账本（如超级账本）。 分布式系统核心问题一致性问题如果一个分布式系统无法保证处理结果一致的话，那任何建立于其上的业务系统都无法正常工作。 将可能引发不一致的并行操作进行串行化，就是现在计算机系统里处理分布式一致性问题的基础思路和唯一秘诀。 理想的分布式系统一致性应该满足： 可终止行（Termination）：一致的结果在有限时间内完成； 共识性（Consensus）：不同节点最终完成决策的结果应该相同； 合法性（Validity）：决策的结果必须是其他进程提出的提案。 绝对理想的强一致性代价很大。除非不发生任何故障，所有节点之间的通信无需任何时间，这个时候其实就等价于一台机器了。实际上，超强的一致性要求往往意味着越弱的性能。 强一致性主要包含：顺序一致性、线性一致性。 强一致性的系统往往比较难实现。很多时候，人们发现实际需求并没有那么强，可以适当放宽一致性要求，降低系统实现的难度。例如在一定约束下实现所谓最终一致性，即总会存在一个时刻（而不是立刻），系统达到一致的状态，这对于大部分的 Web 系统来说已经足够了。这一类弱化的一致性，被笼统称为弱一致性。 实际上，要保障系统满足不同程度的一致性，往往需要通过共识算法来达成。 共识算法共识算法解决的是对某个提案，大家达成一致意见的过程。 搞学术的人都喜欢对问题先确定一个界限，那么，这个问题的最坏界限在哪里呢？很不幸，一般情况下，分布式系统的共识问题无解。 当节点间网络不可靠时，很显然，无法确保实现共识。然而，即便在网络通信可靠的情况下，一个可扩展的分布式系统的共识问题的下限是无解。 这个结论，被称为 FLP 不可能性 原理，可以看做分布式领域的“测不准原理”。 FLP不可能性原理 FLP 不可能原理：在网络可靠，存在节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性算法。 FLP 不可能原理实际上告诉人们，不要浪费时间去为异步分布式系统设计在任意场景下都能实现共识的算法。 但，学术界做研究，考虑的是数据和物理意义上极端的情形，很多时候现实生活要美好的多。科学告诉你什么是不可能的；工程则告诉你，付出一些代价，我可以把它变成可能。这就是工程的魅力。 科学上告诉你去赌场赌博从概率上总会是输钱的；工程则告诉你，如果你愿意接受最终输钱的结果，中间说不定偶尔能小赢几笔呢！？ 在付出一定代价的情况下，我们能做到多少？回答这一问题的另一个很出名的原理：CAP 原理。 CAP 原理分布式系统不可能同时确保一致性（Consistency）、可用性（Availability）和分区容忍性（Partition），设计中往往需要弱化对某个特性的保证。 一致性（Consistency）：任何操作应该都是原子的，发生在后面的事件能看到前面事件发生导致的结果（强一致性）； 可用性（Availability）：在有限时间内，任何非失败节点都能应答请求； 分区容忍性（Partition）：网络可能发生分区，即节点之间的通信不可保障。 Paxos 与 RaftPaxos 问题是指分布式的系统中存在故障（fault），但不存在恶意（corrupt）节点场景（即可能消息丢失或重复，但无错误消息）下的共识达成（Consensus）问题。 Paxos 能保证在超过 1/2 的正常节点存在时，系统能达成共识。 Paxos 存在两个阶段：准备（prepare）阶段和提交（commit）阶段。准备阶段解决大家对哪个提案进行投票的问题，提交阶段解决最终值的问题。 Raft 算法是 Paxos 算法的一种简化实现。 拜占庭问题拜占庭问题更为广泛，讨论的是允许存在少数节点作恶（消息可能被伪造）场景下的一致性达成问题。 拜占庭算法讨论的是最坏情况下的保障。 面向拜占庭问题的容错算法，解决的是网络通信可靠，但节点可能故障情况下的一致性达成。 1以函数来表示，将军的总数为 n，n 里面背叛者的数量为 t，则只要 n &gt; 3t 就可以容错。 拜占庭问题之所以难解，在于任何时候系统中都可能存在多个提案（因为提案成本很低），并且要完成最终的一致性确认过程十分困难，容易受干扰。但一旦确认，即为最终确认。 比特币的区块链网络在设计时提出了创新的 PoW（Proof of Work）算法思路。一个是限制一段时间内整个网络中出现提案的个数（增加提案成本），另外一个是放宽对最终一致性确认的需求，约定好大家都确认并沿着已知最长的链进行拓宽。系统的最终确认是概率意义上的存在。这样，即便有人试图恶意破坏，也会付出很大的经济代价（付出超过系统一半的算力）。 后来的各种 PoX 系列算法，也都是沿着这个思路进行改进，采用经济上的惩罚来制约破坏者。 可靠性指标 指标 概率可靠性 每年允许不可用时间 典型场景 1个9 90% 1.2 月 不可用 2个9 99% 3.6 天 普通单点 3个9 99.9% 8.6 小时 普通企业 4个9 99.99% 51.6 分钟 高可用 5个9 99.999% 5 分钟 电信级 6个9 99.9999% 31 秒 极高要求 7个9 99.99999% 3 秒 N/A 8个9 99.999999% 0.3 秒 N/A 9个9 99.9999999% 30 毫秒 N/A 依靠单点实现的可靠性毕竟是有限的，要想进一步的提升，那就只好消灭单点，通过主从、多活等模式让多个节点集体完成原先单点的工作。这可以从概率意义上改善服务的可靠性，也是分布式系统的一个重要用途。 密码学与安全技术Hash 算法Hash（哈希或散列）算法是信息技术领域非常基础也非常重要的技术。它能使任意长度的二进制值（明文）映射为较短的固定长度的二进制值（Hash 值），并且不同的明文很难映射为相同的 Hash 值。 一个优秀的 Hash 算法，将能实现： 正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。 逆向困难：给定（若干）hash 值，在有限时间内很难（基本不可能）逆推出明文。 输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。 冲突避免：很难找到两段内容不同的明文，使得他们的 hash 值一致（发生冲突）。冲突避免有时候又被称为“抗碰撞性”。如果给定一个明文前提下，无法找到碰撞的另一个明文，称为“弱抗碰撞性”；如果无法找到任意两个明文，发生碰撞，则称算法具有“强抗碰撞性”。 一般的，Hash 算法都是算力敏感型，意味着计算资源是瓶颈，主频越高的 CPU 进行 Hash 的速度也越快。也有一些 Hash 算法不是算力敏感的， 例如 scrypt，需要大量的内存资源，节点不能通过简单的增加更多的 CPU 来获得 hash 性能的提升。 数字摘要是 Hash 算法最重要的一个用途。数字摘要是解决确保内容没被篡改过的问题（利用 Hash 函数的抗碰撞性特点）。在网络上下载软件或文件时，往往同时会提供一个数字摘要值，用户下载下来原始文件可以自行进行计算，并同提供的摘要值进行比对，以确保内容没有被修改过。 加解密算法现代加密算法的典型组件包括：加解密算法、加密密钥、解密密钥。其中，加解密算法自身是固定不变的，一般是公开可见的；密钥则往往每次不同，并且需要保护起来，一般来说，对同一种算法，密钥长度越长，则加密强度越大。 加密过程中，通过加密算法和加密密钥，对明文进行加密，获得密文；解密过程中，通过解密算法和解密密钥，对密文进行解密，获得明文。 根据加解密的密钥是否相同，算法可以分为对称加密（symmetric cryptography，又称公共密钥加密，common-key cryptography）和非对称加密（asymmetric cryptography，又称公钥加密，public-key cryptography）。两种模式适用于不同的需求，恰好形成互补，很多时候也可以组合使用，形成混合加密机制。 并非所有加密算法的强度都可以从数学上进行证明。公认的高强度加密算法是在经过长时间各方面实践论证后，被大家所认可，不代表其不存在漏洞。但任何时候，自行发明加密算法都是一种不太明智的行为。 数字签名类似在纸质合同上签名确认合同内容，数字签名用于证实某数字内容的完整性（integrity）和来源（或不可抵赖，non-repudiation）。 HMAC：Hash-based Message Authentication Code，即“基于 Hash 的消息认证码”。 盲签名 多重签名 群签名 环签名 数字证书数字证书用来证明某个公钥是谁的，并且内容是正确的。 对于非对称加密算法和数字签名来说，很重要的一点就是公钥的分发。一旦公钥被人替换（典型的如中间人攻击），则整个安全体系将被破坏掉。怎么确保一个公钥确实是某个人的原始公钥？这就需要数字证书机制。 顾名思义，数字证书就是像一个证书一样，证明信息和合法性。由证书认证机构（Certification Authority，CA）来签发，权威的 CA 包括 Verisign 等。 PKI 体系在非对称加密中，公钥则可以通过证书机制来进行保护，如何管理和分发证书则可以通过 PKI （Public Key Infrastructure）来保障。顾名思义，PKI 体系在现代密码学应用领域处于十分基础的地位，解决了十分核心的证书管理问题。 一般情况下， PKI 至少包含如下组件： CA（Certification Authority）：负责证书的颁发和作废，接收来自 RA 的请求，是最核心的部分； RA（Registration Authority）：对用户身份进行验证，校验数据合法性，负责登记，审核过了就发给 CA； 证书数据库：存放证书，一般采用 LDAP 目录服务，标准格式采用 X.500 系列。 常见的流程为，用户通过 RA 登记申请证书，CA 完成证书的制造，颁发给用户。用户需要撤销证书则向 CA 发出申请。 Merkle 树默克尔树（哈希树）是一种二叉树，由一个根节点、一组中间节点和一组叶子节点组成。最下面的叶节点包含存储数据或其哈希值，每个中间节点是它的两个孩子节点内容的哈希值，根节点也是由它的两个子节点内容的哈希值组成。 默克尔树的特点是，底层数据的任何变动，都会传递到其父亲节点，一直到树根。 同态加密同态加密（Homomorphic Encryption）是一种特殊的加密方法，允许对密文进行处理得到仍然是加密的结果，即对密文直接进行处理，跟对明文进行处理再加密，得到的结果相同。从代数的角度讲，即同态性。 与同态加密相关的一个问题是函数加密。 同态加密保护的是数据本身，而函数加密顾名思义保护的是处理函数本身，即让第三方看不到处理过程的前提下，对数据进行处理。 比特币 - Bitcoin做设计，很多时候都是在权衡（trade-off）。 比特币项目是区块链技术首个大规模的成功应用，并且是首个得到实践检验的数字货币实现，在金融学和信息技术历史上都具有十分重要的意义。 比特币是基于密码学和经济博弈的一种数字货币，也是历史上首个经过大规模长时间运作检验的数字货币系统。 区块如何避免作恶基于经济博弈原理。 在一个开放的网络中，无法通过技术手段保证每个人都是合作的。但可以通过经济博弈来让合作者得到利益，让非合作者遭受损失和风险。 一个典型的例子 两个人来分一个蛋糕，如果都想拿到较大的一块，在没有第三方的前提下，该怎么指定规则才公平？ 最简单的一个方案是负责切蛋糕的人后选。 比特币网络需要所有试图参与者（矿工）都首先要付出挖矿的代价，进行算力消耗，越想拿到新区块的决定权，意味着抵押的算力越多。一旦失败，这些算力都会被没收掉，成为沉默成本。当网络中存在众多参与者时，个体试图拿到新区块决定权要付出的算力成本是巨大的，意味着进行一次作恶付出的代价已经超过可能带来的好处。 负反馈调节比特币网络中矿工越多，系统就越稳定，比特币价值就越高，但挖到矿的概率会降低。反之，网络中矿工减少，会让系统更容易导致被攻击，比特币价值越低，但挖到矿的概率会提高。 因此，比特币的价格理论上应该稳定在一个合适的值（网络稳定性也会稳定在相应的值），这个价格乘以挖到矿的概率，恰好达到矿工的收益预期。 从长远角度看，硬件成本是下降的，但每个区块的比特币奖励每隔 4 年减半，最终将在 2140 年达到 2100 万枚，之后将完全依靠交易的服务费来鼓励矿工对网络的维护。 共识机制目前，Proof of 系列中比较出名的一致性协议包括 PoW 和 PoS，都是通过经济惩罚来限制恶意参与。 PoW 工作量证明， Proof of Work，通过计算来猜测一个数值（nonce），得以解决规定的 hash 问题。保证在一段时间内，系统中只能出现少数合法提案。同时，这些少量的合法提案会在网络中进行广播，收到的用户进行验证后会基于它认为的最长链上继续难题的计算。因此，系统中可能出现链的分叉（Fork），但最终会有一条链成为最长的链。 超市付款需要排成一队，可能有人不守规矩要插队。超市管理员会检查队伍，认为最长的一条队伍是合法的，并让不合法的分叉队伍重新排队。只要大部分人不傻，就会自觉在最长的队伍上排队。 PoS 权益证明，Proof of Stake，类似现实生活中的股东机制，拥有股份越多的人越容易获取记账权。 闪电网络比特币的区块链机制自身提供了很好的可信保障，但是很慢；另一方面考虑，对于大量的小额交易来说，是否真实需要这么高的可信性？闪电网络通过智能合约来完善链下的交易渠道。 核心概念： RSMS（Recoverable Sequence Maturity Contract）：解决链下交易确认的问题。 中文可翻译为“可撤销的顺序成熟度合同”。这个词很绕，其实主要原理很简单，就是类似准备金机制。 HTLC（Hashed Timelock Contract）：解决了支付通道的问题。 中文意思是“哈希的带时钟的合约”。这个其实就是限时转账。通过智能合约，双方约定转账方先冻结一笔钱，并提供一个哈希值，如果在一定时间内有人能提出一个字符串，使得它哈希后的值跟已知值匹配（实际上意味着转账方授权了接收方来提现），则这笔钱转给接收方。 RSMC 保障了两个人之间的直接交易可以在链下完成，HTLC 保障了任意两个人之间的转账都可以通过一条“支付”通道来完成。整合这两种机制，就可以实现任意两个人之间的交易都可以在链下完成了。 在整个交易中，智能合约起到了中介的重要角色，而区块链则确保最终的交易结果被确认。 侧链允许资产在比特币区块链和其它链之间互转。降低核心的区块链上发生交易的次数。 以太坊 - Ethereum君子和而不同。 以太坊项目进一步扩展了区块链网络的能力，从交易延伸为智能合约（ Smart Contract ）。 根据以太坊官方的宣称，以太坊（ Ehtereum ）目标是打造成一个运行智能合约的去中心化平台（ Platform for Smart Contract ），平台上的应用按程序设定运行，不存在停机、审查、欺诈、第三方人为干预的可能。 以太坊平台由 Golang、C++、Python 等多种编程语言实现。 当然，为了打造这个平台，以太坊提供了一条公开的区块链，并制定了面向智能合约的一套编程语言。智能合约开发者可以在其上使用官方提供的工具来开发支持以太坊区块链协议的应用（即所谓的 DAPP ）。 核心概念 EVM：以太坊虚拟机，轻量级虚拟机环境，是以太坊中智能合约的运行环境。 Account：账户，分两类：合约账户存储执行的合约代码；外部账户为以太币拥有者账户，对应到某公钥。 Transaction：交易，从一个账户到另一个账户的消息，包括以太币或者合约执行参数。 Gas：燃料，每执行一条合约指令会消耗一定的燃料，当某个交易还未执行结束，而燃料消耗完时，合约执行终止并回滚状态。 一致性目前采用了 PoW 作为一致达成保证，未来可能迁移到 PoS 上。 降低攻击设计核心思想是通过经济激励机制防止少数人作恶： 所有交易都要提供交易费用，避免 DDoS 攻击； 程序运行指令数通过 gas 来限制，所消耗的费用超过设定上限时会被取消，避免恶意合约。 提高扩展性以太坊未来希望通过分片机制可以提高整个网络的扩展性。 分片之前整个网络的处理取决于单个节点的处理。分片后，只有同一片内的处理是同步的、一致的，不同分片之间则可以是异步的。 超级账本 - HyperledgerHyperledger 项目是首个面向企业的开放区块链技术的重要探索。在 Linux 基金会的支持下，吸引了包括 IBM、Intel、摩根等在内的众多科技和金融巨头的参与。 该项目的出现，实际上宣布区块链技术已经不再是仅面向“社会实践”性质的应用场景，它已经正式被主流机构和企业市场认可；同时，Hyperledger 首次提出和实现的完备权限管理、创新的一致性算法和可插拔、可扩展的框架，对于区块链相关技术和产业的发展都将产生深远的影响。 区块链即服务懒惰和好奇，是创新与进步的源泉。 云的出现，让传统信息行业变得前所未有的便捷。只要云中有的服务，通过简单的几下点击，就可以获得一个运行中的服务实例，节约了大量的研发和运维的时间和成本。 现有的区块链分为三种：私有链、联盟链和公有链。私有链存在于机构内部，必要性较低，且在性能上弱于现有的分布式系统。联盟链建立在多个联盟机构之间，每个联盟成员之间各自拥有一个核心节点。公有链向社会开放，可以用于信息认证、公共资源共享。任何团体或个人可以加入公有链。 目前，业界已经开始有少数区块链前沿技术团队开发了区块链即服务（ Blockchain as a Service，BaaS ）的平台。根据上述划分，BaaS 平台可以面向用户群体提供联盟链及公开链两种服务，并根据不同的服务类型进行不同的结构设计及优化。 （完）]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>BlockChain</tag>
        <tag>Fintech</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「数学之美」书摘]]></title>
    <url>%2F2017%2F11%2F22%2Fexcerpts-of-the-beauty-of-mathematics%2F</url>
    <content type="text"><![CDATA[本文主要摘自「数学之美」（第二版）的关键内容，摘取内容与原书相比肯定不够全面。如果对此书内容感兴趣，强烈建议阅读原书。 以下为摘取内容（为了辅助说明，部分内容同时引用了相关网络资源，均有出处链接）： 文字和语言与数学，从产生起原本就有相通性，虽然它们的发展一度分道扬镳，但是最终还是能走在一起。 人类对机器理解自然语言的认识走了一条大弯路。早起的研究中采用基于规则的方法，虽然解决了一些简单的问题，但是无法从根本上将自然语言理解实用化。直到多年以后，人们开始尝试基于统计的方法进行自然语言处理，才有了突破性进展和实用的产品。 统计语言模型是自然语言处理的基础，并且被广泛应用于机器翻译、语音识别、印刷体或手写体识别、拼写纠错、汉字输入和文献查询。 中文分词是中文信息处理的基础，它同样走过了一段弯路，目前依靠统计语言模型已经基本解决了这个问题。 隐含马尔可夫模型最初应用于通信领域，继而推广到语音和语言处理中，成为连接自然语言处理和通信的桥梁。同时，隐含马尔可夫模型也是机器学习的主要工具之一。 WIKI：隐马尔可夫模型 隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。 在正常的马尔可夫模型中，状态对于观察者来说是直接可见的。这样状态的转换概率便是全部的参数。而在隐马尔可夫模型中，状态并不是直接可见的，但受状态影响的某些变量则是可见的。每一个状态在可能输出的符号上都有一概率分布。因此输出符号的序列能够透露出状态序列的一些信息。 信息是可以量化度量的。信息熵不仅是对信息的量化度量，也是整个信息论的基础。它对于通信、数据压缩、自然语言处理都有很强的指导意义。 作为现代自然语言处理的奠基者，贾里尼克教授成功地将数学原理应用于自然语言处理领域中，他的一生富于传奇色彩。 布尔代数虽然非常简单，却是计算机科学的基础，它不仅把逻辑和数学合二为一，而且给了我们一个全新的视角看待世界，开创了数字化时代。 互联网搜索引擎在建立索引前需要用一个程序自动地将所有的网页下载到服务器上，这个程序称为网络爬虫。它的编写是基于离散数学中图论的原理。 图论：图由一些节点和连接这些节点的弧组成。网络爬虫基于图论进行网页下载。 BFS (Breadth-First Search)，广度优先搜索。 DFS (Depth-First Search)：深度优先搜索。 PageRank：网页民主排名。 核心思想为：如果一个网页被很多网页所链接，说明它受到普遍的承认和信赖，那么它的排名就高。 TF-IDF：网页与查询相关性度量。 TF：Term Frequency，词频。 IDF：Inverse Document Frequency，逆文本频率指数。信息检索中使用最多的权重。 阮一峰的网络日志『TF-IDF与余弦相似性的应用（一）：自动提取关键词』 第一步，计算词频。 考虑到文章有长短之分，为了便于不同文章的比较，进行“词频”标准化。 词频（TF）= 某个词在文章中的出现次数 / 文章总词数 第二步，计算逆文档频率。 这时，需要一个语料库（corpus），用来模拟语言的使用环境。 逆文档频率（IDF）= log(语料库的文档总数 / 包含该词的文档数 + 1) 如果一个词越常见，那么分母就越大，逆文档频率就越小越接近 0 。分母之所以要加 1，是为了避免分母为 0（即所有文档都不包含该词）。log表示对得到的值取对数。 第三步，计算 TF-IDF。 TF-IDF = 词频(TF) * 逆文档频率(IDF) 可以看到，TF-IDF 与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。 地图和本地服务中要用到有限状态机和动态规划技术。这两项技术是机器智能和机器学习的工具，它们的应用非常广泛，还包括语音识别、拼写和语法纠错、拼音输入法、工业控制和生物的序列分析等。 「地址」是种有限状态机，导航的关键算法是图论中的动态规划。 WIKI：有限状态机 有限状态机（Finite-State Machine，FSM）又称有限状态自动机，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。 在计算机科学中，有限状态机被广泛用于建模应用行为、硬件电路系统设计、软件工程、编译器、网络协议和计算与语言的研究。 WIKI：动态规划 动态规划在查找有很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并被保存，从简单的问题直到整个问题都被解决。因此，动态规划保存递归时的结果，因而不会在解决同样的问题时花费时间。 动态规划只能应用于有最优子结构的问题。最优子结构的意思是局部最优解能决定全局最优解（对有些问题这个要求并不能完全满足，故有时需要引入一定的近似）。简单地说，问题能够分解成子问题来解决。 辛格做事的哲学：先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 问题，是在工业界成功的秘诀之一。 计算机虽然读不懂新闻，却可以准确地对新闻进行分类。其数学工具是看似毫不相干的余弦定理。 阮一峰的网络日志『TF-IDF与余弦相似性的应用（二）：找出相似文章』 因此，我们可以通过夹角的大小，来判断向量的相似程度。夹角越小，就代表越相似。 余弦值越接近 1，就表明夹角越接近 0 度，也就是两个向量越相似，这就叫“余弦相似性”。 使用 TF-IDF 算法，找出两篇文章的关键字； 每篇文章各取出若干个关键词（比如 20 个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）； 生成两篇文章各自的词频向量； 计算两个向量的余弦相似度，值越大就表示越相似。 “余弦相似性”是一种非常有用的算法，只要是计算两个向量的相似程度，都可以采用它。 无论是词汇的聚类还是文本的分类，都可以通过线性代数中矩阵的奇异值分解来进行。这样一来，自然语言处理的问题就变成了一个数学问题。 世间万物都有一个唯一标识的特征，信息也是如此。每一条信息都有它特定的指纹，通过这个指纹可以区别不同的信息。 密码学的根本是信息论和数学。没有信息论指导的密码是非常容易被破解的。只有在信息论被广泛应用于密码学后，密码才真正变得安全。 搜索引擎中排名靠前的网页也未必是有用的网页。消除这些作弊网页的原理和通信中过滤噪音的原理相同。 正确的数学模型在科学和工程中至关重要，而发现正确模型的途径常常是曲折的。正确的模型在形式上通常是简单的。 最大熵模型是一个完美的数学模型。它可以将各种信息整合到一个统一的模型中，在信息处理和机器学习中有着广泛的应用。它在形式上非常简单、优美，而在实现时需要有精深的数学基础和高超的技巧。 汉字的输入过程本身就是人和计算机之间的通信。好的输入法会自觉或不自觉地遵循通信的数学模型。当然要做出最有效的输入法，应当自觉使用信息论做指导。 将自然语言处理从基于规则的研究方法转到基于统计的研究方法上，宾夕法尼亚大学的教授米奇·马库斯功不可没。他创立了今天在学术界广泛使用的 LCD 语料库，同时培养了一大批精英人物。 判断一个元素是否在一个集合中，布隆过滤器是计算机工程中解决这个问题最好的数学工具。 贝叶斯网络是一个加权的有向图，是马尔可夫链的扩展。而从认识论的层面看：贝叶斯网络克服了马尔可夫链那种机械的线性约束，它可以把任何有关联的事件统一到它的框架下面。它在生物统计、图像处理、决策支持系统和博弈论中都有广泛的使用。 条件随机场是计算联合概率分布的有效模型，而句法分析似乎是英文课上英语老师教的东西，这两者有什么联系呢？ 维特比算法是现代数字通信中使用最频繁的算法，同时也是很多自然语言处理的解码算法。可以毫不夸张地讲，维特比是对我们今天生活的影响力最大的科学家之一。因为如今基于 CDMA 的 3G 移动通信标准主要就是他创办的高通公司制定的。 只要有一些训练数据，再定义一个最大化函数，采用 EM 算法，利用计算机经过若干次迭代，就可以得到所需要的模型。这实在是太美妙了，这也许是我们的造物主刻意安排的。所以我把它称作上帝的算法。 逻辑回归模型是一种将影响概率的不同因素结合在一起的指数模型，它不仅在搜索广告中起着重要的作用，而且被广泛应用于信息处理和生物统计中。 Google 颇为神秘的云计算中最重要的 MapReduce 工具，其原理就是计算机算法中常用的“各个击破”算法，它的原理原来这么简单——将复杂的大问题分解成很多小问题分别求解，然后再把小问题的解合并成原始问题的解。由此可见，在生活中大量用到的、真正有用的方法常常都是简单朴实的。 Google 大脑并不是一个什么都能思考的大脑，而是一个很能计算的人工神经网络。因此，与其说 Google 大脑很聪明，不如说它很能算。不过，换个角度来说，随着计算能力的不断提高，计算量大但简单的数学方法有时能够解决很复杂的问题。 如果说在过去的 40 年里，主导全球 IT 产业发展的是摩尔定律，那么在今后的 20 年里，主导 IT 行业继续发展的动力则将来自于数据。]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 10 Install MySQL Community Server]]></title>
    <url>%2F2017%2F11%2F21%2Fwindows-10-install-mysql-community-server%2F</url>
    <content type="text"><![CDATA[下载下载页面：https://dev.mysql.com/downloads/mysql/ 本文使用的版本下载链接： https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.20-winx64.zip 安装 将下载的zip文件解压到指定的路径，如：D:\Softwares\mysql-5.7.20-winx64，以下以 [MYSQL_DIR] 代替。 1cd [MYSQL_DIR]/bin 初始化 1&gt; mysqld --initialize --user mysql --console 执行成功后会生成一个临时密码： A temporary password is generated for root@localhost: WjdKaOdBt5+0 安装 1&gt; mysqld -install Service successfully installed. 启动服务 1&gt; net start mysql MySQL 服务正在启动. MySQL 服务已经启动成功. 验证 登录 1&gt; mysql -u root -p Enter password：输入上面生成的临时密码 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 3Server version: 5.7.20 修改密码 1mysql&gt; alter user root@localhost identified by &quot;root&quot;; Query OK, 0 rows affected (0.00 sec) （完）]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rocketmq Practice - Core Concept]]></title>
    <url>%2F2017%2F11%2F10%2Frocketmq-practice-core-concept%2F</url>
    <content type="text"><![CDATA[本文是对官方原文的理解翻译，利于自己更好的理解 RocketMQ。 Producer（生产者）Producer 将业务应用系统生成的消息发送到 Broker。RocketMQ 提供多种发送模式：同步、异步和单向。 Producer Group（生产者组）相同角色的 Producer 会组织在一起。当原有的 Producer 在交易之后崩溃时，Broker 会协调同一组内不同的 Producer 完成相应事务的提交或回退。 注意：每个 Producer 组只会允许一个实例，以避免不必要的实例初始化。 Consumer（消费者）Consumer 从 Broker 拉取消息并将其提供给应用程序。从应用的角度来看，有两种类型的 Consumer： PullConsumer（拉取消费者）PullConsumer 从 Broker 拉取消息。当消息被拉取后，应用程序启动相应的消费处理程序。 PushConsumer（推送消费者）PushConsumer 封装了消息拉取、消耗进度及其他维护工作，提供一个回调接口用于在消息最终到达时实现业务逻辑处理。 Consumer Group（消费者组）类似上面提到的 Producer Group，相同角色的 Consumer 会组织在一起并命名为 Consumer Group。 Consumer Group 是一个很好的概念，在消息消费方面实现负载均衡和容错目标是非常容易的。 注意：Consumer Group 中的Consumer 实例必须有完全相同的主题订阅。 Topic（主题）Topic 是一个类别，用于 Producer 传递消息和 Consumer 拉取消息。Topic 与 Producer 和 Consumer 之间的关系是松散的。 具体来说，一个 Topic 可以由零个、一个或多个 Producer 向它发送消息；相反地，一个 Producer 能够发送消息到不同的 Topic。 从 Consumer 的角度来看，一个 Topic 可以由零个、一个或多个 Consumer Group 订阅。同样， 一个 Consumer Group 可以订阅一个或多个 Topic，只要这个组内保持订阅的一致。 Message（消息）Message 是要传递的信息。一个消息必须有一个主题，就像信件的邮件地址一样。 一个消息可能包含可选的标签和额外的键值对。例如，你可能给消息设置一个业务密钥，能够在 Broker 上查找消息，在开发时期进行问题诊断。 Message Queue（消息队列）Topic 被分为一个或多个子主题，称为“消息队列”。 Tag（标签）Tag ，为用户提供额外的灵活性。使用 Tag ，来自相同的业务模块具有不同目的的消息，可能具体相同的主题和不同的标签。Tags 能够有助于保持代码的整洁与连贯，并且 Tags 也可以方便 RoketMQ 提供的查询系统。 Broker（中间件）Broker 是 RocketMQ 系统的主要组件。它接收来自 Producers 的消息、存储他们并准备处理来自 Consumers 的请求。同时它还存储消息相关的元数据，包含 Consumer Groups，消费进度偏移和主题/队列信息。 Name Server（命名服务）Name Server 提供路由信息。Producer 和 Consumer 客户端查找主题以获取相应的 Broker 列表。 Message Model（消息模型） Clustering（集群） Broadcasting（广播） Message Order（消息顺序）当使用 DefaultMQPushConsumer 时，你可以决定是有序的或并发的。 有序的 有序的消费消息意味着 Consumer 按照 Producer 发送的消息顺序进行消费。如果处理需要强制使用全局顺序的情况，请确保使用的主题只有一个消息队列。 如果指定有序消费，则消费消息的最大并发数是订阅消息的消费者组数量。 并发的 当消费消息是并发的，消费消息的最大并发数受限于为每个消费者指定的线程池。 在这种模式下，不再保证消息的顺序。 官方原文：https://rocketmq.apache.org/docs/core-concept/]]></content>
      <categories>
        <category>Messaging</category>
      </categories>
      <tags>
        <tag>Messaging</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ Practice - Quickstart]]></title>
    <url>%2F2017%2F11%2F09%2Frocketmq-practice-quickstart%2F</url>
    <content type="text"><![CDATA[本文实践环境说明：Windows 10 专业版，JDK 1.8.0_65。 下载http://rocketmq.apache.org/dowloading/releases/ 解压 rocketmq-all-4.1.0-incubating-bin-release.zip 到 &lt;rocketmq-installed-dir&gt; 启动服务启动 NameServer 1%ROCKETMQ_HOME%/bin/mqnamesrv -n 127.0.0.1:9876 &gt;E:\logs\mqnamesrv.log The Name Server boot success. serializeType=JSON 启动 Broker 1%ROCKETMQ_HOME%/bin/mqbroker -n 127.0.0.1:9876 &gt;E:\mqbroker.log 运行客户端配置环境变量： NAMESRV_ADDR -&gt; 127.0.0.1:9876 发送消息 1%ROCKETMQ_HOME%/bin/tools org.apache.rocketmq.example.quickstart.Producer SendResult [sendStatus=SEND_OK, msgId=0A00BF859C787EA987AC2DCBCA8A0354, offsetMsgId=0A00BF8500002A9F00000000000256A2, messageQueue=MessageQueue [topic=TopicTest, brokerName=Dawn, queueId=0], queueOffset=213]SendResult [sendStatus=SEND_OK, msgId=0A00BF859C787EA987AC2DCBCA8C0355, offsetMsgId=0A00BF8500002A9F0000000000025756, messageQueue=MessageQueue [topic=TopicTest, brokerName=Dawn, queueId=1], queueOffset=213]SendResult [sendStatus=SEND_OK, …… 接收消息 1%ROCKETMQ_HOME%/bin/tools org.apache.rocketmq.example.quickstart.Consumer ConsumeMessageThread_2 Receive New Messages: [MessageExt [queueId=1, storeSize=180, queueOffset=249, sysFlag=0, bornTimestamp=1510233930866, bornHost=/10.0.191.133:10130, storeTimestamp=1510233930867, storeHost=/10.0.191.133:10911, msgId=0A00BF8500002A9F000000000002BC96, commitLogOffset=179350, bodyCRC=1102156316, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties={MIN_OFFSET=0, MAX_OFFSET=250, CONSUME_START_TIME=1510233997434, UNIQ_KEY=0A00BF859C787EA987AC2DCBCC7203E5, WAIT=true, TAGS=TagA}, body=18]]]ConsumeMessageThread_1 Receive New Messages: [MessageExt [queueId=1, storeSize=180, queueOffset=248, sysFlag=0, bornTimestamp=1510233930852, bornHost=/10.0.191.133:10130, storeTimestamp=1510233930854, storeHost=/10.0.191.133:10911, … 停止服务停止 Broker 1%ROCKETMQ_HOME%/bin/mqshutdown broker killing broker成功: 已终止 PID 为 42376 的进程。Done! 停止 NameServer 1%ROCKETMQ_HOME%/bin/mqshutdown namesrv killing name server成功: 已终止 PID 为 39464 的进程。Done! 官方快速起步：https://rocketmq.apache.org/docs/quick-start/]]></content>
      <categories>
        <category>Messaging</category>
      </categories>
      <tags>
        <tag>Messaging</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ Practice - Architecture Learn]]></title>
    <url>%2F2017%2F11%2F09%2Frocketmq-practice-architecture-learn%2F</url>
    <content type="text"><![CDATA[Apache RocketMQ 是一个分布式消息及流处理平台，具有低延迟、高性能和可靠性，以及万亿级容量和灵活的扩展性。 体系架构 RocketMQ 主要包含 4 部分，它们中的每一部分都可以在非单点失败的情况下进行水平扩展。 NameServers Brokers Producers Consumers NameServer Cluster（命名服务集群）NameServers 提供发现和路由的轻量级服务。集群中每个 NameServer 记录完整的路由信息，提供相应的读写服务，支持快速存储扩展。 NameServer（命名服务）NameServer 是一个功能齐全的服务，主要包含以下 2 个特性： Broker 管理 NameServer 接受来自 Broker 集群的注册，并提供监测 Broker 是否存活的心跳机制。 路由管理 每个 NameServer 保存 Broker集群的整个路由信息以及客户端查询的队列信息。 正如我们所知，RocketMQ 客户端（Producer &amp; Consumer）通过 NameServer 获取队列路由信息，但客户端是如何知道 NameServer 地址的呢？获取 NameServer 地址列表的 4 种方式： 编写程序 producer.setNamesrvAddr(&quot;ip:port&quot;) Java 选项 rocketmq.namesrv.addr 环境变量 NAMESRV_ADDR HTTP 端点 Broker Cluster（代理集群）Brokers 通过轻量级的 TOPIC 和 QUEUE 机制满足消息存储。他们支持 Push 和 Pull 两种模式，包含容错机制（拷贝2-3份），并提供了强大的填补高峰和积累数以百亿计的消息在其原来的时间顺序的能力(这句没看懂) 。此外，Brokers 也提供灾难恢复，丰富的指标统计和预警机制。 Broker Server（代理服务）Broker Server 负责消息的存储、交付、消息查询与 HA 保证等。 Broker Server 重要的子模块： 远程模块 - Broker 入口，处理来自客户端的请求。 客户端管理 - 管理客户端（Producer &amp; Consumer）和维护消费者的主题订阅。 存储服务 - 提供简单的API来存储或查询物理磁盘中的消息。 HA 服务 - 提供主从 Broker 间的数据同步功能。 索引服务 - 按指定的键为消息建立索引，并提供快速的消息查询。 Producer Cluster（生产者集群）Producers 支持分布式部署。分布式 Producers 通过负载均衡模型向 Brokers 集群发送消息，发送过程支持快速失败及低延迟。 Consumer Cluster（消费者集群）Consumers 在 Push 和 Pull 两种模式下支持分布式部署。它也支持集群消费和消息广播。它提供实时的消息订阅机制，可以满足大多数消费者的需求。 更多信息请参考官方：https://rocketmq.apache.org/]]></content>
      <categories>
        <category>Messaging</category>
      </categories>
      <tags>
        <tag>Messaging</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Create My Hexo Blog]]></title>
    <url>%2F2017%2F11%2F09%2Fcreate-my-hexo-blog%2F</url>
    <content type="text"><![CDATA[本文记录了创建自己的 Hexo 博客过程。 环境准备Node.js：https://nodejs.org/zh-cn/ Git：https://git-scm.com/ Hexo如果需要搭建自己的博客（网站），强烈推荐查看官网教程。Hexo：http://hexo.io/ 安装1npm install -g hexo-cli 通过 hexo --version 验证 Hexo 是否安装成功。 初始化123hexo init &lt;dir&gt;cd &lt;dir&gt;npm install 执行成功后，即站点完成初始化工作。 启动服务1hexo server 启动成功后，访问：http://localhost:4000/ NexT自己的博客选择了 NexT 主题，详细说明请查看官网教程。NexT：http://theme-next.iissnan.com/ 安装12cd my-hexo-sitegit clone https://github.com/iissnan/hexo-theme-next themes/next 启用修改文件 my-hexo-site/_config.yml 的 theme 属性值为 next ，重启服务。 切换 SchemeNexT 支持多种外观风格，默认使用 Muse，如上图。 修改文件 my-hexo-site/themes/next/_config.yml 的scheme属性值为 Pisces 来切换风格。 123#scheme: Muse#scheme: Mistscheme: Pisces NexT 还有更丰富的配置及第三方扩展，具体请查看官网。 感谢感谢 Hexo ，感谢 NexT，感谢 OpenSource，让我们能够方便的定制自己的站点。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ Practice Getting Started]]></title>
    <url>%2F2017%2F11%2F08%2Factivemq-practice-getting-started%2F</url>
    <content type="text"><![CDATA[本文只是记录 ActiveMQ 服务的基本部署和消息的简单测试应用。 体系架构 核心概念 消息流 消息生产者（Producer） –&gt; 中间件（Broker） –&gt; 消息消费者（Consumer） 两种模型 Point to Point（点对点） Publish/Subscribe（发布/订阅） 服务部署参考：http://activemq.apache.org/getting-started.html 本文实践环境说明：Windows 10 专业版，JDK 1.8.0_65。 1. 下载http://activemq.apache.org/download.html (目前最新版本5.15.2) 2. 安装 &amp; 启动服务解压 apache-activemq-5.15.2-bin.zip 到 &lt;ActiveMQ_installed_dir&gt; 1%ACTIVEMQ_HOME%\bin\activemq start 3. Web控制台URL：http://127.0.0.1:8161/admin/Login：adminPassword：admin 通过 conf/jetty-real.properties 配置用户名密码 4. 日志文件1%ACTIVEMQ_HOME%/data/activemq.log 5. 停止服务1%ACTIVEMQ_HOME%/bin/activemq stop 示例先决条件：消息服务（中间件）已启动。 1. 启动消息消费者1%ACTIVEMQ_HOME%/bin/activemq consumer 2. 启动消息生产者 自定义文本 1%ACTIVEMQ_HOME%/bin/activemq producer --message &quot;My message&quot; --messageCount 1 定长字节消息 1%ACTIVEMQ_HOME%/bin/activemq producer --messageSize 100 --messageCount 1 更多信息 http://activemq.apache.org/version-5-examples.html 总结本文对 ActiveMQ 进行了基础入门实践练习，以便更好的认识 ActiveMQ。 更多信息请查看官网：http://activemq.apache.org/ (END)]]></content>
      <categories>
        <category>Messaging</category>
      </categories>
      <tags>
        <tag>Messaging</tag>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Practice - Getting Started]]></title>
    <url>%2F2017%2F10%2F23%2Fgit-practice-getting-started%2F</url>
    <content type="text"><![CDATA[Start a working areainit 在当前目录[指定目录]初始化工作空间1git init [&lt;dir&gt;] clone 将指定工作空间拷贝到当前目录[指定目录]1git clone &lt;repo&gt; [&lt;dir&gt;] Work on the current changeadd 将文件添加到中转区（路径/文件名） 1git add octocat.txt 将文件添加到中转区（文件通配符，匹配到的文件都将会添加到中转区） 1git add &apos;*.txt&apos; reset 将HEAD重置到某一个状态（路径/文件名，若不指定则对所有提交生效）1git reset octofamily/octodog.txt rm 删除指定文件（文件名/文件通配符）1git rm &apos;*.txt&apos; Examine the history and statestatus 查看当前仓库状态1git status log 查看仓库变更日志1git log Grow, mark and tweak your common historycommit 将中转区的变更提交到仓库（说明内容）1git commit -m &quot;Add cute octocat story&quot; checkout 切换分支（–路径/文件名） 1git checkout --octocat.txt 切换分支（&lt;分支名称&gt;） 1git checkout &lt;BranchName&gt; branch 创建分支（&lt;分支名称&gt;） 1git branch &lt;BranchName&gt; 删除分支（&lt;分支名称&gt;） 1git branch -d &lt;BranchName&gt; diff 查看更改差异：查看上次提交的不同之处 1git diff 查看更改差异：HEAD为最新提交指针代码 1git diff HEAD 查看更改差异：查看中转区的更改差异 1git diff --staged merge 合并其他分支到当前分支（&lt;其他分支名称&gt;）1git merge &lt;BranchName&gt; Collaboratepush 将本地分支推送到远程仓库（&lt;远程仓库名称&gt; &lt;本地分支名称&gt;）1git push -u &lt;origin&gt; &lt;master&gt; -u告诉Git记住参数，这样下次我们可以简单地运行git push pull 拉取远程仓库变更到本地分支（&lt;远程仓库名称&gt; &lt;本地分支名称&gt;）1git pull &lt;origin&gt; &lt;master&gt; remoteremote add 添加远程仓库（&lt;远程仓库名称&gt; &lt;远程仓库地址&gt;）1git remote add &lt;origin&gt; &lt;https://github.com/try-git/try_git.git&gt;]]></content>
      <categories>
        <category>VCS</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DB2 SQL Script Memo]]></title>
    <url>%2F2017%2F08%2F31%2Fdb2-sql-script%2F</url>
    <content type="text"><![CDATA[视图筛选包含某表的视图列表123SELECT t.viewschema, t.viewname FROM syscat.viewdep t WHERE t.bname = UPPER (&apos;#table&apos;) AND t.viewschema = &apos;#schema&apos;; 列筛选系统字段表12345678 SELECT * FROM syscat.columns c WHERE EXISTS (SELECT 1 FROM syscat.tables t WHERE owner = &apos;#schema&apos; AND t.TABNAME = c.TABNAME) AND UPPER (c.COLNAME) LIKE &apos;%#column%&apos;ORDER BY c.TABNAME;]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>DB2</tag>
      </tags>
  </entry>
</search>
