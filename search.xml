<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ActiveMQ Notes</title>
    <url>/2020/12/25/activemq-notes/</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Docker-run"><a href="#Docker-run" class="headerlink" title="Docker run"></a>Docker run</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --name activemq -p 61616:61616 -p 61613:61613 -p 61614:61614 -p 5672:5672 -p 1883:1883 -p 8161:8161 rmohr&#x2F;activemq:5.15.9</span><br></pre></td></tr></table></figure>
<p>环境变量</p>
<ul>
<li>ACTIVEMQ_TCP=61616</li>
<li>ACTIVEMQ_AMQP=5672</li>
<li>ACTIVEMQ_STOMP=61613</li>
<li>ACTIVEMQ_MQTT=1883</li>
<li>ACTIVEMQ_WS=61614</li>
<li>ACTIVEMQ_UI=8161</li>
</ul>
<h3 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http:&#x2F;&#x2F;localhost:8161&#x2F;admin</span><br></pre></td></tr></table></figure>
<p>用户/密码: <code>admin</code>/<code>admin</code></p>
<h2 id="Protocols"><a href="#Protocols" class="headerlink" title="Protocols"></a>Protocols</h2><h3 id="MQTT-消息队列遥测传输"><a href="#MQTT-消息队列遥测传输" class="headerlink" title="MQTT 消息队列遥测传输"></a>MQTT 消息队列遥测传输</h3><blockquote>
<p>Message Queuing Telemetry Transport</p>
</blockquote>
<h4 id="MQTT-Publish-Subscribe-Architecture"><a href="#MQTT-Publish-Subscribe-Architecture" class="headerlink" title="MQTT Publish / Subscribe Architecture"></a>MQTT Publish / Subscribe Architecture</h4><p><img src="/images/mqtt/mqtt-publish-subscribe.png" alt="mqtt-publish-subscribe"></p>
<h4 id="MQTT-Specification"><a href="#MQTT-Specification" class="headerlink" title="MQTT Specification"></a>MQTT Specification</h4><ul>
<li><a href="https://mqtt.org/mqtt-specification/">https://mqtt.org/mqtt-specification/</a></li>
<li><a href="http://mqtt.p2hp.com/">http://mqtt.p2hp.com/</a></li>
</ul>
<h4 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h4><ul>
<li>Eclipse Paho</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; eclipse paho</span><br><span class="line">https:&#x2F;&#x2F;www.eclipse.org&#x2F;paho&#x2F;index.php?page&#x3D;clients&#x2F;java&#x2F;index.php#</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; github</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;eclipse&#x2F;paho.mqtt.java</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; javadoc</span><br><span class="line">https:&#x2F;&#x2F;www.eclipse.org&#x2F;paho&#x2F;files&#x2F;javadoc&#x2F;index.html</span><br></pre></td></tr></table></figure>
<h3 id="JMS-Java消息服务"><a href="#JMS-Java消息服务" class="headerlink" title="JMS  Java消息服务"></a>JMS  Java消息服务</h3><blockquote>
<p>Java Message Service</p>
</blockquote>
<h4 id="JMS-Specification"><a href="#JMS-Specification" class="headerlink" title="JMS Specification"></a>JMS Specification</h4><p><a href="https://www.oracle.com/java/technologies/java-message-service.html">https://www.oracle.com/java/technologies/java-message-service.html</a></p>
<h3 id="AMQP-高级消息队列协议"><a href="#AMQP-高级消息队列协议" class="headerlink" title="AMQP 高级消息队列协议"></a>AMQP 高级消息队列协议</h3><blockquote>
<p>Advanced Message Queuing Protocol</p>
</blockquote>
<h4 id="AMQP-Specification"><a href="#AMQP-Specification" class="headerlink" title="AMQP Specification"></a>AMQP Specification</h4><p><a href="https://www.amqp.org/">https://www.amqp.org/</a></p>
<p><a href="https://activemq.apache.org/amqp">https://activemq.apache.org/amqp</a></p>
<h3 id="STOMP-简单-或流-面向文本的消息传递协议"><a href="#STOMP-简单-或流-面向文本的消息传递协议" class="headerlink" title="STOMP 简单(或流)面向文本的消息传递协议"></a>STOMP 简单(或流)面向文本的消息传递协议</h3><blockquote>
<p>STOMP is the Simple (or Streaming) Text Orientated Messaging Protocol.</p>
</blockquote>
<h4 id="Stomp-Specification"><a href="#Stomp-Specification" class="headerlink" title="Stomp Specification"></a>Stomp Specification</h4><ul>
<li><a href="http://stomp.github.io/stomp-specification-1.2.html">http://stomp.github.io/stomp-specification-1.2.html</a></li>
</ul>
<h4 id="客户端-1"><a href="#客户端-1" class="headerlink" title="客户端"></a>客户端</h4><p>ActiveMQ Library: </p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.activemq<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>activemq-all<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Package: </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.activemq.transport.stomp.StompConnection;</span><br><span class="line"><span class="keyword">import</span> org.apache.activemq.transport.stomp.StompFrame;</span><br></pre></td></tr></table></figure>


<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><blockquote>
<p>Java Client Demo</p>
</blockquote>
<p><a href="https://github.com/shankai/artifacts/tree/master/activemq-example">https://github.com/shankai/artifacts/tree/master/activemq-example</a></p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>MQTT</tag>
        <tag>AMQP</tag>
        <tag>STOMP</tag>
        <tag>TCP</tag>
        <tag>Message Queue</tag>
      </tags>
  </entry>
  <entry>
    <title>ActiveMQ Practice Getting Started</title>
    <url>/2017/11/08/activemq-practice-getting-started/</url>
    <content><![CDATA[<blockquote>
<p>本文只是记录 ActiveMQ 服务的基本部署和消息的简单测试应用。</p>
</blockquote>
<h2 id="体系架构"><a href="#体系架构" class="headerlink" title="体系架构"></a>体系架构</h2><p><img src="/images/activemq/BrokerDiagram.png" alt="image"></p>
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><ul>
<li><p>消息流</p>
<p><code>消息生产者（Producer）</code> –&gt; <code>中间件（Broker）</code> –&gt; <code>消息消费者（Consumer）</code></p>
</li>
</ul>
<ul>
<li><p>两种模型</p>
<ul>
<li>Point to Point（点对点）</li>
<li>Publish/Subscribe（发布/订阅）</li>
</ul>
</li>
</ul>
<h2 id="服务部署"><a href="#服务部署" class="headerlink" title="服务部署"></a>服务部署</h2><p>参考：<a href="http://activemq.apache.org/getting-started.html">http://activemq.apache.org/getting-started.html</a></p>
<blockquote>
<p>本文实践环境说明：Windows 10 专业版，JDK 1.8.0_65。</p>
</blockquote>
<h3 id="1-下载"><a href="#1-下载" class="headerlink" title="1. 下载"></a>1. 下载</h3><p><a href="http://activemq.apache.org/download.html">http://activemq.apache.org/download.html</a></p>
<p>(目前最新版本5.15.2)</p>
<h3 id="2-安装-amp-启动服务"><a href="#2-安装-amp-启动服务" class="headerlink" title="2. 安装 &amp; 启动服务"></a>2. 安装 &amp; 启动服务</h3><p>解压 <code>apache-activemq-5.15.2-bin.zip</code> 到 <code>&lt;ActiveMQ_installed_dir&gt;</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ACTIVEMQ_HOME%\bin\activemq start</span><br></pre></td></tr></table></figure>
<h3 id="3-Web控制台"><a href="#3-Web控制台" class="headerlink" title="3. Web控制台"></a>3. Web控制台</h3><p>URL：<a href="http://127.0.0.1:8161/admin/">http://127.0.0.1:8161/admin/</a><br>Login：admin<br>Password：admin  </p>
<p>通过 conf/jetty-real.properties 配置用户名密码 </p>
<h3 id="4-日志文件"><a href="#4-日志文件" class="headerlink" title="4. 日志文件"></a>4. 日志文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ACTIVEMQ_HOME%&#x2F;data&#x2F;activemq.log</span><br></pre></td></tr></table></figure>
<h3 id="5-停止服务"><a href="#5-停止服务" class="headerlink" title="5. 停止服务"></a>5. 停止服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ACTIVEMQ_HOME%&#x2F;bin&#x2F;activemq stop</span><br></pre></td></tr></table></figure>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>先决条件：消息服务（中间件）已启动。</p>
<h3 id="1-启动消息消费者"><a href="#1-启动消息消费者" class="headerlink" title="1. 启动消息消费者"></a>1. 启动消息消费者</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ACTIVEMQ_HOME%&#x2F;bin&#x2F;activemq consumer</span><br></pre></td></tr></table></figure>
<h3 id="2-启动消息生产者"><a href="#2-启动消息生产者" class="headerlink" title="2. 启动消息生产者"></a>2. 启动消息生产者</h3><ul>
<li><p>自定义文本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ACTIVEMQ_HOME%&#x2F;bin&#x2F;activemq producer --message &quot;My message&quot; --messageCount 1</span><br></pre></td></tr></table></figure></li>
<li><p>定长字节消息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ACTIVEMQ_HOME%&#x2F;bin&#x2F;activemq producer --messageSize 100 --messageCount 1</span><br></pre></td></tr></table></figure></li>
<li><p>更多信息 </p>
<p><a href="http://activemq.apache.org/version-5-examples.html">http://activemq.apache.org/version-5-examples.html</a></p>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文对 ActiveMQ 进行了基础入门实践练习，以便更好的认识 ActiveMQ。</p>
<p>更多信息请查看官网：<a href="http://activemq.apache.org/">http://activemq.apache.org/</a></p>
<p>(END)</p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>2019 书单</title>
    <url>/2019/01/01/booklist-2019/</url>
    <content><![CDATA[<p>「追寻历史：一个记者和他的20世纪」</p>
<p>「乔布斯传」</p>
<p>「硅谷钢铁侠」</p>
<p>「奈飞文化手册」</p>
<p>「看见」</p>
<p>「三体」1、2、3</p>
]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>Booklist</tag>
      </tags>
  </entry>
  <entry>
    <title>2020 书单</title>
    <url>/2020/01/01/booklist-2020/</url>
    <content><![CDATA[<ul>
<li><input checked="" disabled="" type="checkbox"> 「枪炮、经济与霸权」</li>
<li><input checked="" disabled="" type="checkbox"> 「三联生活周刊」全年杂志</li>
<li><input disabled="" type="checkbox"> 「罗伯特议事规则」第 11 版 (未完)</li>
</ul>
]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>Booklist</tag>
      </tags>
  </entry>
  <entry>
    <title>Confluent Schema Registry Notes</title>
    <url>/2020/02/25/confluent-schema-registry-notes/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>模式注册表为元数据提供了一个服务层。 它提供了一个用于存储和检索 Avro 模式的 RESTful 接口，存储所有模式的版本历史，提供多个兼容性设置，并允许根据配置的兼容性设置改进模式。 它提供了插入 Kafka 客户机的序列化程序，处理以 Avro 格式发送的 Kafka 消息的模式存储和检索。</p>
<p>项目主页：<a href="https://github.com/confluentinc/schema-registry">https://github.com/confluentinc/schema-registry</a></p>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p>镜像引用来源：<a href="https://github.com/confluentinc/examples/blob/5.4.0-post/cp-all-in-one-community/">https://github.com/confluentinc/examples/blob/5.4.0-post/cp-all-in-one-community/</a></p>
<blockquote>
<p>其中 dev 为宿主机</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name eventbus_zk -d -p 2181:2181 zookeeper:3.5.7</span><br><span class="line"></span><br><span class="line">docker run --name schema-registry -d -h schema-registry -p 8081:8081 \</span><br><span class="line">   -e SCHEMA_REGISTRY_HOST_NAME&#x3D;schema-registry \</span><br><span class="line">   -e SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL&#x3D;dev:2181 \</span><br><span class="line">   confluentinc&#x2F;cp-schema-registry:5.5.0 </span><br></pre></td></tr></table></figure>
<h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="查询主题-模式"><a href="#查询主题-模式" class="headerlink" title="查询主题/模式"></a>查询主题/模式</h3><ul>
<li><p>List all subjects</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects</span><br></pre></td></tr></table></figure>
</li>
<li><p>List all schema versions registered under the subject “Kafka-key”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key&#x2F;versions</span><br></pre></td></tr></table></figure></li>
<li><p>Fetch version 1 of the schema registered under subject “Kafka-key”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key&#x2F;versions&#x2F;1</span><br></pre></td></tr></table></figure></li>
<li><p>Fetch the most recently registered schema under subject “Kafka-key”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key&#x2F;versions&#x2F;latest</span><br></pre></td></tr></table></figure></li>
<li><p>Fetch a schema by globally unique id 1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;schemas&#x2F;ids&#x2F;1</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h3 id="注册主题"><a href="#注册主题" class="headerlink" title="注册主题"></a>注册主题</h3><ul>
<li>Register a new version of a schema under the subject “Kafka-key”<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X POST -H &quot;Content-Type: application&#x2F;vnd.schemaregistry.v1+json&quot; \</span><br><span class="line">  --data &#39;&#123;</span><br><span class="line">  &quot;schema&quot;: &quot;&#123;\&quot;type\&quot;: \&quot;record\&quot;,\&quot;name\&quot;: \&quot;User\&quot;,\&quot;fields\&quot;: [&#123;\&quot;name\&quot;: \&quot;id\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;name\&quot;,  \&quot;type\&quot;: \&quot;string\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;age\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125; ]&#125;&quot;&#125;&#39; \</span><br><span class="line">    http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key&#x2F;versions</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">curl -X POST -H &quot;Content-Type: application&#x2F;vnd.schemaregistry.v1+json&quot; \</span><br><span class="line">  --data &#39;&#123;</span><br><span class="line">  &quot;schema&quot;: &quot;&#123;\&quot;type\&quot;: \&quot;record\&quot;,\&quot;name\&quot;: \&quot;User\&quot;,\&quot;fields\&quot;: [&#123;\&quot;name\&quot;: \&quot;id\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;name\&quot;,  \&quot;type\&quot;: \&quot;string\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;age\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;age1\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125; ]&#125;&quot;&#125;&#39; \</span><br><span class="line">    http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key&#x2F;versions</span><br><span class="line">    </span><br><span class="line">curl -X POST -H &quot;Content-Type: application&#x2F;vnd.schemaregistry.v1+json&quot; \</span><br><span class="line">  --data &#39;&#123;</span><br><span class="line">  &quot;schema&quot;: &quot;&#123;\&quot;type\&quot;: \&quot;record\&quot;,\&quot;name\&quot;: \&quot;User\&quot;,\&quot;fields\&quot;: [&#123;\&quot;name\&quot;: \&quot;id\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;name\&quot;,  \&quot;type\&quot;: \&quot;string\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;age\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125;,&#123;\&quot;name\&quot;: \&quot;age2\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125; ]&#125;&quot;&#125;&#39; \</span><br><span class="line">    http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key&#x2F;versions</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h3 id="删除模式-版本"><a href="#删除模式-版本" class="headerlink" title="删除模式/版本"></a>删除模式/版本</h3><ul>
<li><p>Delete version 1 of the schema registered under subject “Kafka-key”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X DELETE http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key&#x2F;versions&#x2F;1</span><br></pre></td></tr></table></figure>
<p>Output: <code>1</code></p>
</li>
<li><p>Delete all versions of the schema registered under subject “Kafka-key”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X DELETE http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key</span><br></pre></td></tr></table></figure>

<p>Output: <code>[2,3,4]</code> </p>
</li>
</ul>
<h3 id="兼容性检查"><a href="#兼容性检查" class="headerlink" title="兼容性检查"></a>兼容性检查</h3><ul>
<li>Check whether a schema has been registered under subject “Kafka-key”<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X POST -H &quot;Content-Type: application&#x2F;vnd.schemaregistry.v1+json&quot; \</span><br><span class="line">  --data &#39;&#123;&quot;schema&quot;: &quot;&#123;\&quot;type\&quot;: \&quot;string\&quot;&#125;&quot;&#125;&#39; \</span><br><span class="line">  http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;subjects&#x2F;Kafka-key</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li>Test compatibility of a schema with the latest schema under subject “Kafka-key”<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X POST -H &quot;Content-Type: application&#x2F;vnd.schemaregistry.v1+json&quot; \</span><br><span class="line">  --data &#39;&#123;&quot;schema&quot;: &quot;&#123;\&quot;type\&quot;: \&quot;string\&quot;&#125;&quot;&#125;&#39; \</span><br><span class="line">  http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;compatibility&#x2F;subjects&#x2F;Kafka-key&#x2F;versions&#x2F;latest</span><br></pre></td></tr></table></figure>
Output: <code>&#123;&quot;is_compatible&quot;:true&#125;</code></li>
</ul>
<h3 id="兼容性设置"><a href="#兼容性设置" class="headerlink" title="兼容性设置"></a>兼容性设置</h3><ul>
<li><p>Get top level config</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;config</span><br></pre></td></tr></table></figure>
<p>Output: <code>&#123;&quot;compatibilityLevel&quot;:&quot;BACKWARD&quot;&#125;</code></p>
</li>
<li><p>Update compatibility requirements globally</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X PUT -H &quot;Content-Type: application&#x2F;vnd.schemaregistry.v1+json&quot; \</span><br><span class="line">  --data &#39;&#123;&quot;compatibility&quot;: &quot;NONE&quot;&#125;&#39; \</span><br><span class="line">  http:&#x2F;&#x2F;172.16.18.143:8081&#x2F;config</span><br></pre></td></tr></table></figure>
<p>Output: <code>&#123;&quot;compatibilityLevel&quot;:&quot;NONE&quot;&#125;</code></p>
</li>
<li><p>Update compatibility requirements under the subject “Kafka-key”</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X PUT -H &quot;Content-Type: application&#x2F;vnd.schemaregistry.v1+json&quot; \</span><br><span class="line">  --data &#39;&#123;&quot;compatibility&quot;: &quot;BACKWARD&quot;&#125;&#39; \</span><br><span class="line">  http:&#x2F;&#x2F;localhost:8081&#x2F;config&#x2F;Kafka-key</span><br></pre></td></tr></table></figure>
<p>Output: <code>&#123;&quot;compatibility&quot;:&quot;BACKWARD&quot;&#125;</code></p>
</li>
</ul>
<h2 id="模式进化与兼容性"><a href="#模式进化与兼容性" class="headerlink" title="模式进化与兼容性"></a>模式进化与兼容性</h2><h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><p>（待续）</p>
]]></content>
      <categories>
        <category>Schema</category>
      </categories>
      <tags>
        <tag>Arvo</tag>
        <tag>Json</tag>
        <tag>Protobuf</tag>
        <tag>Registry</tag>
      </tags>
  </entry>
  <entry>
    <title>2021 书单</title>
    <url>/2021/01/06/booklist-2021/</url>
    <content><![CDATA[<ul>
<li><input checked="" disabled="" type="checkbox"> 「长期价值——百年可口可乐的经营策略」（[英]Neville Isdell [美]David Beasley  高洁 译）</li>
<li><input checked="" disabled="" type="checkbox"> 「分布式服务架构——原理、设计与实践」（李艳鹏 杨彪 著）</li>
<li><input checked="" disabled="" type="checkbox"> 「见识——你能走多远，取决于见识」（吴军 著）</li>
<li><input checked="" disabled="" type="checkbox"> 「态度——把简单的事情，做得出人意料的精彩」（吴军 著）</li>
<li><input checked="" disabled="" type="checkbox"> 「格局——世界永远不缺聪明人」（吴军 著）</li>
<li><input disabled="" type="checkbox"> 「我的改变——个人的现代化 40 年」（王石）</li>
<li><input disabled="" type="checkbox"> 「不拘一格——网飞的自由与责任工作法」（[美]Reed Hastings [美]Erin Meyer 杨占 译）</li>
<li><input disabled="" type="checkbox"> 「反脆弱——从不确定性中获益」（[美]Nassim Nicholas Taleb 雨珂 译）</li>
<li><input disabled="" type="checkbox"> 「人生由我」（[加]Maye Musk 代晓 译）</li>
<li><input disabled="" type="checkbox"> 「他影响了中国——陈云」（叶永烈 著）</li>
<li><input disabled="" type="checkbox"> 「美国家庭万用亲子英文」</li>
<li><input disabled="" type="checkbox"> 「罗伯特议事规则」第 11 版 </li>
</ul>
]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>Booklist</tag>
        <tag>2021</tag>
      </tags>
  </entry>
  <entry>
    <title>Create My Hexo Blog</title>
    <url>/2017/11/09/create-my-hexo-blog/</url>
    <content><![CDATA[<blockquote>
<p>本文记录了创建自己的 Hexo 博客过程。</p>
</blockquote>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>Node.js：<a href="https://nodejs.org/zh-cn/">https://nodejs.org/zh-cn/</a></p>
<p>Git：<a href="https://git-scm.com/">https://git-scm.com/</a></p>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>如果需要搭建自己的博客（网站），强烈推荐查看官网教程。Hexo：<a href="http://hexo.io/">http://hexo.io/</a></p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p>通过 <code>hexo --version</code> 验证 Hexo 是否安装成功。</p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init &lt;dir&gt;</span><br><span class="line">cd &lt;dir&gt;</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>
<p>执行成功后，即站点完成初始化工作。</p>
<h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>
<p>启动成功后，访问：<a href="http://localhost:4000/">http://localhost:4000/</a></p>
<p><img src="/images/hexo/hello-hexo.png" alt="image"></p>
<h2 id="NexT"><a href="#NexT" class="headerlink" title="NexT"></a>NexT</h2><p>自己的博客选择了 NexT 主题，详细说明请查看官网教程。NexT：<a href="http://theme-next.iissnan.com/">http://theme-next.iissnan.com/</a></p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd my-hexo-site</span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;iissnan&#x2F;hexo-theme-next themes&#x2F;next</span><br></pre></td></tr></table></figure>
<h3 id="启用"><a href="#启用" class="headerlink" title="启用"></a>启用</h3><p>修改文件 <code>my-hexo-site/_config.yml</code> 的 <code>theme</code> 属性值为 <code>next</code> ，重启服务。</p>
<p><img src="/images/hexo/hello-next.png" alt="image"></p>
<h3 id="切换-Scheme"><a href="#切换-Scheme" class="headerlink" title="切换 Scheme"></a>切换 Scheme</h3><p>NexT 支持多种外观风格，默认使用 <code>Muse</code>，如上图。</p>
<p>修改文件 <code>my-hexo-site/themes/next/_config.yml</code> 的<code>scheme</code>属性值为 <code>Pisces</code> 来切换风格。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#scheme: Muse</span><br><span class="line">#scheme: Mist</span><br><span class="line">scheme: Pisces</span><br></pre></td></tr></table></figure>
<p><img src="/images/hexo/next-scheme.png" alt="image"></p>
<p>NexT 还有更丰富的配置及第三方扩展，具体请查看官网。</p>
<h2 id="感谢"><a href="#感谢" class="headerlink" title="感谢"></a>感谢</h2><p>感谢 Hexo ，感谢 NexT，感谢 OpenSource，让我们能够方便的定制自己的站点。</p>
]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
  <entry>
    <title>DB2 SQL Script Memo</title>
    <url>/2017/08/31/db2-sql-script/</url>
    <content><![CDATA[<h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><h3 id="筛选包含某表的视图列表"><a href="#筛选包含某表的视图列表" class="headerlink" title="筛选包含某表的视图列表"></a>筛选包含某表的视图列表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT t.viewschema, t.viewname</span><br><span class="line">  FROM syscat.viewdep t</span><br><span class="line"> WHERE t.bname &#x3D; UPPER (&#39;#table&#39;) AND t.viewschema &#x3D; &#39;#schema&#39;;</span><br></pre></td></tr></table></figure>
<h2 id="列"><a href="#列" class="headerlink" title="列"></a>列</h2><h3 id="筛选系统字段表"><a href="#筛选系统字段表" class="headerlink" title="筛选系统字段表"></a>筛选系统字段表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  SELECT *</span><br><span class="line">    FROM syscat.columns c</span><br><span class="line">   WHERE     EXISTS</span><br><span class="line">                (SELECT 1</span><br><span class="line">                   FROM syscat.tables t</span><br><span class="line">                  WHERE owner &#x3D; &#39;#schema&#39; AND t.TABNAME &#x3D; c.TABNAME)</span><br><span class="line">         AND UPPER (c.COLNAME) LIKE &#39;%#column%&#39;</span><br><span class="line">ORDER BY c.TABNAME;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>DB2</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 1604 TLS Server 安装 Docker CE</title>
    <url>/2018/03/12/docker-ce-at-ubuntu-1604-tls-server/</url>
    <content><![CDATA[<blockquote>
<p>环境： Unbuntu 16.04 TLS Server</p>
</blockquote>
<h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a><a href="https://www.docker.com/">Docker</a></h2><ul>
<li><p>Docker CE: Docker Community Edition</p>
</li>
<li><p>Docker EE: Docker Enterprise Edition</p>
</li>
</ul>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p><code>sudo apt-get update</code></p>
<p>可能出现错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Ign:1 cdrom:&#x2F;&#x2F;Ubuntu-Server 16.04.3 LTS _Xenial Xerus_ - Release amd64 (20170801) xenial InRelease</span><br><span class="line">Err:2 cdrom:&#x2F;&#x2F;Ubuntu-Server 16.04.3 LTS _Xenial Xerus_ - Release amd64 (20170801) xenial Release</span><br><span class="line"> Please use apt-cdrom to make this CD-ROM recognized by APT. apt-get update cannot be used to add new CD-ROMs</span><br><span class="line">Hit:3 http:&#x2F;&#x2F;security.ubuntu.com&#x2F;ubuntu xenial-security InRelease</span><br><span class="line">Hit:4 http:&#x2F;&#x2F;us.archive.ubuntu.com&#x2F;ubuntu xenial InRelease</span><br><span class="line">Hit:5 http:&#x2F;&#x2F;us.archive.ubuntu.com&#x2F;ubuntu xenial-updates InRelease</span><br><span class="line">Hit:6 http:&#x2F;&#x2F;us.archive.ubuntu.com&#x2F;ubuntu xenial-backports InRelease</span><br><span class="line">Reading package lists... Done</span><br><span class="line">E: The repository &#39;cdrom:&#x2F;&#x2F;Ubuntu-Server 16.04.3 LTS _Xenial Xerus_ - Release amd64 (20170801) xenial Release&#39; does not have a Release file.</span><br><span class="line">N: Updating from such a repository can&#39;t be done securely, and is therefore disabled by default.</span><br><span class="line">N: See apt-secure(8) manpage for repository creation and user configuration details.</span><br></pre></td></tr></table></figure>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vi &#x2F;etc&#x2F;apt&#x2F;sources.list</span><br></pre></td></tr></table></figure>
<p>注释掉 <code>deb cdrom</code> 打头的部分</p>
<blockquote>
<p>deb cdrom:[Ubuntu-Server 16.04.3 LTS <em>Xenial Xerus</em> - Release amd64 (20170801)]/ xenial main restricted</p>
</blockquote>
<p>保存后退出再次尝试 <code>sudo apt-get update</code></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Install-from-a-package"><a href="#Install-from-a-package" class="headerlink" title="Install from a package"></a>Install from a package</h3><p>下载 docker-ce-18.06（获取<a href="https://download.docker.com/linux/ubuntu/dists/">更多版本</a>）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;docker</span><br><span class="line"></span><br><span class="line">wget https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;ubuntu&#x2F;dists&#x2F;artful&#x2F;pool&#x2F;stable&#x2F;amd64&#x2F;docker-ce_18.06.3~ce~3-0~ubuntu_amd64.deb</span><br></pre></td></tr></table></figure>


<p>安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i &#x2F;usr&#x2F;local&#x2F;docker&#x2F;docker-ce_18.06.3~ce~3-0~ubuntu_amd64.deb</span><br></pre></td></tr></table></figure>
<p>验证</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker version</span><br></pre></td></tr></table></figure>


<h3 id="其他方式"><a href="#其他方式" class="headerlink" title="其他方式"></a>其他方式</h3><blockquote>
<p>通过 rancher 提供的安装脚本在线安装</p>
</blockquote>
<p><code>curl https://releases.rancher.com/install-docker/17.06.sh | sh</code></p>
<p>安装完成后，通过以下命令验证安装结果</p>
<p><code>sudo docker version</code> 或 <code>sudo docker info</code></p>
<h2 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h2><p>卸载Docker CE <code>sudo apt-get purge docker-ce</code></p>
<p>删除Docker镜像、容器、数据卷等文件 <code>sudo rm -rf /var/lib/docker</code></p>
]]></content>
      <categories>
        <category>OS&amp;VM&amp;LXC</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 1604 TLS Server 安装 Docker Compose</title>
    <url>/2020/02/17/docker-compose-at-ubuntu-1604-tls-server/</url>
    <content><![CDATA[<blockquote>
<p>环境： Unbuntu 16.04 TLS Server</p>
</blockquote>
<h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><p><strong>Docker</strong>: <a href="/2018/03/12/docker-ce-at-ubuntu-1604-tls-server/" title="Ubuntu 1604 TLS Server 安装 Docker CE">Ubuntu 1604 TLS Server 安装 Docker CE</a></p>
<h2 id="安装-Compose"><a href="#安装-Compose" class="headerlink" title="安装 Compose"></a>安装 Compose</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo curl -L &quot;https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;compose&#x2F;releases&#x2F;download&#x2F;1.25.3&#x2F;docker-compose-$(uname -s)-$(uname -m)&quot; -o &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose</span><br></pre></td></tr></table></figure>


<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose</span><br></pre></td></tr></table></figure>


<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker-compose --version</span><br></pre></td></tr></table></figure>


<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://docs.docker.com/compose/install/">官方安装 Docker Compose</a></p>
]]></content>
      <categories>
        <category>OS&amp;VM&amp;LXC</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>Docker</tag>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Compose Notes</title>
    <url>/2020/03/03/docker-compose-notes/</url>
    <content><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p><strong>Docker Compose</strong>: <a href="/2020/02/17/docker-compose-at-ubuntu-1604-tls-server/" title="Ubuntu 1604 TLS Server 安装 Docker Compose">Ubuntu 1604 TLS Server 安装 Docker Compose</a></p>
<p>Docker Version</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> docker -v</span></span><br><span class="line">Docker version 18.06.3-ce, build d7080c1</span><br></pre></td></tr></table></figure>


<p>Docker Compose Version</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> docker-compose -v</span></span><br><span class="line">docker-compose version 1.25.4, build 8d51620a</span><br></pre></td></tr></table></figure>




<h2 id="命令用法"><a href="#命令用法" class="headerlink" title="命令用法"></a>命令用法</h2><blockquote>
<p>此处仅罗列了个人使用过的命令与选项，更全面的命令用法请参考 <code>docker-compose -h</code></p>
</blockquote>
<h3 id="Usage-用法-："><a href="#Usage-用法-：" class="headerlink" title="Usage[用法]："></a>Usage[用法]：</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...]</span><br><span class="line"></span><br><span class="line">docker-compose -h|--help</span><br></pre></td></tr></table></figure>


<h3 id="Options-选项"><a href="#Options-选项" class="headerlink" title="Options [选项]:"></a>Options [选项]:</h3><ul>
<li><code>-f, --file FILE</code><br>指定另外一个 compose 文件（默认：<code>docker-compose.yml</code>）</li>
</ul>
<ul>
<li><p><code>-p, --project-name NAME</code><br>指定另外一个项目名称（默认：当前目录名称）</p>
</li>
<li><p><code>-v, --version</code><br>打印版本号并退出</p>
</li>
</ul>
<h3 id="COMMAND-命令-："><a href="#COMMAND-命令-：" class="headerlink" title="COMMAND[命令]："></a>COMMAND[命令]：</h3><ul>
<li><p><code>help</code></p>
<p>命令帮助</p>
</li>
<li><p><code>build</code></p>
<p>构建/重新构建所有服务</p>
</li>
<li><p><code>up</code></p>
<p>创建并且启动所有容器</p>
</li>
<li><p><code>down</code></p>
<p>停止并且移除容器、网络镜像以及卷</p>
</li>
<li><p><code>start</code></p>
<p>启动所有服务</p>
</li>
<li><p><code>stop</code></p>
<p>停止所有服务</p>
</li>
<li><p><code>restart</code></p>
<p>重新启动所有服务</p>
</li>
<li><p><code>exec</code></p>
<p>在运行的容器内执行命令</p>
</li>
<li><p><code>images</code></p>
<p>显示镜像列表</p>
</li>
<li><p><code>ps</code></p>
<p>显示容器列表</p>
</li>
<li><p><code>logs</code></p>
<p>查看容器系统输出</p>
</li>
<li><p><code>version</code></p>
<p>显示 Docker Compose 版本信息</p>
</li>
</ul>
<p>（待续）</p>
]]></content>
      <categories>
        <category>OS&amp;VM&amp;LXC</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title>Dubbo Feature Practies</title>
    <url>/2020/01/09/dubbo-feature-practices/</url>
    <content><![CDATA[<p>Official Site: <a href="http://dubbo.apache.org/">http://dubbo.apache.org</a></p>
<h2 id="Introduce"><a href="#Introduce" class="headerlink" title="Introduce"></a>Introduce</h2><p>Apache Dubbo 是一个高性能的、基于 JAVA 的开源 RPC 框架。</p>
<h2 id="Feature-List"><a href="#Feature-List" class="headerlink" title="Feature List"></a>Feature List</h2><ul>
<li><p>Transparent interface based RPC </p>
<p>Dubbo 提供了基于 RPC 的高性能接口，这对用户是透明的。</p>
</li>
<li><p>Automatic service registration and discovery</p>
<p>Dubbo 支持多种服务注册中心，能够实时监测服务的在线离线。</p>
</li>
<li><p>Runtime traffic routing</p>
<p>Dubbo 可以在运行时进行配置，这样流量可以根据不同的规则进行路由，使得支持如蓝绿部署、数据中心感知路由等功能变得容易。</p>
</li>
<li><p>Intelligent load balancing</p>
<p>Dubbo 支持多种开箱即用的负载均衡策略，这种策略能够感知下游服务状态，以减少延迟并提高系统吞吐量。</p>
</li>
<li><p>High extensibility</p>
<p>Dubbo 的微内核及插件设计确保了它能够很容易地通过第三方实现跨核心特性扩展，如协议传、输和序列化。</p>
</li>
<li><p>Visualized service governance</p>
<p>Dubbo 为服务治理和维护提供了丰富的工具，如查询服务元数据，健康状态和统计。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Framework</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>RPC</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 笔记</title>
    <url>/2020/04/16/elk-elasticsearch-notes/</url>
    <content><![CDATA[<blockquote>
<p>Elasticsearch: 7.4.0</p>
</blockquote>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>官网：<a href="https://www.elastic.co/">https://www.elastic.co/</a></p>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name es -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.4.0</span><br></pre></td></tr></table></figure>


<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><ul>
<li>kibana</li>
<li>elasticsearch-head：<a href="https://github.com/mobz/elasticsearch-head">https://github.com/mobz/elasticsearch-head</a></li>
</ul>
<h2 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h2><h3 id="CORS"><a href="#CORS" class="headerlink" title="CORS"></a>CORS</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br></pre></td></tr></table></figure>


<h2 id="REST-API-Examples"><a href="#REST-API-Examples" class="headerlink" title="REST API Examples"></a>REST API Examples</h2><h3 id="index"><a href="#index" class="headerlink" title="_index"></a>_index</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">POST xxx-index-2020-04-10/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;cluster&quot;</span>: <span class="string">&quot;primary-dc&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;reason&quot;</span>: <span class="string">&quot;Total timeout 1000 ms elapsed&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;hostname&quot;</span>: <span class="string">&quot;9ddf7031ac70&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;partition&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">&quot;offset&quot;</span>: <span class="number">21</span>,</span><br><span class="line">    <span class="attr">&quot;messageId&quot;</span>: <span class="string">&quot;70df2035-3c81-4ebf-8f76-a396ee1f94fc&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;topicName&quot;</span>: <span class="string">&quot;T2.g2.t1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;subscription&quot;</span>: <span class="string">&quot;my-Subscription1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;batchId&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;publish_timestamp&quot;</span>: <span class="number">1587010729737</span>,</span><br><span class="line">    <span class="attr">&quot;timestamp&quot;</span>: <span class="number">1587010742388</span>,</span><br><span class="line">    <span class="attr">&quot;status&quot;</span>: <span class="string">&quot;DISCARDED&quot;</span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>


<h3 id="search"><a href="#search" class="headerlink" title="_search"></a>_search</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET xxx-index-wildcard-*/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;from&quot;</span>: <span class="number">0</span>, </span><br><span class="line">  <span class="attr">&quot;size&quot;</span>: <span class="number">20</span>, </span><br><span class="line">  <span class="attr">&quot;sort&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;timestamp&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;unmapped_type&quot;</span>: <span class="string">&quot;date&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;order&quot;</span>: <span class="string">&quot;asc&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ], </span><br><span class="line">  <span class="attr">&quot;query&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;bool&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;must&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">&quot;term&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;topicName.keyword&quot;</span>: &#123;</span><br><span class="line">              <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;T2.g2.t1&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">         <span class="attr">&quot;term&quot;</span>: &#123;</span><br><span class="line">           <span class="attr">&quot;subscription.keyword&quot;</span>: &#123;</span><br><span class="line">             <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;my-Subscription1&quot;</span></span><br><span class="line">           &#125;</span><br><span class="line">         &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="alias"><a href="#alias" class="headerlink" title="_alias"></a>_alias</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">POST xxx-index-2020-04-20/_alias/xxx-index-alias</span><br><span class="line">&#123;&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>ELK</tag>
        <tag>Elasticsearch</tag>
        <tag>Elastic</tag>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title>Logstash 笔记</title>
    <url>/2019/05/31/elk-logstash-notes/</url>
    <content><![CDATA[<h2 id="Input-Plugins"><a href="#Input-Plugins" class="headerlink" title="Input Plugins"></a>Input Plugins</h2><h3 id="Tcp-input-plugin"><a href="#Tcp-input-plugin" class="headerlink" title="Tcp input plugin"></a><a href="https://www.elastic.co/guide/en/logstash/6.5/plugins-inputs-tcp.html">Tcp input plugin</a></h3><blockquote>
<p>logstash:6.5.3</p>
</blockquote>
<p>创建配置文件到 <code>/usr/local/logstash/pipeline/tcp.conf</code></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  tcp &#123;</span><br><span class="line">    port =&gt; 9600</span><br><span class="line">    codec =&gt; json</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line"></span><br><span class="line">    json &#123;</span><br><span class="line">      source =&gt; &quot;message&quot;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    mutate &#123; copy =&gt; &#123; &quot;message&quot; =&gt; &quot;messageContent&quot; &#125; &#125;</span><br><span class="line"></span><br><span class="line">    mutate &#123; remove_field =&gt; [ &quot;message&quot;] &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>启动 Logstash 容器，并挂载 tcp pipeline 配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --rm -it --name logstash -p 9600:9600 -v /usr/local/logstash/pipeline/:/usr/share/logstash/pipeline/ logstash:6.5.3</span><br></pre></td></tr></table></figure>


<p><a href="https://www.elastic.co/guide/en/logstash/current/docker-config.html#_pipeline_configuration">Configuring Logstash for Docker</a></p>
<p>准备测试数据 <code>test.json</code></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;message&quot;</span>:&#123;<span class="attr">&quot;someField&quot;</span>:<span class="string">&quot;someValue&quot;</span>&#125;&#125;</span><br></pre></td></tr></table></figure>


<p>发送</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nc localhost 9600 &lt; test.json</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>ELK</tag>
        <tag>Logstash</tag>
      </tags>
  </entry>
  <entry>
    <title>Kibana 笔记</title>
    <url>/2020/04/20/elk-kibana-notes/</url>
    <content><![CDATA[<blockquote>
<p>Elasticsearch: 7.4.0, Kibana:7.4.0</p>
</blockquote>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>官网：<a href="https://www.elastic.co/">https://www.elastic.co/</a></p>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --name kibana -p 5601:5601 -e ELASTICSEARCH_HOSTS&#x3D;http:&#x2F;&#x2F;dev:9200 docker.elastic.co&#x2F;kibana&#x2F;kibana:7.4.0</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Elasticsearch</tag>
        <tag>Elastic</tag>
        <tag>Kibana</tag>
      </tags>
  </entry>
  <entry>
    <title>Event Broker Hermes Notes</title>
    <url>/2020/02/19/event-broker-hermes-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p><a href="https://hermes-pubsub.readthedocs.io/en/latest/">Hermes</a> 是使用 Kafka 作为消息存储和路由支持的消息代理，使用发布-订阅模式大大简化了服务之间的通信。</p>
<p>它是 HTTP-native，公开用于消息发布的 REST 端点，并将消息推送到订阅者 REST 端点。</p>
<p>Hermes 使用 HTTP 作为默认通信协议。 这意味着发布或接收消息的唯一先决条件是能够发送或使用 HTTP 请求。</p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="/images/hermes/architecture-overview.png" alt="image"></p>
<blockquote>
<p>核心模块与组件</p>
</blockquote>
<ul>
<li>Hermes Frontend 接收来自客户端的消息</li>
<li>Hermes Consumers 发送消息到订阅者（push 模式）</li>
<li>Hermes Management 管理主题和订阅</li>
</ul>
<ul>
<li>Message Store 存储和路由消息，当前实现： Kafka</li>
<li>Metadata Store 共享元数据存储，当前实现：Zookeeper</li>
<li>Metrics Store [可选] 存储 Hermes 度量数据，当前实现：Graphite</li>
<li>Tracking Store [可选] 存储消息追踪信息，当前实现：Elasticsearch/MongoDB</li>
</ul>
<blockquote>
<p>消息流</p>
</blockquote>
<p>消息发送者发送消息到 <strong>Hermes Frontend</strong>：</p>
<ul>
<li>消息被分配唯一的 Hermes-Message-Id，可用于在系统中跟踪其路径</li>
<li>每个动作时间被计量，度量被发送到 <strong>Metrics Store</strong></li>
<li>如果主题已启用跟踪，则跟踪信息将发送到 <strong>Tracking Store</strong></li>
<li>消息被发送到 <strong>Message Store</strong></li>
</ul>
<p><strong>Hermes Consumers</strong> 发送消息给订阅者：</p>
<ul>
<li>从 <strong>Message Store</strong> 读取消息</li>
<li>每个动作时间被计量，度量被发送到 <strong>Metrics Store</strong></li>
<li>消息发送到订阅者</li>
<li>如果订阅者发生错误，<strong>Hermes Consumers</strong> 调整发送速度并重试</li>
</ul>
<blockquote>
<p>主要概念</p>
</blockquote>
<ul>
<li><p><strong>publisher</strong> 发送消息给 Hermes </p>
</li>
<li><p><strong>subscriber</strong> 希望从 Hermes  接收消息，</p>
</li>
<li><p><strong>group</strong> 是由一个发布者管理的一组主题，例如将整个主题空间划分为域和有界上下文组</p>
</li>
<li><p><strong>topic</strong> 保存相同类型的消息，定义所有存储的消息的类型、模式和持久性，订阅者可以订阅存储在主题上的消息</p>
</li>
<li><p><strong>subscription</strong> 是按每个主题创建的，保存有关已使用的消息和其他订阅者定义的属性(如最大传递速率或重试策略)的信息</p>
</li>
</ul>
<blockquote>
<p>命名约定</p>
</blockquote>
<p>主题通常使用全限定名引用，全限定名由组名和以点分隔的主题名组成。 组名可以包含任何字符-字母、数字、点。 但是，主题名称不能包含点。</p>
<p><code>Full-qualifed topic name</code> = <code>Group name</code>.<code>Topic name</code></p>
<h2 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h2><h3 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h3><p>获取最新版本（此时为 <code>1.4.0</code>）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone -b hermes-1.4.0 https:&#x2F;&#x2F;github.com&#x2F;allegro&#x2F;hermes.git hermes-1.4.0</span><br></pre></td></tr></table></figure>


<h3 id="Deploy-1"><a href="#Deploy-1" class="headerlink" title="Deploy"></a>Deploy</h3><blockquote>
<p>警告！<br>警告！<br>警告！</p>
</blockquote>
<p>该 <code>1.4.0</code> 版本 docker-compose 中包含的 <code>allegro/hermes-*:latest</code> 镜像版本并不是对应的 <code>1.4.0</code> 或最新版本，tag 为 <code>latest</code> 的镜像竟然是 3 年前构建的。有图为证：</p>
<p><img src="/images/hermes/docker-image-latest-is-bug.png" alt="docker-image-latest-is-bug"></p>
<p>遇到这种情况，此时最好的方式便是自行编译源码，自行构建对应版本的镜像。</p>
<p>以构建 <code>frontend:1.4.0</code> 为例</p>
<ol>
<li><p>编译</p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Change Dir</span></span><br><span class="line">cd hermes-1.4.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制原有镜像构建文件</span></span><br><span class="line">cp -r docker/latest docker/1.4.0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Change Dir</span></span><br><span class="line">cd hermes-frontend</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编译打包</span></span><br><span class="line">gradle -x test distZip -Pdistribution</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将构建包拷贝到对应的目录下</span></span><br><span class="line">cp build/distributions/hermes-frontend-1.4.0.zip ../docker/1.4.0/frontend/</span><br></pre></td></tr></table></figure>
</li>
<li><p>编辑 Dockerfile</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> jeanblanchard/java:<span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">MAINTAINER</span> Allegro</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk update \</span></span><br><span class="line"><span class="bash">  &amp;&amp; apk add unzip wget bash \</span></span><br><span class="line"><span class="bash">  &amp;&amp; rm -rf /var/cache/apk/*</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> hermes-frontend-1.4.0.zip /tmp/hermes-frontend-1.4.0.zip</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> unzip -q <span class="string">&quot;/tmp/hermes-frontend-1.4.0.zip&quot;</span> -d /opt \</span></span><br><span class="line"><span class="bash">  &amp;&amp; rm <span class="string">&quot;/tmp/hermes-frontend-1.4.0.zip&quot;</span> \</span></span><br><span class="line"><span class="bash">  &amp;&amp; mv /opt/hermes-frontend-* /opt/hermes-frontend</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> HERMES_FRONTEND_OPTS=<span class="string">&quot;-Darchaius.configurationSource.additionalUrls=file:///etc/hermes/frontend.properties -Dlogback.configurationFile=/etc/hermes/logback.xml&quot;</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> frontend.properties /etc/hermes/frontend.properties</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> logback.xml /etc/hermes/logback.xml</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> /opt/hermes-frontend/bin/hermes-frontend</span></span><br></pre></td></tr></table></figure>

</li>
<li><p>构建镜像</p>
<ul>
<li><p>Frontend</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Change Dir</span></span><br><span class="line">cd ../docker/1.4.0/frontend</span><br><span class="line"><span class="meta">#</span><span class="bash"> 构建镜像</span></span><br><span class="line">docker build -t frontend:1.4.0 .</span><br></pre></td></tr></table></figure></li>
<li><p>consumer</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Change Dir</span></span><br><span class="line">cd ../docker/1.4.0/consumers</span><br><span class="line"><span class="meta">#</span><span class="bash"> 构建镜像</span></span><br><span class="line">docker build -t consumers:1.4.0 .</span><br></pre></td></tr></table></figure></li>
<li><p>management</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Change Dir</span></span><br><span class="line">cd ../docker/1.4.0/management</span><br><span class="line"><span class="meta">#</span><span class="bash"> 构建镜像</span></span><br><span class="line">docker build -t management:1.4.0 .</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
<li><p>替换镜像</p>
<p>替换 <code>docker/docker-compose.yml</code> 中镜像<code>allegro/hermes-frontend</code>为 <code>frontend:1.4.0</code></p>
<p>替换 <code>docker/docker-compose.yml</code> 中镜像<code>allegro/hermes-consumers</code>为 <code>consumers:1.4.0</code></p>
<p>替换 <code>docker/docker-compose.yml</code> 中镜像<code>allegro/hermes-management</code>为 <code>management:1.4.0</code></p>
</li>
</ol>
<p>至此，<code>frontend</code> 的替换操作已经完成。接着将 <code>consumer</code> 与 <code>management</code> 也进行类似的处理。</p>
<p>处理完毕。</p>
<p>最后，可以照下述步骤进一步操作。</p>
<p>启动服务容器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd hermes-1.4.0&#x2F;docker</span><br><span class="line"></span><br><span class="line">docker-compose up</span><br></pre></td></tr></table></figure>
<p>注意：在所有容器启动成功后，服务在实际的运行过程中，会出现一个错误，这一错误导致 <code>Hermes Consumers</code>无法收到消息。Kafka 容器后台错误信息摘要：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[2020-02-20 08:58:10,259] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:10,767] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:11,269] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:11,772] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:12,276] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:12,778] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:13,281] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:13,786] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:14,287] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:14,790] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:15,291] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:15,797] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:16,298] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br><span class="line">[2020-02-20 08:58:16,801] ERROR [KafkaApi-1001] Number of alive brokers &#x27;1&#x27; does not meet the required replication factor &#x27;3&#x27; for the offsets topic (configured via &#x27;offsets.topic.replication.factor&#x27;). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)</span><br></pre></td></tr></table></figure>
<p>出现该问题的根本原因暂时没有深入研究，目前通过增加一个配置项临时规避该错误。</p>
<p>具体操作：对 Kafka 容器内模板文件<code>/etc/confluent/docker/kafka.properties.template</code>增加<code>offsets.topic.replication.factor=1</code>这一设置，这样目标文件<code>/etc/kafka/kafka.properties</code> 在容器启动后会自动包含该设置。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &quot;offsets.topic.replication.factor=1&quot; &gt;&gt; /etc/confluent/docker/kafka.properties.template</span><br></pre></td></tr></table></figure>
<p>重启 Kafka 容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker restart docker_kafka_1</span><br></pre></td></tr></table></figure>


<h2 id="API-Examples"><a href="#API-Examples" class="headerlink" title="API Examples"></a>API Examples</h2><h3 id="Group-Hermes-Management"><a href="#Group-Hermes-Management" class="headerlink" title="Group (Hermes Management)"></a>Group (Hermes Management)</h3><ul>
<li>创建组</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://172.16.18.143:8090/groups \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;&#123;</span><br><span class="line">    &quot;groupName&quot;: &quot;my-group&quot;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>


<h3 id="Topic-Hermes-Management"><a href="#Topic-Hermes-Management" class="headerlink" title="Topic (Hermes Management)"></a>Topic (Hermes Management)</h3><ul>
<li>创建主题</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://172.16.18.143:8090/topics \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;&#123;</span><br><span class="line">    &quot;name&quot;: &quot;my-group.my-topic&quot;,</span><br><span class="line">    &quot;description&quot;: &quot;This is my topic&quot;,</span><br><span class="line">    &quot;contentType&quot;: &quot;JSON&quot;,</span><br><span class="line">    &quot;retentionTime&quot;: &#123;</span><br><span class="line">        &quot;duration&quot;: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;owner&quot;: &#123;</span><br><span class="line">        &quot;source&quot;: &quot;Plaintext&quot;,</span><br><span class="line">        &quot;id&quot;: &quot;MyTeam&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>


<h3 id="Subscription-Hermes-Management"><a href="#Subscription-Hermes-Management" class="headerlink" title="Subscription (Hermes Management)"></a>Subscription (Hermes Management)</h3><ul>
<li><p>创建订阅钩子端点（可以使用任何技术实现）</p>
<blockquote>
<p>本示例使用 nodejs，将以下代码保存到文件 <code>hermes-subendpoint.js</code></p>
</blockquote>
</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> bodyParser = <span class="built_in">require</span>(<span class="string">&#x27;body-parser&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> app = express()</span><br><span class="line"></span><br><span class="line">app.use(bodyParser.json()); <span class="comment">// for parsing application/json</span></span><br><span class="line">app.use(bodyParser.urlencoded(&#123; <span class="attr">extended</span>: <span class="literal">true</span> &#125;)); <span class="comment">// for parsing application/x-www-form-urlencoded</span></span><br><span class="line"></span><br><span class="line">app.post(<span class="string">&#x27;/&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">&#x27;Request Body:&#x27;</span>, req.body);</span><br><span class="line">  res.send(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line">app.get(<span class="string">&#x27;/&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">  res.send(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> server = app.listen(<span class="number">8081</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> host = server.address().address</span><br><span class="line">  <span class="keyword">var</span> port = server.address().port</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>运行</p>
</blockquote>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">npm install express --save</span><br><span class="line">npm install body-parser --save</span><br><span class="line"></span><br><span class="line"><span class="comment">// start </span></span><br><span class="line">node hermes-subendpoint.js</span><br></pre></td></tr></table></figure>
<blockquote>
<p>测试</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://localhost:8081/ \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;&#123;</span><br><span class="line">	&quot;a&quot;:1</span><br><span class="line">	&#125;&#x27;</span><br></pre></td></tr></table></figure>
<p>钩子端点控制台输出：<code>Request Body: &#123; a: 1 &#125;</code></p>
<ul>
<li>创建订阅</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://172.16.18.143:8090/topics/my-group.my-topic/subscriptions \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;&#123;</span><br><span class="line">    &quot;topicName&quot;: &quot;my-group.my-topic&quot;,</span><br><span class="line">    &quot;name&quot;: &quot;my-Subscription&quot;, </span><br><span class="line">    &quot;description&quot;: &quot;This is my subscription&quot;,</span><br><span class="line">    &quot;endpoint&quot;: &quot;http://172.16.18.1:8081/&quot;, </span><br><span class="line">    &quot;owner&quot;: &#123;</span><br><span class="line">        &quot;source&quot;: &quot;Plaintext&quot;,</span><br><span class="line">        &quot;id&quot;: &quot;MyTeam&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>


<h3 id="Publish-Hermes-Frontend"><a href="#Publish-Hermes-Frontend" class="headerlink" title="Publish (Hermes-Frontend)"></a>Publish (Hermes-Frontend)</h3><ul>
<li>发布消息</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://172.16.18.143:8080/topics/my-group.my-topic \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;&#123;</span><br><span class="line">    &quot;message&quot;: &quot;Hello world!&quot;,</span><br><span class="line">    &quot;more&quot;: &quot;1112223334444555&quot;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>
<p>钩子端点控制台输出：</p>
<p><code>Request Body: &#123; message: &#39;Hello world!&#39;, more: &#39;1112223334444555&#39; &#125;</code></p>
<p>（待续）</p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>EventBroker</tag>
        <tag>Hermes</tag>
        <tag>Kafka</tag>
        <tag>Push</tag>
        <tag>Webhook</tag>
      </tags>
  </entry>
  <entry>
    <title>Event Broker Nakadi Notes</title>
    <url>/2020/02/18/event-broker-nakadi-notes/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Nakadi 的目标是提供一个事件经纪人基础设施，以便:</p>
<ul>
<li><p>通过安全的 RESTful API 进行抽象事件交付</p>
<p>这允许微服务团队维护服务边界，而不直接依赖于任何特定的消息代理技术。 可以为每个事件类型单独管理访问权限，并使用 OAuth 和自定义授权插件进行保护。</p>
</li>
<li><p>支持事件驱动应用程序和异步微服务的方便开发</p>
<p>可以使用事件类型架构定义事件类型，并通过注册表进行管理。 在发布事件类型之前，将根据模式验证所有事件。 它为数据使用者提供了数据质量和数据一致性的保证。</p>
</li>
<li><p>有效的低延迟事件传递</p>
<p>一旦发布者使用简单的 Http Post 发送事件，就可以通过流式 HTTP 连接推送到消费者，从而实现接近实时的事件处理。消费者连接具有保持活力控制并支持使用订阅管理流偏移量。</p>
</li>
</ul>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><h3 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h3><ul>
<li>类似 Kafka 队列上的 REST 抽象</li>
<li>事件类型的CRUD</li>
<li>事件批量发布</li>
<li>Low-level API（消费）<ul>
<li>手动的客户端分区管理</li>
<li>不支持提交</li>
</ul>
</li>
<li>High-level API（订阅）<ul>
<li>在消费者客户端之间自动重新分配分区</li>
<li>支持提交，移动服务器端游标</li>
</ul>
</li>
</ul>
<h3 id="Schema"><a href="#Schema" class="headerlink" title="Schema"></a>Schema</h3><ul>
<li><p>模式注册表</p>
</li>
<li><p>模式进化</p>
</li>
<li><p>事件类型类别</p>
<blockquote>
<p>categories: 每个事件类别为一个事件类型启用不同的功能，特别是它们的模式和验证规则</p>
</blockquote>
<ul>
<li><strong>Business</strong> 作为业务流程的一部分或驱动业务流程的事件，如客户订单中的状态转换。</li>
<li><strong>Data Change</strong> 表示对记录或其他项或新项的更改的事件。 更改事件与创建、更新、删除或快照操作相关联。</li>
<li><strong>Undefined</strong> 适用于生产者完全自定义的事件的自由格式类别。</li>
</ul>
</li>
<li><p>分区策略（Random/Hash/User Defined）</p>
<ul>
<li><strong>Random</strong> 分区是随机选择的，事件将均匀地分布在分区之间。 Nakadi 使用的默认选项是 Random。</li>
<li><strong>Hash</strong> 通过对事件类型的 <code>partition_key_fields</code>中定义的字段值进行哈希处理来选择分区。 在实践中，这意味着那些大致相同的逻辑实体和具有相同的分区键值的事件将被发送到相同的分区。</li>
<li><strong>user_defined</strong> 分区由生产者在发送事件时设置。 此选项仅适用于 <code>business</code>和 <code>data change</code> 类别。</li>
</ul>
</li>
<li><p>事件强化策略</p>
</li>
<li><p>事件验证（通过模式）</p>
</li>
</ul>
<h3 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h3><ul>
<li>OAuth2 认证</li>
<li>事件类型授权</li>
<li>黑名单</li>
</ul>
<h3 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h3><ul>
<li>Timelines<ul>
<li>允许透明地将生产和消费切换到不同的集群(tier、region、 AZ) ，而不会移动实际数据和任何服务降级</li>
<li>为其他流媒体技术和引擎的实现提供了可能(比如 AWS Kinesis，Google pub / sub 等等)</li>
</ul>
</li>
</ul>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Nakadi API 允许通过 HTTP 发布和消费事件。</p>
<p>理解事件的一个好方法是，它们类似于流处理或队列系统中的消息，但具有可以理解和验证的定义结构。 包含描述事件的信息的对象称为事件类型。</p>
<p>要发布和消费事件，拥有事件的应用程序必须首先向 Nakadi 注册一个新的事件类型。 事件类型包含诸如其名称、应用程序、分区和丰富数据的策略以及 JSON 模式等信息。 Nakadi 支持列出所有可用事件类型的事件类型注册表 API。</p>
<p>一旦创建了事件类型，称为流的资源就可用于该事件类型。 流将接受来自生产者的类型的事件，并且一个或多个消费者可以从中读取。 Nakadi 可以验证发送到流的每个事件。</p>
<p>事件类型的流可以划分为一个或多个分区。 每个事件被精确地放置到一个分区中。 每个分区代表一个有序的日志——一旦一个事件被添加到一个分区中，它的位置永远不会改变，但是没有跨分区的全局排序。</p>
<p>消费者可以使用分配给每个分区的游标读取事件并跟踪它们在流中的位置。 消费者还可以使用光标从特定位置的流中读取数据。 多个使用者可以从同一个流中读取，允许不同的应用程序同时读取流。</p>
<h3 id="事件应用分类"><a href="#事件应用分类" class="headerlink" title="事件应用分类"></a>事件应用分类</h3><ul>
<li><p><strong>Event Type Owners</strong> 事件类型所有者通过事件类型注册表与 Nakadi 交互，以基于模式定义事件类型并创建事件流。</p>
</li>
<li><p><strong>Event Producers</strong> 生产者将符合事件类型模式的事件发布到事件类型的流。</p>
</li>
<li><p><strong>Event Consumers</strong> 消费者从事件流中读取事件，多个消费者可以从同一流中读取数据。</p>
</li>
</ul>
<h3 id="Cursors-Offsets-Partitiions（游标-偏移量-分区）"><a href="#Cursors-Offsets-Partitiions（游标-偏移量-分区）" class="headerlink" title="Cursors, Offsets, Partitiions（游标, 偏移量, 分区）"></a>Cursors, Offsets, Partitiions（游标, 偏移量, 分区）</h3><p>默认情况下，事件资源将从事件类型的所有分区和流的末端(或“尾端”)消耗。 要只选择特定的分区和流中要开始的位置，可以在请求中提供 X-Nakadi-Cursors 标头:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -v http:&#x2F;&#x2F;localhost:8080&#x2F;event-types&#x2F;order.ORDER_RECEIVED&#x2F;events \</span><br><span class="line">  -H &#39;X-Nakadi-Cursors: [&#123;&quot;partition&quot;: &quot;0&quot;, &quot;offset&quot;:&quot;12&quot;&#125;]&#39;</span><br></pre></td></tr></table></figure>
<p>标头值是游标的 JSON 数组。 数组中的每个游标描述流的分区和从中流出的偏移量。 请注意，同一个分区中的事件保持了它们的总体顺序。</p>
<p>光标的偏移量值允许您选择要从流中的哪个位置使用。 这可以是任何已知的偏移量值，也可以是将从头开始启动流的专用值 BEGIN。 例如，从分区0开始读:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -v http:&#x2F;&#x2F;localhost:8080&#x2F;event-types&#x2F;order.ORDER_RECEIVED&#x2F;events \</span><br><span class="line">  -H &#39;X-Nakadi-Cursors:[&#123;&quot;partition&quot;: &quot;0&quot;, &quot;offset&quot;:&quot;BEGIN&quot;&#125;]&#39;</span><br></pre></td></tr></table></figure>


<h3 id="Event-Stream-Keepalives-事件流保活"><a href="#Event-Stream-Keepalives-事件流保活" class="headerlink" title="Event Stream Keepalives 事件流保活"></a>Event Stream Keepalives 事件流保活</h3><p>如果没有事件需要发送，Nakadi 将通过定期发送一个没有事件但包含指向当前偏移量的指针的批处理来保持流连接打开。 例如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -v http:&#x2F;&#x2F;localhost:8080&#x2F;event-types&#x2F;order.ORDER_RECEIVED&#x2F;events </span><br><span class="line">      </span><br><span class="line"></span><br><span class="line">HTTP&#x2F;1.1 200 OK</span><br><span class="line"></span><br><span class="line">&#123;&quot;cursor&quot;:&#123;&quot;partition&quot;:&quot;0&quot;,&quot;offset&quot;:&quot;6&quot;&#125;,&quot;events&quot;:[&#123;&quot;order_number&quot;: &quot;ORDER_003&quot;, &quot;metadata&quot;: &#123;&quot;eid&quot;: &quot;4cc6d2f0-eb01-11e5-b606-1c6f65464fc6&quot;, &quot;occurred_at&quot;: &quot;2016-03-15T23:58:15+01:00&quot;&#125;&#125;]&#125;</span><br><span class="line">&#123;&quot;cursor&quot;:&#123;&quot;partition&quot;:&quot;0&quot;,&quot;offset&quot;:&quot;6&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;cursor&quot;:&#123;&quot;partition&quot;:&quot;0&quot;,&quot;offset&quot;:&quot;6&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;cursor&quot;:&#123;&quot;partition&quot;:&quot;0&quot;,&quot;offset&quot;:&quot;6&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;cursor&quot;:&#123;&quot;partition&quot;:&quot;0&quot;,&quot;offset&quot;:&quot;6&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：该示例为 Low-level API 已被否决，并将从未来的 Nakadi 版本中删除。 请考虑使用高级别的 API。</p>
</blockquote>
<h3 id="Timelines"><a href="#Timelines" class="headerlink" title="Timelines"></a>Timelines</h3><p>时间线的创建是使用 Zookeeper 通过一系列的锁（Locks）和屏障（Barriers）来协调的。 </p>
<ol>
<li>初始状态</li>
</ol>
<p>每次启动 Nakadi 应用程序时，它都会尝试创建以下 ZK 结构。为了不覆盖初始结构，由于并发性，每个实例在执行之前都需要获取锁 <code>/nakadi/timelines/lock</code>。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">timelines:</span></span><br><span class="line">  <span class="attr">lock:</span> <span class="bullet">-</span>                    <span class="string">lock</span> <span class="string">for</span> <span class="string">timeline</span> <span class="string">versions</span> <span class="string">synchronization</span></span><br><span class="line">  <span class="attr">version:</span> &#123;<span class="string">version</span>&#125;      <span class="string">monotonically</span> <span class="string">incremented</span> <span class="string">long</span> <span class="string">value</span> <span class="string">(version</span> <span class="string">of</span> <span class="string">timelines</span> <span class="string">configuration)</span></span><br><span class="line">  <span class="attr">locked_et:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">nodes:</span>                    <span class="string">nakadi</span> <span class="string">nodes</span></span><br><span class="line">    <span class="attr">node1:</span> &#123;<span class="string">version</span>&#125;    <span class="string">Each</span> <span class="string">nakadi</span> <span class="string">node</span> <span class="string">exposes</span> <span class="string">the</span> <span class="string">version</span> <span class="string">used</span> <span class="string">on</span> <span class="string">this</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">node2:</span> &#123;<span class="string">version</span>&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>为 <code>et_1</code> 创建时间线</li>
</ol>
<p>当创建一个新的时间线时，第一步是通过在 <code>/timelines/locked_et/et_1</code> 上创建一个临时节点来获得更新时间线的锁。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">timelines:</span></span><br><span class="line">  <span class="attr">lock:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">0</span></span><br><span class="line">  <span class="attr">locked_et:</span></span><br><span class="line">    <span class="attr">et_1:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">nodes:</span></span><br><span class="line">    <span class="attr">node1:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">node2:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<ol start="3">
<li>通知所有 Nakadi 节点相关更改：版本屏障</li>
</ol>
<p>协调创建时间线的实例修改版本节点，所有 Nakadi 实例都在监听变化，因此当发生变化时，它们会得到通知。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">timelines:</span></span><br><span class="line">  <span class="attr">lock:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">1</span>       <span class="comment"># this is incremented by 1</span></span><br><span class="line">  <span class="attr">locked_et:</span></span><br><span class="line">    <span class="attr">et_1:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">nodes:</span></span><br><span class="line">    <span class="attr">node1:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">node2:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<ol start="4">
<li>等待所有节点对新版本作出反应</li>
</ol>
<p>每个 Nakadi 实例监视 <code>/nakadi/timelines/version/</code> 的值。 当它发生更改时，每个实例检查所有锁定的事件类型，并通过在本地释放或阻塞发布者来做出相应的反应。一旦每个实例更新了它本地的锁定事件类型列表，它就会添加自己的版本，让时间线创建者发起者知道它可以处理。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">timelines:</span></span><br><span class="line">  <span class="attr">lock:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">1</span> </span><br><span class="line">  <span class="attr">locked_et:</span></span><br><span class="line">     <span class="attr">et_1:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">nodes:</span></span><br><span class="line">    <span class="attr">node1:</span> <span class="number">1</span>       <span class="comment"># each instance updates its own version</span></span><br><span class="line">    <span class="attr">node2:</span> <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="5">
<li>更改数据库</li>
</ol>
<p>一旦所有实例都作出反应，创建过程继续进行，发起者在 <code>timeline</code> 表中插入必要的数据库条目，并对现有存储进行快照显示可用的最新偏移量。 它还在新存储中创建一个主题。 请注意，如果从未使用过时间线分区，则存储的偏移量为 -1。 如果只有一个事件，则偏移量为 0，依此类推。</p>
<ol start="6">
<li>移除锁并再次通知所有实例</li>
</ol>
<p>按照初始状态创建时间线的相同逻辑，锁将被删除，版本将被修改。 所有 Nakadi 实例的处理是移除本地锁并在必要时切换时间线。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">timelines:</span></span><br><span class="line">  <span class="attr">lock:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span> </span><br><span class="line">  <span class="attr">locked_et:</span>     </span><br><span class="line">  <span class="attr">nodes:</span></span><br><span class="line">    <span class="attr">node1:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">node2:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>在每个实例处理之后，它看起来应该像：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">timelines:</span></span><br><span class="line">  <span class="attr">lock:</span> <span class="bullet">-</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span> </span><br><span class="line">  <span class="attr">locked_et:</span></span><br><span class="line">  <span class="attr">nodes:</span></span><br><span class="line">    <span class="attr">node1:</span> <span class="number">2</span>       <span class="comment"># each instance updates its own version</span></span><br><span class="line">    <span class="attr">node2:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>
<ul>
<li>至此，一个新的时间线创建成功。</li>
</ul>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;zalando&#x2F;nakadi.git</span><br></pre></td></tr></table></figure>


<h3 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd nakadi</span><br><span class="line">docker-compose up </span><br></pre></td></tr></table></figure>


<p>启动成功后，各服务端口：</p>
<ul>
<li><code>8080</code> - API Server</li>
<li><code>5432</code> - PostgreSQL</li>
<li><code>9092</code>, <code>29092</code> - Kafka</li>
<li><code>2181</code> - Zookeeper</li>
</ul>
<h2 id="API-示例"><a href="#API-示例" class="headerlink" title="API 示例"></a>API 示例</h2><ul>
<li><p>创建事件类型</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://172.16.18.143:8080/event-types \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;&#123;</span><br><span class="line">  &quot;name&quot;: &quot;order.ORDER_RECEIVED&quot;,</span><br><span class="line">  &quot;owning_application&quot;: &quot;order-service&quot;,</span><br><span class="line">  &quot;category&quot;: &quot;undefined&quot;,</span><br><span class="line">  &quot;schema&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;json_schema&quot;,</span><br><span class="line">    &quot;schema&quot;: &quot;&#123; \&quot;additionalProperties\&quot;: true &#125;&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>
<p><a href="https://nakadi.io/manual.html#/event-types_post">API 用法</a></p>
</li>
<li><p>添加订阅</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://172.16.18.143:8080/subscriptions \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;&#123;</span><br><span class="line">	&quot;owning_application&quot;: &quot;abc&quot;,</span><br><span class="line">	&quot;event_types&quot;: [&quot;order.ORDER_RECEIVED&quot;]</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>
<p><a href="https://nakadi.io/manual.html#/subscriptions_post">API 用法</a></p>
</li>
</ul>
<ul>
<li><p>发布消息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http://172.16.18.143:8080/event-types/order.ORDER_RECEIVED/events \</span><br><span class="line">  -H &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">  -d &#x27;[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;order_number&quot;: &quot;24873243241&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;order_number&quot;: &quot;24873243242&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]&#x27;</span><br></pre></td></tr></table></figure>
<p><a href="https://nakadi.io/manual.html#/event-types/name/events_post">API 用法</a></p>
</li>
<li><p>订阅消费</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X GET http://172.16.18.143:8080/subscriptions/&#123;subscription_id&#125;/events</span><br></pre></td></tr></table></figure>
<p><a href="https://nakadi.io/manual.html#/subscriptions/subscription_id/events_get">API 用法</a></p>
</li>
</ul>
<h2 id="部署-UI（可选）"><a href="#部署-UI（可选）" class="headerlink" title="部署 UI（可选）"></a>部署 UI（可选）</h2><blockquote>
<p><a href="https://github.com/zalando-nakadi/nakadi-ui">https://github.com/zalando-nakadi/nakadi-ui</a></p>
</blockquote>
<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -it -d -p 3000:3000 -e NAKADI_API_URL=http://172.16.18.1:8080 -e BASE_URL=http://172.16.18.143:3000 nakadi/nakadi-ui:latest</span><br></pre></td></tr></table></figure>


<p>（待续）</p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>Kafka</tag>
        <tag>Event Broker</tag>
        <tag>Nakadi</tag>
        <tag>HttpStream</tag>
      </tags>
  </entry>
  <entry>
    <title>「数学之美」书摘</title>
    <url>/2017/11/22/excerpts-of-the-beauty-of-mathematics/</url>
    <content><![CDATA[<p>本文主要摘自「数学之美」（第二版）的关键内容，摘取内容与原书相比肯定不够全面。如果对此书内容感兴趣，强烈建议阅读原书。</p>
<p><img src="/images/book-cover/beauty-of-mathematics.jpg" alt="image"></p>
<p>以下为摘取内容（为了辅助说明，部分内容同时引用了相关网络资源，均有出处链接）：</p>
<p><strong>文字和语言与数学，从产生起原本就有相通性，虽然它们的发展一度分道扬镳，但是最终还是能走在一起。</strong></p>
<p><strong>人类对机器理解自然语言的认识走了一条大弯路。早起的研究中采用基于规则的方法，虽然解决了一些简单的问题，但是无法从根本上将自然语言理解实用化。直到多年以后，人们开始尝试基于统计的方法进行自然语言处理，才有了突破性进展和实用的产品。</strong></p>
<p><strong>统计语言模型是自然语言处理的基础，并且被广泛应用于机器翻译、语音识别、印刷体或手写体识别、拼写纠错、汉字输入和文献查询。</strong></p>
<p><strong>中文分词是中文信息处理的基础，它同样走过了一段弯路，目前依靠统计语言模型已经基本解决了这个问题。</strong></p>
<p><strong>隐含马尔可夫模型最初应用于通信领域，继而推广到语音和语言处理中，成为连接自然语言处理和通信的桥梁。同时，隐含马尔可夫模型也是机器学习的主要工具之一。</strong></p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B">WIKI：隐马尔可夫模型</a></p>
<p>隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。</p>
<p>在正常的马尔可夫模型中，状态对于观察者来说是直接可见的。这样状态的转换概率便是全部的参数。而在隐马尔可夫模型中，状态并不是直接可见的，但受状态影响的某些变量则是可见的。每一个状态在可能输出的符号上都有一概率分布。因此输出符号的序列能够透露出状态序列的一些信息。</p>
</blockquote>
<p><strong>信息是可以量化度量的。信息熵不仅是对信息的量化度量，也是整个信息论的基础。它对于通信、数据压缩、自然语言处理都有很强的指导意义。</strong></p>
<p><strong>作为现代自然语言处理的奠基者，贾里尼克教授成功地将数学原理应用于自然语言处理领域中，他的一生富于传奇色彩。</strong></p>
<p><strong>布尔代数虽然非常简单，却是计算机科学的基础，它不仅把逻辑和数学合二为一，而且给了我们一个全新的视角看待世界，开创了数字化时代。</strong></p>
<p><strong>互联网搜索引擎在建立索引前需要用一个程序自动地将所有的网页下载到服务器上，这个程序称为网络爬虫。它的编写是基于离散数学中图论的原理。</strong></p>
<p>图论：图由一些节点和连接这些节点的弧组成。网络爬虫基于图论进行网页下载。</p>
<ul>
<li>BFS (Breadth-First Search)，广度优先搜索。</li>
<li>DFS (Depth-First Search)：深度优先搜索。</li>
</ul>
<p><strong>PageRank：网页民主排名。</strong></p>
<p>核心思想为：如果一个网页被很多网页所链接，说明它受到普遍的承认和信赖，那么它的排名就高。</p>
<p><strong>TF-IDF：网页与查询相关性度量。</strong></p>
<ul>
<li>TF：Term Frequency，词频。</li>
<li>IDF：Inverse Document Frequency，逆文本频率指数。信息检索中使用最多的权重。</li>
</ul>
<blockquote>
<p><a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html">阮一峰的网络日志『TF-IDF与余弦相似性的应用（一）：自动提取关键词』</a></p>
<p>第一步，计算词频。</p>
<p>考虑到文章有长短之分，为了便于不同文章的比较，进行“词频”标准化。</p>
<p><code>词频（TF）= 某个词在文章中的出现次数 / 文章总词数 </code></p>
<p>第二步，计算逆文档频率。</p>
<p>这时，需要一个语料库（corpus），用来模拟语言的使用环境。</p>
<p><code>逆文档频率（IDF）= log(语料库的文档总数 / 包含该词的文档数 + 1)</code></p>
<p>如果一个词越常见，那么分母就越大，逆文档频率就越小越接近 0 。分母之所以要加 1，是为了避免分母为 0（即所有文档都不包含该词）。log表示对得到的值取对数。</p>
<p>第三步，计算 TF-IDF。</p>
<p><code>TF-IDF = 词频(TF) * 逆文档频率(IDF)</code></p>
<p>可以看到，TF-IDF 与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。</p>
</blockquote>
<p><strong>地图和本地服务中要用到有限状态机和动态规划技术。这两项技术是机器智能和机器学习的工具，它们的应用非常广泛，还包括语音识别、拼写和语法纠错、拼音输入法、工业控制和生物的序列分析等。</strong></p>
<p>「地址」是种有限状态机，导航的关键算法是图论中的动态规划。</p>
<blockquote>
<p><a href="https://zh.wikipedia.org/wiki/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA">WIKI：有限状态机</a></p>
<p>有限状态机（Finite-State Machine，FSM）又称有限状态自动机，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。</p>
<p>在计算机科学中，有限状态机被广泛用于建模应用行为、硬件电路系统设计、软件工程、编译器、网络协议和计算与语言的研究。</p>
<p><a href="https://zh.wikipedia.org/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92">WIKI：动态规划</a></p>
<p>动态规划在查找有很多<strong>重叠子问题</strong>的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并被保存，从简单的问题直到整个问题都被解决。因此，动态规划保存递归时的结果，因而不会在解决同样的问题时花费时间。</p>
<p>动态规划只能应用于有<strong>最优子结构</strong>的问题。最优子结构的意思是局部最优解能决定全局最优解（对有些问题这个要求并不能完全满足，故有时需要引入一定的近似）。简单地说，问题能够分解成子问题来解决。</p>
</blockquote>
<p><strong>辛格做事的哲学：先帮助用户解决 80% 的问题，再慢慢解决剩下的 20% 问题，是在工业界成功的秘诀之一。</strong></p>
<p><strong>计算机虽然读不懂新闻，却可以准确地对新闻进行分类。其数学工具是看似毫不相干的余弦定理。</strong></p>
<blockquote>
<p><a href="http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html">阮一峰的网络日志『TF-IDF与余弦相似性的应用（二）：找出相似文章』</a></p>
<p>因此，我们可以通过夹角的大小，来判断向量的相似程度。夹角越小，就代表越相似。</p>
<p>余弦值越接近 1，就表明夹角越接近 0 度，也就是两个向量越相似，这就叫“余弦相似性”。</p>
<ol>
<li>使用 TF-IDF 算法，找出两篇文章的关键字；</li>
<li>每篇文章各取出若干个关键词（比如 20 个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；</li>
<li>生成两篇文章各自的词频向量；</li>
<li>计算两个向量的余弦相似度，值越大就表示越相似。</li>
</ol>
<p>“余弦相似性”是一种非常有用的算法，只要是计算两个向量的相似程度，都可以采用它。</p>
</blockquote>
<p><strong>无论是词汇的聚类还是文本的分类，都可以通过线性代数中矩阵的奇异值分解来进行。这样一来，自然语言处理的问题就变成了一个数学问题。</strong></p>
<p><strong>世间万物都有一个唯一标识的特征，信息也是如此。每一条信息都有它特定的指纹，通过这个指纹可以区别不同的信息。</strong></p>
<p><strong>密码学的根本是信息论和数学。没有信息论指导的密码是非常容易被破解的。只有在信息论被广泛应用于密码学后，密码才真正变得安全。</strong></p>
<p><strong>搜索引擎中排名靠前的网页也未必是有用的网页。消除这些作弊网页的原理和通信中过滤噪音的原理相同。</strong></p>
<p><strong>正确的数学模型在科学和工程中至关重要，而发现正确模型的途径常常是曲折的。正确的模型在形式上通常是简单的。</strong></p>
<p><strong>最大熵模型是一个完美的数学模型。它可以将各种信息整合到一个统一的模型中，在信息处理和机器学习中有着广泛的应用。它在形式上非常简单、优美，而在实现时需要有精深的数学基础和高超的技巧。</strong></p>
<p><strong>汉字的输入过程本身就是人和计算机之间的通信。好的输入法会自觉或不自觉地遵循通信的数学模型。当然要做出最有效的输入法，应当自觉使用信息论做指导。</strong></p>
<p><strong>将自然语言处理从基于规则的研究方法转到基于统计的研究方法上，宾夕法尼亚大学的教授米奇·马库斯功不可没。他创立了今天在学术界广泛使用的 LCD 语料库，同时培养了一大批精英人物。</strong></p>
<p><strong>判断一个元素是否在一个集合中，布隆过滤器是计算机工程中解决这个问题最好的数学工具。</strong></p>
<p><strong>贝叶斯网络是一个加权的有向图，是马尔可夫链的扩展。而从认识论的层面看：贝叶斯网络克服了马尔可夫链那种机械的线性约束，它可以把任何有关联的事件统一到它的框架下面。它在生物统计、图像处理、决策支持系统和博弈论中都有广泛的使用。</strong></p>
<p><strong>条件随机场是计算联合概率分布的有效模型，而句法分析似乎是英文课上英语老师教的东西，这两者有什么联系呢？</strong></p>
<p><strong>维特比算法是现代数字通信中使用最频繁的算法，同时也是很多自然语言处理的解码算法。可以毫不夸张地讲，维特比是对我们今天生活的影响力最大的科学家之一。因为如今基于 CDMA 的 3G 移动通信标准主要就是他创办的高通公司制定的。</strong></p>
<p><strong>只要有一些训练数据，再定义一个最大化函数，采用 EM 算法，利用计算机经过若干次迭代，就可以得到所需要的模型。这实在是太美妙了，这也许是我们的造物主刻意安排的。所以我把它称作上帝的算法。</strong></p>
<p><strong>逻辑回归模型是一种将影响概率的不同因素结合在一起的指数模型，它不仅在搜索广告中起着重要的作用，而且被广泛应用于信息处理和生物统计中。</strong></p>
<p><strong>Google 颇为神秘的云计算中最重要的 MapReduce 工具，其原理就是计算机算法中常用的“各个击破”算法，它的原理原来这么简单——将复杂的大问题分解成很多小问题分别求解，然后再把小问题的解合并成原始问题的解。由此可见，在生活中大量用到的、真正有用的方法常常都是简单朴实的。</strong></p>
<p><strong>Google 大脑并不是一个什么都能思考的大脑，而是一个很能计算的人工神经网络。因此，与其说 Google 大脑很聪明，不如说它很能算。不过，换个角度来说，随着计算能力的不断提高，计算量大但简单的数学方法有时能够解决很复杂的问题。</strong></p>
<p><strong>如果说在过去的 40 年里，主导全球 IT 产业发展的是摩尔定律，那么在今后的 20 年里，主导 IT 行业继续发展的动力则将来自于数据。</strong></p>
]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Practice - Getting Started</title>
    <url>/2017/10/23/git-practice-getting-started/</url>
    <content><![CDATA[<h2 id="Start-a-working-area"><a href="#Start-a-working-area" class="headerlink" title="Start a working area"></a>Start a working area</h2><h3 id="init"><a href="#init" class="headerlink" title="init"></a>init</h3><ul>
<li><p>在当前目录[指定目录]初始化工作空间</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git init [&lt;dir&gt;]</span><br></pre></td></tr></table></figure>
<h3 id="clone"><a href="#clone" class="headerlink" title="clone"></a>clone</h3></li>
<li><p>将指定工作空间拷贝到当前目录[指定目录]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone &lt;repo&gt; [&lt;dir&gt;]</span><br></pre></td></tr></table></figure>
<h2 id="Work-on-the-current-change"><a href="#Work-on-the-current-change" class="headerlink" title="Work on the current change"></a>Work on the current change</h2></li>
</ul>
<h3 id="add"><a href="#add" class="headerlink" title="add"></a>add</h3><ul>
<li><p>将文件添加到中转区（路径/文件名）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add octocat.txt </span><br></pre></td></tr></table></figure></li>
<li><p>将文件添加到中转区（文件通配符，匹配到的文件都将会添加到中转区）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add &#39;*.txt&#39;</span><br></pre></td></tr></table></figure>
<h3 id="reset"><a href="#reset" class="headerlink" title="reset"></a>reset</h3></li>
<li><p>将HEAD重置到某一个状态（路径/文件名，若不指定则对所有提交生效）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git reset octofamily&#x2F;octodog.txt</span><br></pre></td></tr></table></figure>
<h3 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h3></li>
<li><p>删除指定文件（文件名/文件通配符）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git rm &#39;*.txt&#39;</span><br></pre></td></tr></table></figure>
<h2 id="Examine-the-history-and-state"><a href="#Examine-the-history-and-state" class="headerlink" title="Examine the history and state"></a>Examine the history and state</h2></li>
</ul>
<h3 id="status"><a href="#status" class="headerlink" title="status"></a>status</h3><ul>
<li><p>查看当前仓库状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure>
<h3 id="log"><a href="#log" class="headerlink" title="log"></a>log</h3></li>
<li><p>查看仓库变更日志</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git log</span><br></pre></td></tr></table></figure>
<h2 id="Grow-mark-and-tweak-your-common-history"><a href="#Grow-mark-and-tweak-your-common-history" class="headerlink" title="Grow, mark and tweak your common history"></a>Grow, mark and tweak your common history</h2></li>
</ul>
<h3 id="commit"><a href="#commit" class="headerlink" title="commit"></a>commit</h3><ul>
<li><p>将中转区的变更提交到仓库（说明内容）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git commit -m &quot;Add cute octocat story&quot; </span><br></pre></td></tr></table></figure>
<h3 id="checkout"><a href="#checkout" class="headerlink" title="checkout"></a>checkout</h3></li>
<li><p>切换分支（–路径/文件名）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git checkout --octocat.txt</span><br></pre></td></tr></table></figure></li>
<li><p>切换分支（&lt;分支名称&gt;）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git checkout &lt;BranchName&gt;</span><br></pre></td></tr></table></figure>
<h3 id="branch"><a href="#branch" class="headerlink" title="branch"></a>branch</h3></li>
<li><p>创建分支（&lt;分支名称&gt;）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git branch &lt;BranchName&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>删除分支（&lt;分支名称&gt;）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git branch -d &lt;BranchName&gt;</span><br></pre></td></tr></table></figure>
<h3 id="diff"><a href="#diff" class="headerlink" title="diff"></a>diff</h3></li>
<li><p>查看更改差异：查看上次提交的不同之处</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git diff</span><br></pre></td></tr></table></figure></li>
<li><p>查看更改差异：HEAD为最新提交指针代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git diff HEAD</span><br></pre></td></tr></table></figure></li>
<li><p>查看更改差异：查看中转区的更改差异</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git diff --staged</span><br></pre></td></tr></table></figure>
<h3 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h3></li>
<li><p>合并其他分支到当前分支（&lt;其他分支名称&gt;）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git merge &lt;BranchName&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Collaborate"><a href="#Collaborate" class="headerlink" title="Collaborate"></a>Collaborate</h2></li>
</ul>
<h3 id="push"><a href="#push" class="headerlink" title="push"></a>push</h3><ul>
<li>将本地分支推送到远程仓库（&lt;远程仓库名称&gt; &lt;本地分支名称&gt;）<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git push -u &lt;origin&gt; &lt;master&gt;</span><br></pre></td></tr></table></figure></li>
<li>u告诉Git记住参数，这样下次我们可以简单地运行git push</li>
</ul>
<h3 id="pull"><a href="#pull" class="headerlink" title="pull"></a>pull</h3><ul>
<li>拉取远程仓库变更到本地分支（&lt;远程仓库名称&gt; &lt;本地分支名称&gt;）<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git pull &lt;origin&gt; &lt;master&gt;</span><br></pre></td></tr></table></figure>
<h3 id="remote"><a href="#remote" class="headerlink" title="remote"></a>remote</h3></li>
</ul>
<h4 id="remote-add"><a href="#remote-add" class="headerlink" title="remote add"></a>remote add</h4><ul>
<li>添加远程仓库（&lt;远程仓库名称&gt; &lt;远程仓库地址&gt;）<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git remote add &lt;origin&gt; &lt;https:&#x2F;&#x2F;github.com&#x2F;try-git&#x2F;try_git.git&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>SCM</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Gitlab CE 服务部署及简单使用</title>
    <url>/2020/01/07/gitlab-ce-service-setup-and-trial/</url>
    <content><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo docker run --detach \</span><br><span class="line">  --hostname gitlab.example.com \</span><br><span class="line">  --publish 9443:443 --publish 9080:80 --publish 9022:22 \</span><br><span class="line">  --name gitlab \</span><br><span class="line">  --restart always \</span><br><span class="line">  --volume &#x2F;opt&#x2F;gitlab&#x2F;config:&#x2F;etc&#x2F;gitlab \</span><br><span class="line">  --volume &#x2F;opt&#x2F;gitlab&#x2F;logs:&#x2F;var&#x2F;log&#x2F;gitlab \</span><br><span class="line">  --volume &#x2F;opt&#x2F;gitlab&#x2F;data:&#x2F;var&#x2F;opt&#x2F;gitlab \</span><br><span class="line">  gitlab&#x2F;gitlab-ce:latest</span><br></pre></td></tr></table></figure>
<h2 id="DNS-Or-hosts"><a href="#DNS-Or-hosts" class="headerlink" title="DNS Or hosts"></a>DNS Or hosts</h2><p>配置域名解析或在客户端配置主机别名。</p>
<p>主机别名示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">172.16.18.143 gitlab.example.com</span><br></pre></td></tr></table></figure>
<h1 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h1><h2 id="首次登录"><a href="#首次登录" class="headerlink" title="首次登录"></a>首次登录</h2><ol>
<li>浏览器打开:  <code>http://gitlab.example.com:9080</code> </li>
<li>重置管理员<code>root</code>密码(e.g. <code>admin123</code>)</li>
<li>登录</li>
</ol>
<h2 id="启用双重认证（可选）Two-Factor-Authentication"><a href="#启用双重认证（可选）Two-Factor-Authentication" class="headerlink" title="启用双重认证（可选）Two-Factor Authentication"></a>启用双重认证（可选）Two-Factor Authentication</h2><p>在个人设置中启用双重认证，手机端使用 FreeOTP 生成认证码。</p>
<h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><ul>
<li>User</li>
<li>Group</li>
<li>Repository</li>
<li>TLS &amp; SSH </li>
<li>Settings<br>…</li>
</ul>
]]></content>
      <categories>
        <category>SCM</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>gRPC 笔记</title>
    <url>/2021/01/18/grpc-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><blockquote>
<p>A high performance, open source universal RPC framework</p>
</blockquote>
<p><a href="https://www.grpc.io/">https://www.grpc.io/</a></p>
<p>gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services.</p>
<ul>
<li>Simple service definition <code>Define your service using Protocol Buffers, a powerful binary serialization toolset and language</code></li>
<li>Start quickly and scale <code>Install runtime and dev environments with a single line and also scale to millions of RPCs per second with the framework</code></li>
<li>Works across languages and platforms <code>Automatically generate idiomatic client and server stubs for your service in a variety of languages and platforms</code></li>
<li>Bi-directional streaming and integrated auth <code>Bi-directional streaming and fully integrated pluggable authentication with HTTP/2-based transport</code></li>
</ul>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><img src="/images/grpc/landing-2.svg" alt="landing-2"></p>
<h2 id="Protocol-Compiler"><a href="#Protocol-Compiler" class="headerlink" title="Protocol Compiler"></a>Protocol Compiler</h2><p>Download: <a href="https://github.com/protocolbuffers/protobuf/releases">https://github.com/protocolbuffers/protobuf/releases</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> https://github.com/protocolbuffers/protobuf/releases/download/v3.14.0/protoc-3.14.0-osx-x86_64.zip</span></span><br><span class="line"></span><br><span class="line">cp /Users/shankai/Downloads/protoc-3.14.0-osx-x86_64/bin/protoc /usr/local/bin/protoc</span><br><span class="line"></span><br><span class="line">protoc -h</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">cd</span> /path/xx.proto</span></span><br><span class="line"></span><br><span class="line">protoc --java_out=../java/ vehicle-service.proto</span><br></pre></td></tr></table></figure>

<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><blockquote>
<p>java &amp; nodejs</p>
</blockquote>
<p><a href="https://github.com/shankai/artifacts/tree/master/grpc-example">https://github.com/shankai/artifacts/tree/master/grpc-example</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><p><a href="https://www.grpc.io/docs/languages/java/quickstart/">https://www.grpc.io/docs/languages/java/quickstart/</a></p>
<p><a href="https://www.grpc.io/docs/languages/java/basics/">https://www.grpc.io/docs/languages/java/basics/</a></p>
<p><a href="https://github.com/grpc/grpc-java/blob/master/README.md">https://github.com/grpc/grpc-java/blob/master/README.md</a></p>
<h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p><a href="https://www.grpc.io/docs/languages/node/quickstart/">https://www.grpc.io/docs/languages/node/quickstart/</a></p>
]]></content>
      <categories>
        <category>RPC</category>
      </categories>
      <tags>
        <tag>Protobuf</tag>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title>Hazelcast Notes</title>
    <url>/2019/12/17/hazelcast-notes/</url>
    <content><![CDATA[<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><h3 id="Docker-2-container"><a href="#Docker-2-container" class="headerlink" title="Docker(2 container)"></a>Docker(2 container)</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -it -p 5701:5701 -e MANCENTER_URL=<span class="string">&#x27;http://172.16.18.143:8200/hazelcast-mancenter&#x27;</span> -e JAVA_OPTS=<span class="string">&#x27;-Dhazelcast.local.publicAddress=172.16.18.143:5701 -Dhazelcast.rest.enabled=true&#x27;</span> hazelcast/hazelcast:3.12.4</span><br><span class="line"></span><br><span class="line">docker run -d -it -p 5702:5701 -e MANCENTER_URL=<span class="string">&#x27;http://172.16.18.143:8200/hazelcast-mancenter&#x27;</span> -e JAVA_OPTS=<span class="string">&#x27;-Dhazelcast.local.publicAddress=172.16.18.143:5702 -Dhazelcast.rest.enabled=true&#x27;</span> hazelcast/hazelcast:3.12.4</span><br></pre></td></tr></table></figure>
<ul>
<li><code>-Dhazelcast.rest.enabled=true</code>启用 REST API</li>
</ul>
<h2 id="Management"><a href="#Management" class="headerlink" title="Management"></a>Management</h2><h3 id="Docker-Run"><a href="#Docker-Run" class="headerlink" title="Docker Run"></a>Docker Run</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -dit -p 8200:8080 hazelcast/management-center:latest</span><br></pre></td></tr></table></figure>
<h3 id="Visit"><a href="#Visit" class="headerlink" title="Visit"></a>Visit</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http://192.168.11.10:8200/hazelcast-mancenter</span><br></pre></td></tr></table></figure>


<h2 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h2><h3 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h3><ul>
<li>Put Key-Value to Map</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -v -X POST -H &quot;Content-Type: text&#x2F;plain&quot; -d &quot;bar&quot; http:&#x2F;&#x2F;127.0.0.1:5701&#x2F;hazelcast&#x2F;rest&#x2F;maps&#x2F;mapName&#x2F;foo</span><br></pre></td></tr></table></figure>
<ul>
<li>Get Value From Map By Key</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;127.0.0.1:5701&#x2F;hazelcast&#x2F;rest&#x2F;maps&#x2F;mapName&#x2F;foo</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Hazelcast</tag>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo Deploy By Github Actions</title>
    <url>/2021/02/16/hexo-github-actions-deploy-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>作为个人的技术笔记，将 Hexo Blog 以 Github Pages 的方式对外发布。Hexo Cli 提供了较好的发布方式（<code>hexo deploy</code>），足以满足低频发布操作。</p>
<p>今天的实践是：<strong>通过 Github Actions 来“持续集成”发布 Hexo Blog Site 到 Github Pages</strong>。</p>
<blockquote>
<p>实践的过程中遇到各种问题，对环境做更新：<br>Nodejs:<code>v12.19.0</code>-&gt;<code>v14.15.4</code><br>Hexo: <code>3.9.0</code>-&gt; <code>5.3.0</code></p>
</blockquote>
<h2 id="Github-Actions"><a href="#Github-Actions" class="headerlink" title="Github Actions"></a>Github Actions</h2><blockquote>
<p>GitHub Actions让你很容易自动化所有的软件工作流程，现在拥有世界级的CI/CD。从GitHub上构建、测试和部署你的代码。让代码评审、分支管理和问题分类按照您想要的方式工作。</p>
</blockquote>
<p>Github Actions 特性：<a href="https://github.com/features/actions">https://github.com/features/actions</a></p>
<p>Github Actions 文档：<a href="https://docs.github.com/cn/actions">https://docs.github.com/cn/actions</a></p>
<p>Github Actions 市场：<a href="https://github.com/marketplace?type=actions">https://github.com/marketplace?type=actions</a></p>
<h2 id="Hexo-Action"><a href="#Hexo-Action" class="headerlink" title="Hexo Action"></a>Hexo Action</h2><p>Github Actions 市场已经有了相关的 Action：Hexo Action。</p>
<p><a href="https://github.com/marketplace/actions/hexo-action">https://github.com/marketplace/actions/hexo-action</a></p>
<p><a href="https://github.com/sma11black/hexo-action">https://github.com/sma11black/hexo-action</a></p>
<h2 id="Operation"><a href="#Operation" class="headerlink" title="Operation"></a>Operation</h2><p>参考 Hexo Action 使用手册，</p>
<ol>
<li>创建密钥对（Github Pages Deploy Keys 使用公钥，Github Source Repos Secrets <code>DEPLOY_KEY</code>使用私钥）；</li>
<li>在 Github Source Repos 添加流程文件，如在 <code>.github/workflows</code> 下创建 <code>deploy.yml</code></li>
</ol>
<p><code>deploy.yml</code> 示例</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This is a basic workflow to help you get started with Actions</span></span><br><span class="line"></span><br><span class="line"><span class="attr">name:</span> <span class="string">CI</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Controls when the action will run. </span></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="comment"># Triggers the workflow on push or pull request events but only for the master branch</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span> [ <span class="string">master</span> ]</span><br><span class="line">  <span class="attr">pull_request:</span></span><br><span class="line">    <span class="attr">branches:</span> [ <span class="string">master</span> ]</span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">A</span> <span class="string">job</span> <span class="string">to</span> <span class="string">deploy</span> <span class="string">blog.</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Checkout</span></span><br><span class="line">      <span class="attr">uses:</span> <span class="string">actions/checkout@v1</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">submodules:</span> <span class="literal">true</span> <span class="comment"># Checkout private submodules(themes or something else).</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.)</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Cache</span> <span class="string">node</span> <span class="string">modules</span></span><br><span class="line">      <span class="attr">uses:</span> <span class="string">actions/cache@v1</span></span><br><span class="line">      <span class="attr">id:</span> <span class="string">cache</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">node_modules</span></span><br><span class="line">        <span class="attr">key:</span> <span class="string">$&#123;&#123;</span> <span class="string">runner.os</span> <span class="string">&#125;&#125;-node-$&#123;&#123;</span> <span class="string">hashFiles(&#x27;**/package-lock.json&#x27;)</span> <span class="string">&#125;&#125;</span></span><br><span class="line">        <span class="attr">restore-keys:</span> <span class="string">|</span></span><br><span class="line">          <span class="string">$&#123;&#123;</span> <span class="string">runner.os</span> <span class="string">&#125;&#125;-node-</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">Dependencies</span></span><br><span class="line">      <span class="attr">if:</span> <span class="string">steps.cache.outputs.cache-hit</span> <span class="type">!=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npm</span> <span class="string">ci</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Deploy hexo blog website.</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Hexo</span> <span class="string">Action</span></span><br><span class="line">      <span class="attr">id:</span> <span class="string">deploy</span></span><br><span class="line">      <span class="attr">uses:</span> <span class="string">sma11black/hexo-action@v1.0.4</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">deploy_key:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.DEPLOY_KEY</span> <span class="string">&#125;&#125;</span></span><br><span class="line">        <span class="attr">user_name:</span> <span class="string">shankai</span></span><br><span class="line">        <span class="attr">user_email:</span> <span class="string">shankai.kvn@gmail.com</span></span><br><span class="line">        <span class="attr">commit_msg:</span> <span class="string">$&#123;&#123;</span> <span class="string">github.event.head_commit.message</span> <span class="string">&#125;&#125;</span>  <span class="comment"># (or delete this input setting to use hexo default settings)</span></span><br><span class="line">    <span class="comment"># Use the output from the `deploy` step(use for test action)</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Get</span> <span class="string">the</span> <span class="string">output</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line">        <span class="string">echo</span> <span class="string">&quot;$<span class="template-variable">&#123;&#123; steps.deploy.outputs.notify &#125;&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>


<ul>
<li><code>name</code> Actions 的名称</li>
<li><code>on</code> 触发 Actions 的事件</li>
<li><code>jobs</code> 执行的一系列任务，每个任务是单独的运行环境，<code>runs-on</code>指定运行环境</li>
<li><code>steps</code>任务包含一系列操作步骤，每个步骤是一个 Action，如 Hexo Deploy 本例中使用 <code>uses: sma11black/hexo-action@v1.0.4</code></li>
</ul>
<p>编辑完成 <code>deploy.yml</code> 后提交变更，push 到 Hexo Source Repo。</p>
<h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><ol>
<li><p>将主题 next 作为 git module（Github Actions: hexo-action 用法） </p>
<p>因为 hexo 站点与 next 主题是完全独立的，此处在构建时 next 做为资源依赖参与构建。</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf themes&#x2F;next</span><br><span class="line">git rm -r themes&#x2F;next</span><br><span class="line">rm -rf .git&#x2F;modules&#x2F;themes&#x2F;next</span><br><span class="line">git submodule add https:&#x2F;&#x2F;github.com&#x2F;theme-next&#x2F;hexo-theme-next themes&#x2F;next</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p>远程仓库使用 SSH 方式访问而非 Https</p>
<p>出现的错误：</p>
</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">fatal: could not read Username <span class="keyword">for</span> <span class="string">&#x27;https://github.com&#x27;</span>: No such device or address</span><br><span class="line">FATAL Something<span class="string">&#x27;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html</span></span><br><span class="line"><span class="string">Error: Spawn failed</span></span><br><span class="line"><span class="string">    at ChildProcess.&lt;anonymous&gt; (/github/workspace/node_modules/hexo-deployer-git/node_modules/hexo-util/lib/spawn.js:51:21)</span></span><br><span class="line"><span class="string">    at ChildProcess.emit (events.js:314:20)</span></span><br><span class="line"><span class="string">    at Process.ChildProcess._handle.onexit (internal/child_process.js:276:12)</span></span><br></pre></td></tr></table></figure>
<p>修改 hexo/_config.yml 部署相关配置，使用 SSH 方式访问 Github Pages Repo（<a href="https://github.com/sma11black/hexo-action/issues/5%EF%BC%89">https://github.com/sma11black/hexo-action/issues/5）</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>


<p>（完）</p>
]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Github Actions</tag>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 命令行笔记</title>
    <url>/2019/06/03/java-cmd-notes/</url>
    <content><![CDATA[<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -jar XXX.jar</span><br></pre></td></tr></table></figure>


<h2 id="查看文件"><a href="#查看文件" class="headerlink" title="查看文件"></a>查看文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jar tf XXX.jar</span><br></pre></td></tr></table></figure>


<h2 id="更新文件"><a href="#更新文件" class="headerlink" title="更新文件"></a>更新文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">jar uf  XXX.jar &#x2F;path&#x2F;of&#x2F;jar&#x2F;file</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Programming Language</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Jar</tag>
        <tag>War</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka Connect Redis</title>
    <url>/2021/01/26/kafka-connect-redis-notes/</url>
    <content><![CDATA[<h2 id="Kafka-Connect"><a href="#Kafka-Connect" class="headerlink" title="Kafka Connect"></a>Kafka Connect</h2><p>Worker.java (ENABLE_AUTO_COMMIT_CONFIG:false, AUTO_OFFSET_RESET_CONFIG:earliest)</p>
<p>WorkerSinkTask.java</p>
<p><code>offset.flush.interval.ms</code><br>Interval at which to try committing offsets for tasks.<br>Default:    60000 (1 minute)</p>
<p>Confluent Kafka Connect Tutorial</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;docs.confluent.io&#x2F;5.0.0&#x2F;installation&#x2F;docker&#x2F;docs&#x2F;installation&#x2F;connect-avro-jdbc.html</span><br><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;docs.confluent.io&#x2F;5.0.0&#x2F;connect&#x2F;concepts.html#connect-converters</span><br></pre></td></tr></table></figure>



<p>Kafka Connect REST API</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http:&#x2F;&#x2F;dev:8083&#x2F;connector-plugins</span><br><span class="line">http:&#x2F;&#x2F;dev:8083&#x2F;connectors</span><br></pre></td></tr></table></figure>


<p>Lenses</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;docs.lenses.io&#x2F;4.1&#x2F;integrations&#x2F;connectors&#x2F;stream-reactor&#x2F;sinks&#x2F;redissinkconnector&#x2F;</span><br><span class="line">https:&#x2F;&#x2F;docs.lenses.io&#x2F;2.1&#x2F;lenses-sql&#x2F;kcql.html</span><br><span class="line"></span><br></pre></td></tr></table></figure>






<p>测试环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># all(zk,kafka,schema-registry,kafka-connect,ui,connectors)</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;lensesio&#x2F;fast-data-dev</span><br><span class="line"></span><br><span class="line"># ui &amp; kafka-connect</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;lensesio&#x2F;kafka-connect-ui</span><br><span class="line">https:&#x2F;&#x2F;hub.docker.com&#x2F;r&#x2F;confluentinc&#x2F;cp-kafka-connect</span><br></pre></td></tr></table></figure>




<h2 id="Build"><a href="#Build" class="headerlink" title="Build"></a>Build</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># clone from fork repository </span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;shankai&#x2F;stream-reactor.git</span><br><span class="line">cd stream-reactor&#x2F;kafka-connect-redis</span><br><span class="line">gradle clean build collectFatJar -x test</span><br></pre></td></tr></table></figure>


<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><h3 id="All"><a href="#All" class="headerlink" title="All"></a>All</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># redis pubsub mode has bug</span><br><span class="line">docker run --rm -d --name lensesio_dev \</span><br><span class="line">       -p 2181:2181 -p 3030:3030 -p 9092:9092 \</span><br><span class="line">       -p 8081-8083:8081-8083 -p 9581-9585:9581-9585 \</span><br><span class="line">       -e ADV_HOST&#x3D;dev -e CONNECTORS&#x3D;redis \</span><br><span class="line">       lensesio&#x2F;fast-data-dev:latest</span><br><span class="line"></span><br><span class="line"># redis pubsub fix </span><br><span class="line">docker run --rm -d --name lensesio_dev \</span><br><span class="line">       -p 2181:2181 -p 3030:3030 -p 9092:9092 \</span><br><span class="line">       -p 8081-8083:8081-8083 -p 9581-9585:9581-9585 \</span><br><span class="line">       -e ADV_HOST&#x3D;dev -e CONNECTORS&#x3D;redis \</span><br><span class="line">       -v &#x2F;Users&#x2F;shankai&#x2F;codebase&#x2F;oss&#x2F;stream-reactor&#x2F;kafka-connect-redis&#x2F;build&#x2F;libs&#x2F;kafka-connect-redis-2.1.3.jar:&#x2F;opt&#x2F;landoop&#x2F;connectors&#x2F;stream-reactor&#x2F;kafka-connect-redis&#x2F;kafka-connect-redis-2.1.3.jar \</span><br><span class="line">       lensesio&#x2F;fast-data-dev:latest</span><br></pre></td></tr></table></figure>


<h3 id="Kafka-Connect-amp-UI"><a href="#Kafka-Connect-amp-UI" class="headerlink" title="Kafka Connect &amp; UI"></a>Kafka Connect &amp; UI</h3><p>docker pull confluentinc/cp-zookeeper<br>docker pull confluentinc/cp-kafka</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name eventbus_kafka -d \</span><br><span class="line">   -p 9092:9092 \</span><br><span class="line">   -e KAFKA_LISTENERS&#x3D;PLAINTEXT:&#x2F;&#x2F;0.0.0.0:9092 \</span><br><span class="line">   -e KAFKA_ADVERTISED_LISTENERS&#x3D;PLAINTEXT:&#x2F;&#x2F;dev:9092 \</span><br><span class="line">   -e KAFKA_ZOOKEEPER_CONNECT&#x3D;dev:2181 \</span><br><span class="line">   -e KAFKA_AUTO_CREATE_TOPICS_ENABLE&#x3D;true \</span><br><span class="line">   -e KAFKA_DELETE_TOPIC_ENABLE&#x3D;true \</span><br><span class="line">   -e KAFKA_BROKER_ID&#x3D;0 \</span><br><span class="line">   -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock \</span><br><span class="line">   wurstmeister&#x2F;kafka:2.11-1.1.1</span><br></pre></td></tr></table></figure>




<p>docker pull confluentinc/cp-schema-registry</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name schema-registry -h schema-registry -p 8081:8081 \</span><br><span class="line">   -e SCHEMA_REGISTRY_HOST_NAME&#x3D;schema-registry \</span><br><span class="line">   -e SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL&#x3D;dev:2181 \</span><br><span class="line">   confluentinc&#x2F;cp-schema-registry:5.5.0 </span><br></pre></td></tr></table></figure>




<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name schema-registry -h schema-registry -p 8081:8081 \</span><br><span class="line">   -e SCHEMA_REGISTRY_HOST_NAME&#x3D;schema-registry \</span><br><span class="line">   -e SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL&#x3D;dev:2181 \</span><br><span class="line">   confluentinc&#x2F;cp-schema-registry:5.5.0 </span><br><span class="line"></span><br><span class="line">docker run --name eventbus_kafka -d \</span><br><span class="line">   -p 9092:9092 \</span><br><span class="line">   -e KAFKA_LISTENERS&#x3D;PLAINTEXT:&#x2F;&#x2F;0.0.0.0:9092 \</span><br><span class="line">   -e KAFKA_ADVERTISED_LISTENERS&#x3D;PLAINTEXT:&#x2F;&#x2F;dev:9092 \</span><br><span class="line">   -e KAFKA_ZOOKEEPER_CONNECT&#x3D;dev:2181 \</span><br><span class="line">   -e KAFKA_AUTO_CREATE_TOPICS_ENABLE&#x3D;true \</span><br><span class="line">   -e KAFKA_DELETE_TOPIC_ENABLE&#x3D;true \</span><br><span class="line">   -e KAFKA_BROKER_ID&#x3D;0 \</span><br><span class="line">   -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock \</span><br><span class="line">   wurstmeister&#x2F;kafka:2.11-1.1.1</span><br></pre></td></tr></table></figure>




<p>docker pull confluentinc/cp-kafka-connect</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name&#x3D;kafka-connect-avro \</span><br><span class="line">  -e CONNECT_BOOTSTRAP_SERVERS&#x3D;dev:9092 \</span><br><span class="line">  -e CONNECT_REST_PORT&#x3D;8083 \</span><br><span class="line">  -e CONNECT_GROUP_ID&#x3D;&quot;quickstart-avro&quot; \</span><br><span class="line">  -e CONNECT_CONFIG_STORAGE_TOPIC&#x3D;&quot;quickstart-avro-config&quot; \</span><br><span class="line">  -e CONNECT_OFFSET_STORAGE_TOPIC&#x3D;&quot;quickstart-avro-offsets&quot; \</span><br><span class="line">  -e CONNECT_STATUS_STORAGE_TOPIC&#x3D;&quot;quickstart-avro-status&quot; \</span><br><span class="line">  -e CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR&#x3D;1 \</span><br><span class="line">  -e CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR&#x3D;1 \</span><br><span class="line">  -e CONNECT_STATUS_STORAGE_REPLICATION_FACTOR&#x3D;1 \</span><br><span class="line">  -e CONNECT_KEY_CONVERTER&#x3D;&quot;io.confluent.connect.avro.AvroConverter&quot; \</span><br><span class="line">  -e CONNECT_VALUE_CONVERTER&#x3D;&quot;io.confluent.connect.avro.AvroConverter&quot; \</span><br><span class="line">  -e CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL&#x3D;&quot;http:&#x2F;&#x2F;dev:8081&quot; \</span><br><span class="line">  -e CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL&#x3D;&quot;http:&#x2F;&#x2F;dev:8081&quot; \</span><br><span class="line">  -e CONNECT_INTERNAL_KEY_CONVERTER&#x3D;&quot;org.apache.kafka.connect.json.JsonConverter&quot; \</span><br><span class="line">  -e CONNECT_INTERNAL_VALUE_CONVERTER&#x3D;&quot;org.apache.kafka.connect.json.JsonConverter&quot; \</span><br><span class="line">  -e CONNECT_REST_ADVERTISED_HOST_NAME&#x3D;&quot;dev&quot; \</span><br><span class="line">  -e CONNECT_LOG4J_ROOT_LOGLEVEL&#x3D;INFO \</span><br><span class="line">  -e CONNECT_PLUGIN_PATH&#x3D;&#x2F;usr&#x2F;share&#x2F;java,&#x2F;etc&#x2F;kafka-connect&#x2F;jars \</span><br><span class="line">  -v &#x2F;Users&#x2F;shankai&#x2F;codebase&#x2F;oss&#x2F;fork&#x2F;jars&#x2F;:&#x2F;etc&#x2F;kafka-connect&#x2F;jars&#x2F; \</span><br><span class="line">  -p 8083:8083 \</span><br><span class="line">  confluentinc&#x2F;cp-kafka-connect:latest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">  --name&#x3D;kc-redis-avro \</span><br><span class="line">  -e CONNECT_BOOTSTRAP_SERVERS&#x3D;dev:9092 \</span><br><span class="line">  -e CONNECT_REST_PORT&#x3D;8083 \</span><br><span class="line">  -e CONNECT_GROUP_ID&#x3D;&quot;quickstart-avro&quot; \</span><br><span class="line">  -e CONNECT_CONFIG_STORAGE_TOPIC&#x3D;&quot;quickstart-avro-config&quot; \</span><br><span class="line">  -e CONNECT_OFFSET_STORAGE_TOPIC&#x3D;&quot;quickstart-avro-offsets&quot; \</span><br><span class="line">  -e CONNECT_STATUS_STORAGE_TOPIC&#x3D;&quot;quickstart-avro-status&quot; \</span><br><span class="line">  -e CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR&#x3D;1 \</span><br><span class="line">  -e CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR&#x3D;1 \</span><br><span class="line">  -e CONNECT_STATUS_STORAGE_REPLICATION_FACTOR&#x3D;1 \</span><br><span class="line">  -e CONNECT_KEY_CONVERTER&#x3D;&quot;io.confluent.connect.avro.AvroConverter&quot; \</span><br><span class="line">  -e CONNECT_VALUE_CONVERTER&#x3D;&quot;io.confluent.connect.avro.AvroConverter&quot; \</span><br><span class="line">  -e CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL&#x3D;&quot;http:&#x2F;&#x2F;dev:8081&quot; \</span><br><span class="line">  -e CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL&#x3D;&quot;http:&#x2F;&#x2F;dev:8081&quot; \</span><br><span class="line">  -e CONNECT_INTERNAL_KEY_CONVERTER&#x3D;&quot;org.apache.kafka.connect.json.JsonConverter&quot; \</span><br><span class="line">  -e CONNECT_INTERNAL_VALUE_CONVERTER&#x3D;&quot;org.apache.kafka.connect.json.JsonConverter&quot; \</span><br><span class="line">  -e CONNECT_REST_ADVERTISED_HOST_NAME&#x3D;&quot;dev&quot; \</span><br><span class="line">  -e CONNECT_LOG4J_ROOT_LOGLEVEL&#x3D;INFO \</span><br><span class="line">  -e CONNECT_PLUGIN_PATH&#x3D;&#x2F;usr&#x2F;share&#x2F;java,&#x2F;etc&#x2F;kafka-connect&#x2F;jars \</span><br><span class="line">  -p 8083:8083 \</span><br><span class="line">kc-redis:latest</span><br></pre></td></tr></table></figure>
<p>docker pull landoop/kafka-connect-ui</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;lensesio&#x2F;kafka-connect-ui</span><br><span class="line"></span><br><span class="line">docker run -d --name kafka-connect-ui -it -p 8000:8000 -e &quot;CONNECT_URL&#x3D;http:&#x2F;&#x2F;dev:8083&quot; landoop&#x2F;kafka-connect-ui</span><br></pre></td></tr></table></figure>


<h2 id="Connector"><a href="#Connector" class="headerlink" title="Connector"></a>Connector</h2><h3 id="connector-configuration-override"><a href="#connector-configuration-override" class="headerlink" title="connector configuration override"></a>connector configuration override</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">value.converter.schema.registry.url&#x3D;http:&#x2F;&#x2F;dev:8081</span><br><span class="line">value.converter&#x3D;io.confluent.connect.protobuf.ProtobufConverter</span><br></pre></td></tr></table></figure>


<p>worker.properties: <code>connector.client.config.override.policy=All</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;consumer.override.max.poll.records&quot;: &quot;1&quot;,</span><br><span class="line">&quot;consumer.override.fetch.max.wait.ms&quot;: &quot;0&quot;</span><br></pre></td></tr></table></figure>


<p>LOG_DIR=/app</p>
<h3 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h3><h4 id="RedisSinkConnector-PubSub"><a href="#RedisSinkConnector-PubSub" class="headerlink" title="RedisSinkConnector PubSub"></a>RedisSinkConnector PubSub</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">connector.class&#x3D;com.datamountaineer.streamreactor.connect.redis.sink.RedisSinkConnector</span><br><span class="line">connect.redis.port&#x3D;6379</span><br><span class="line">connect.redis.kcql&#x3D;select * from sea_vessel_position_reports STOREAS PubSub(channel&#x3D;Timestamp)</span><br><span class="line">topics&#x3D;sea_vessel_position_reports</span><br><span class="line">tasks.max&#x3D;1</span><br><span class="line">connect.redis.host&#x3D;dev</span><br><span class="line">name&#x3D;quickstart-redis-pub</span><br></pre></td></tr></table></figure>
<h4 id="RedisSinkConnector-Cache"><a href="#RedisSinkConnector-Cache" class="headerlink" title="RedisSinkConnector Cache"></a>RedisSinkConnector Cache</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">connector.class&#x3D;com.datamountaineer.streamreactor.connect.redis.sink.RedisSinkConnector</span><br><span class="line">connect.redis.port&#x3D;6379</span><br><span class="line">connect.redis.kcql&#x3D;INSERT INTO PK- select * from sea_vessel_position_reports PK Timestamp</span><br><span class="line">topics&#x3D;sea_vessel_position_reports</span><br><span class="line">tasks.max&#x3D;1</span><br><span class="line">connect.redis.host&#x3D;dev</span><br><span class="line">name&#x3D;quickstart-redis-cache</span><br></pre></td></tr></table></figure>


<h3 id="Rest"><a href="#Rest" class="headerlink" title="Rest"></a>Rest</h3><h4 id="Redis-Cache"><a href="#Redis-Cache" class="headerlink" title="Redis Cache"></a>Redis Cache</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl --location --request POST &#x27;http://dev:8083/connectors&#x27; \</span><br><span class="line">--header &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">--data-raw &#x27;&#123;</span><br><span class="line">    &quot;name&quot;: &quot;RedisSinkConnectorCache&quot;,</span><br><span class="line">    &quot;config&quot;: &#123;</span><br><span class="line">        &quot;connector.class&quot;: &quot;com.datamountaineer.streamreactor.connect.redis.sink.RedisSinkConnector&quot;,</span><br><span class="line">        &quot;connect.redis.port&quot;: &quot;6379&quot;,</span><br><span class="line">        &quot;connect.redis.kcql&quot;: &quot;INSERT INTO FX- select location from sea_vessel_position_reports PK Timestamp&quot;,</span><br><span class="line">        &quot;topics&quot;: &quot;sea_vessel_position_reports&quot;,</span><br><span class="line">        &quot;tasks.max&quot;: &quot;1&quot;,</span><br><span class="line">        &quot;connect.redis.host&quot;: &quot;dev&quot;,</span><br><span class="line">        &quot;name&quot;: &quot;RedisSinkConnectorCache&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>
<h4 id="Redis-PubSub"><a href="#Redis-PubSub" class="headerlink" title="Redis PubSub"></a>Redis PubSub</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl --location --request POST &#x27;http://dev:8083/connectors&#x27; \</span><br><span class="line">--header &#x27;Content-Type: application/json&#x27; \</span><br><span class="line">--data-raw &#x27;&#123;</span><br><span class="line">    &quot;name&quot;: &quot;RedisSinkConnectorPubSub&quot;,</span><br><span class="line">    &quot;config&quot;: &#123;</span><br><span class="line">        &quot;connector.class&quot;: &quot;com.datamountaineer.streamreactor.connect.redis.sink.RedisSinkConnector&quot;,</span><br><span class="line">        &quot;connect.redis.port&quot;: &quot;6379&quot;,</span><br><span class="line">        &quot;connect.redis.kcql&quot;: &quot;select * from sea_vessel_position_reports STOREAS PubSub(channel=Timestamp)&quot;,</span><br><span class="line">        &quot;topics&quot;: &quot;sea_vessel_position_reports&quot;,</span><br><span class="line">        &quot;tasks.max&quot;: &quot;1&quot;,</span><br><span class="line">        &quot;connect.redis.host&quot;: &quot;dev&quot;,</span><br><span class="line">        &quot;name&quot;: &quot;RedisSinkConnectorPubSub&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&#x27;</span><br></pre></td></tr></table></figure>
<h2 id="Redis-Benchmark"><a href="#Redis-Benchmark" class="headerlink" title="Redis Benchmark"></a>Redis Benchmark</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis-benchmark -h redis-ps-redis-perf-paas.paas -c 1 -d 1024  script load &quot;redis.call(&#39;publish&#39;, &#39;abc&#39;)&quot; </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>Kafka</tag>
        <tag>Redis</tag>
        <tag>Kafka Connect</tag>
        <tag>Streaming</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka Connect REST API 笔记</title>
    <url>/2021/02/23/kafka-connect-rest-api-notes/</url>
    <content><![CDATA[<h2 id="Connectors"><a href="#Connectors" class="headerlink" title="Connectors"></a>Connectors</h2><h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h2><h2 id="Connector-Plugins"><a href="#Connector-Plugins" class="headerlink" title="Connector Plugins"></a>Connector Plugins</h2>]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Kafka Connect</tag>
        <tag>Connectors</tag>
        <tag>Tasks</tag>
        <tag>Topics</tag>
        <tag>Plugins</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka Notes</title>
    <url>/2020/02/24/kafka-notes/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>…</p>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><blockquote>
<p>172.16.18.143 为宿主机 IP</p>
</blockquote>
<ul>
<li><p>Zookeeper</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name eventbus_zk -d -p 2181:2181 zookeeper:3.5.7</span><br><span class="line"><span class="meta">#</span><span class="bash"> docker run --name eventbus_zk -d -p 2181:2181 wurstmeister/zookeeper:3.4.6</span>	</span><br></pre></td></tr></table></figure>

</li>
<li><p>Kafka</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name eventbus_kafka -d \</span><br><span class="line">   -p 9092:9092 \</span><br><span class="line">   -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \</span><br><span class="line">   -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://172.16.18.143:9092 \</span><br><span class="line">   -e KAFKA_ZOOKEEPER_CONNECT=172.16.18.143:2181 \</span><br><span class="line">   -e KAFKA_AUTO_CREATE_TOPICS_ENABLE=true \</span><br><span class="line">   -e KAFKA_DELETE_TOPIC_ENABLE=true \</span><br><span class="line">   -e KAFKA_BROKER_ID=0 \</span><br><span class="line">   -v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">   wurstmeister/kafka:2.11-1.1.1</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h2 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h2><blockquote>
<p>示例</p>
</blockquote>
<ul>
<li><p>Topic List</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/opt/kafka/bin/kafka-topics.sh --list --zookeeper 172.16.18.143:2181</span><br></pre></td></tr></table></figure></li>
<li><p>Producer</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/opt/kafka/bin/kafka-console-producer.sh --broker-list 172.16.18.143:9092 --topic test.eb1</span><br></pre></td></tr></table></figure></li>
<li><p>Consumer</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server 172.16.18.143:9092 --topic test.eb1  --from-beginning</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p>（待续）</p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>Kafka</tag>
        <tag>Streaming</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Command Notes</title>
    <url>/2020/08/01/linux-command-package/</url>
    <content><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt-get install inetutils-ping</span><br><span class="line">apt-get install net-tools</span><br></pre></td></tr></table></figure>


<h2 id="jq"><a href="#jq" class="headerlink" title="jq"></a>jq</h2><h3 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h3><ul>
<li><code>-j</code> “join”</li>
<li><code>-r</code> “raw”</li>
</ul>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl --location --request GET &quot;http:&#x2F;&#x2F;icosregistry-icosregistry-service-icos.icos.icos.city&#x2F;v1&#x2F;assets?pageSize&#x3D;100000&amp;pageNo&#x3D;0&amp;typeName&#x3D;vehicle_speedlimit&quot;</span><br><span class="line"></span><br><span class="line">curl --location --request GET &quot;http:&#x2F;&#x2F;icosregistry-icosregistry-service-icos.icos.icos.city&#x2F;v1&#x2F;assets?typeName&#x3D;traffic_lamp_type&amp;pageSize&#x3D;100&quot; | jq -jr &#39;.data[]|.id,&quot; &quot;,.name,&quot;\n&quot;&#39;</span><br><span class="line"></span><br><span class="line">curl --location --request GET &quot;http:&#x2F;&#x2F;icosregistry-icosregistry-service-icos.icos.icos.city&#x2F;v1&#x2F;assets?typeName&#x3D;twin_intersection_type&amp;pageSize&#x3D;100&quot; | jq -jr &#39;.data[]|.id,&quot; &quot;,.name,&quot;\n&quot;&#39;</span><br><span class="line"></span><br><span class="line">curl --location --request GET &quot;http:&#x2F;&#x2F;icosregistry-icosregistry-service-icos.icos.icos.city&#x2F;v1&#x2F;assets?typeName&#x3D;twin_traffic_lamp_direction&amp;pageSize&#x3D;100&quot; | jq -jr &#39;.data[]|.id,&quot; &quot;,.name,&quot;\n&quot;&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl --location --request GET &quot;http:&#x2F;&#x2F;icosregistry-icosregistry-service-icos.icos.icos.city&#x2F;v1&#x2F;assets?typeName&#x3D;isvd1_hikvision&amp;pageSize&#x3D;100&quot; | jq -jr &#39;.data[]|.id,&quot; &quot;,.name,&quot;\n&quot;&#39;</span><br><span class="line"></span><br><span class="line">curl --location --request GET &quot;http:&#x2F;&#x2F;icosregistry-icosregistry-service-icos.icos.icos.city&#x2F;v1&#x2F;assets?typeName&#x3D;cam1_hikvision&amp;pageSize&#x3D;100&quot; | jq -jr &#39;.data[]|.id,&quot; &quot;,.name,&quot;\n&quot;&#39;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>OS&amp;VM&amp;LXC</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CLI</tag>
        <tag>Command Line</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB Notes</title>
    <url>/2019/09/01/mongodb-notes/</url>
    <content><![CDATA[<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>环境：Ubuntu 16.04<br>用户：root<br>官方手册： <a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/">https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/</a></p>
<h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget -qO - https:&#x2F;&#x2F;www.mongodb.org&#x2F;static&#x2F;pgp&#x2F;server-4.0.asc | apt-key add -</span><br><span class="line"></span><br><span class="line">echo &quot;deb [ arch&#x3D;amd64,arm64 ] https:&#x2F;&#x2F;repo.mongodb.org&#x2F;apt&#x2F;ubuntu xenial&#x2F;mongodb-org&#x2F;4.0 multiverse&quot; | tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;mongodb-org-4.0.list</span><br><span class="line"></span><br><span class="line">apt-get install apt-transport-https</span><br><span class="line"></span><br><span class="line">apt-get update</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="安装最新"><a href="#安装最新" class="headerlink" title="安装最新"></a>安装最新</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt-get install -y mongodb-org</span><br></pre></td></tr></table></figure>
<h4 id="安装指定版本"><a href="#安装指定版本" class="headerlink" title="安装指定版本"></a>安装指定版本</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt-get install -y mongodb-org&#x3D;4.0.11 mongodb-org-server&#x3D;4.0.11 mongodb-org-shell&#x3D;4.0.11 mongodb-org-mongos&#x3D;4.0.11 mongodb-org-tools&#x3D;4.0.11</span><br></pre></td></tr></table></figure>
<h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name mongo-dev -d -p 27017:27017 mongo:latest</span><br></pre></td></tr></table></figure>


<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><p>远程连接示例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mongo --host qloudmongodb.pditdapps:27017 -u &quot;qloudwiki&quot; -p &quot;qloudwiki&quot; --authenticationDatabase &quot;wiki&quot;</span><br></pre></td></tr></table></figure>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><blockquote>
<p><code>xxx</code> 为数据库名称</p>
</blockquote>
<ul>
<li>数据库列表</li>
</ul>
<p><code>show dbs</code></p>
<ul>
<li>切换数据库 </li>
</ul>
<p><code>use xxx</code></p>
<h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><blockquote>
<p><code>xxx</code> 为集合名称</p>
</blockquote>
<ul>
<li>集合列表</li>
</ul>
<p><code>show collections</code></p>
<ul>
<li>查询</li>
</ul>
<p><code>db.xxx.find()</code></p>
<ul>
<li>删除</li>
</ul>
<p><code>db.xxx.drop()</code></p>
]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Nodejs Https Server Notes</title>
    <url>/2019/07/03/nodejs-https-server-demo/</url>
    <content><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul>
<li>nodejs:v10.16.0</li>
<li>npm:6.9.0</li>
</ul>
<h2 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">keytool -genkeypair -alias vsd -validity 7200 -keyalg RSA -keysize 4096 -storetype JKS -keystore vsd.keystore -storepass vsd@2019 -keypass vsd@2019 -dname &quot;CN&#x3D;v.s.d, OU&#x3D;dtts, O&#x3D;dtts&quot;</span><br><span class="line"></span><br><span class="line">keytool -v -importkeystore -srckeystore vsd.keystore -srcalias vsd -srcstorepass vsd@2019 -srckeypass vsd@2019 -destkeystore vsd.p12 -deststoretype PKCS12 -deststorepass vsd@2019 -destkeypass vsd@2019</span><br><span class="line"></span><br><span class="line">openssl pkcs12 -in vsd.p12 -nocerts -nodes -out vsd.key.pem -passin pass:vsd@2019</span><br><span class="line">openssl pkcs12 -in vsd.p12 -clcerts -nokeys -out vsd.cert.pem -passin pass:vsd@2019</span><br></pre></td></tr></table></figure>


<h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install express https http fs body-parser</span><br></pre></td></tr></table></figure>

<h2 id="创建文件"><a href="#创建文件" class="headerlink" title="创建文件"></a>创建文件</h2><blockquote>
<p>vsd.js </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var express &#x3D; require(&#39;express&#39;);</span><br><span class="line">var https &#x3D; require(&#39;https&#39;);</span><br><span class="line">var http &#x3D; require(&#39;http&#39;);</span><br><span class="line">var fs &#x3D; require(&#39;fs&#39;);</span><br><span class="line">var bodyParser &#x3D; require(&#39;body-parser&#39;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; This line is from the Node.js HTTPS documentation.</span><br><span class="line">var options &#x3D; &#123;</span><br><span class="line">  key: fs.readFileSync(&#39;qmsauthn.key.pem&#39;),</span><br><span class="line">  cert: fs.readFileSync(&#39;qmsauthn.cert.pem&#39;)</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Create a service (the app object is just a callback).</span><br><span class="line">var app &#x3D; express();</span><br><span class="line"></span><br><span class="line">app.use(bodyParser.json());</span><br><span class="line">app.use(bodyParser.urlencoded());</span><br><span class="line">&#x2F;&#x2F; in latest body-parser use like below.</span><br><span class="line">app.use(bodyParser.urlencoded(&#123; extended: true &#125;));</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; get api</span><br><span class="line">app.get(&#39;&#x2F;api&#x2F;v1&#39;, (req, res) &#x3D;&gt; &#123;</span><br><span class="line">  res.status(200).send(&#123;</span><br><span class="line">    success: &#39;true&#39;,</span><br><span class="line">    message: &#39;todos retrieved successfully&#39;,</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; post api (Content-Type: application&#x2F;x-www-form-urlencoded)</span><br><span class="line">app.post(&#39;&#x2F;api&#x2F;v2&#39;, (req, res) &#x3D;&gt; &#123;</span><br><span class="line">  console.log(req.body);</span><br><span class="line">  res.status(200).send(&#123;</span><br><span class="line">    success: &#39;true&#39;,</span><br><span class="line">    message: &#39;todos retrieved successfully&#39;,</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Create an HTTP service.</span><br><span class="line">http.createServer(app).listen(80);</span><br><span class="line">&#x2F;&#x2F; Create an HTTPS service identical to the HTTP service.</span><br><span class="line">https.createServer(options, app).listen(443);</span><br></pre></td></tr></table></figure>
<h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><blockquote>
<p>http</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -i http:&#x2F;&#x2F;v.s.d&#x2F;api&#x2F;v1</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X POST \</span><br><span class="line">  http:&#x2F;&#x2F;v.s.d&#x2F;api&#x2F;v2 \</span><br><span class="line">  -H &#39;Content-Type: application&#x2F;x-www-form-urlencoded&#39; \</span><br><span class="line">  -d aa&#x3D;111</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Programming Language</category>
      </categories>
      <tags>
        <tag>Nodejs</tag>
        <tag>TLS</tag>
        <tag>Https</tag>
      </tags>
  </entry>
  <entry>
    <title>Nodejs 笔记</title>
    <url>/2020/04/20/nodejs-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>官网：<a href="https://nodejs.org/">https://nodejs.org/</a></p>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>参考官网，以下为笔记环境信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 6.9.0</span></span><br><span class="line">npm -v</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> v10.16.0</span></span><br><span class="line">node -v </span><br></pre></td></tr></table></figure>


<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><blockquote>
<p>通过 express 创建一个简单的端点服务，其中包含 GET、POST 端点示例</p>
</blockquote>
<ol>
<li>安装依赖</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install express body-parser</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>端点服务代码，保存到 <code>endpoint.js</code> 文件</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">&#x27;express&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> bodyParser = <span class="built_in">require</span>(<span class="string">&#x27;body-parser&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> app = express()</span><br><span class="line"></span><br><span class="line">app.use(bodyParser.json()); <span class="comment">// for parsing application/json</span></span><br><span class="line">app.use(bodyParser.urlencoded(&#123; <span class="attr">extended</span>: <span class="literal">true</span> &#125;)); <span class="comment">// for parsing application/x-www-form-urlencoded</span></span><br><span class="line"></span><br><span class="line">app.post(<span class="string">&#x27;/&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;===================================, Now:&#123;&#125;&#x27;</span>, <span class="built_in">Date</span>.now());</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;Request Body:&#x27;</span>, req.body);</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">&#x27;Request Headers:&#x27;</span>, req.headers);</span><br><span class="line">res.send(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line">app.get(<span class="string">&#x27;/&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">res.send(<span class="string">&#x27;ok&#x27;</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> server = app.listen(<span class="number">8099</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> host = server.address().address</span><br><span class="line"><span class="keyword">var</span> port = server.address().port</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>启动端点服务</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">node endpoint.js</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>验证</li>
</ol>
<p><code>GET</code>  返回 <code>ok</code> 即成功。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl http://localhost:8099/</span><br></pre></td></tr></table></figure>


<p><code>POST</code> 返回 <code>ok</code> 即成功。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -XPOST http://localhost:8099/ -H &quot;Content-Type: application/json&quot; -d &#x27;&#123;&quot;name&quot;: &quot;zhangsan&quot;, &quot;age&quot;: 20&#125;&#x27;</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>Programming Language</category>
      </categories>
      <tags>
        <tag>Nodejs</tag>
        <tag>Node</tag>
        <tag>Javascription</tag>
        <tag>Express</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache OFBiz Notes</title>
    <url>/2020/01/09/ofbiz-notes/</url>
    <content><![CDATA[<h2 id="Introduce"><a href="#Introduce" class="headerlink" title="Introduce"></a>Introduce</h2><p>Apache OFBiz 是一套非常灵活的业务应用程序，可以在任何行业中使用。 通用体系结构允许开发人员轻松地扩展或增强它以创建自定义特性。</p>
<p>官网：<a href="https://ofbiz.apache.org/">https://ofbiz.apache.org/</a></p>
<p>名词：OFBiz: Open for business</p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><ul>
<li><p>JDK 1.8</p>
<p> <code>java -version</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java version &quot;1.8.0_201&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_201-b09)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)</span><br></pre></td></tr></table></figure>

</li>
<li><p>Gradle/Gradlew</p>
<p><code>gradle -v</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">------------------------------------------------------------</span><br><span class="line">Gradle 5.1</span><br><span class="line">------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">Build time:   2019-01-02 18:57:47 UTC</span><br><span class="line">Revision:     d09c2e354576ac41078c322815cc6db2b66d976e</span><br><span class="line"></span><br><span class="line">Kotlin DSL:   1.1.0</span><br><span class="line">Kotlin:       1.3.11</span><br><span class="line">Groovy:       2.5.4</span><br><span class="line">Ant:          Apache Ant(TM) version 1.9.13 compiled on July 10 2018</span><br><span class="line">JVM:          1.8.0_201 (Oracle Corporation 25.201-b09)</span><br><span class="line">OS:           Mac OS X 10.15.2 x86_64</span><br></pre></td></tr></table></figure>




</li>
</ul>
<h2 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h2><ul>
<li>Resource</li>
</ul>
<p><code>https://www.apache.org/dyn/closer.lua/ofbiz/apache-ofbiz-16.11.06.zip</code></p>
<ul>
<li>Unzip</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unzip apache-ofbiz-16.11.06.zip</span><br></pre></td></tr></table></figure>


<h2 id="Build-amp-Run"><a href="#Build-amp-Run" class="headerlink" title="Build &amp; Run"></a>Build &amp; Run</h2><ul>
<li>CD</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd apache-ofbiz-16.11.06</span><br></pre></td></tr></table></figure>
<ul>
<li>Build</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gradle cleanAll loadDefault</span><br></pre></td></tr></table></figure>
<ul>
<li>Run</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gradle ofbiz</span><br></pre></td></tr></table></figure>
<ul>
<li><del>Stop</del></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gradle ofbiz --shutdown</span><br></pre></td></tr></table></figure>
<h2 id="Browser"><a href="#Browser" class="headerlink" title="Browser"></a>Browser</h2><ul>
<li>会计模块路由</li>
</ul>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">https://localhost:8443/accounting</span><br></pre></td></tr></table></figure>
<p>Username &amp; Password: <code>admin</code>/<code>ofbiz</code></p>
<h2 id="Modules-and-Features"><a href="#Modules-and-Features" class="headerlink" title="Modules and Features"></a>Modules and Features</h2><h3 id="Accounting（会计）"><a href="#Accounting（会计）" class="headerlink" title="Accounting（会计）"></a>Accounting（会计）</h3><ul>
<li> Standard Double entry General Ledger</li>
<li> Supports multiple organisations, account hierarchies and segmentation</li>
<li> Accounts Receivable (AR), Accounts Payable (AP), Invoices, Payments, Statements and Aging</li>
<li> Agreement contracts and Credit management</li>
<li> Asset Management including Depreciation</li>
<li> Budgeting Management</li>
<li> Support for payment gateways and payment processing</li>
<li> Financial Reporting</li>
<li> Fully integrated with Order Management, Inventory, Purchasing and Manufacturing out of the box</li>
</ul>
<h3 id="Manufacturing（制造业）"><a href="#Manufacturing（制造业）" class="headerlink" title="Manufacturing（制造业）"></a>Manufacturing（制造业）</h3><ul>
<li> Bill of Materials</li>
<li> Jobshop, Manufacturing Routings and Tasks</li>
<li> Production Planning and MRP</li>
<li> Production and Job Costing</li>
<li> Equipment Billing</li>
<li> Raw Material Procurement</li>
<li> Manufacturing Reporting</li>
</ul>
<h3 id="Human-Resources（人力资源）"><a href="#Human-Resources（人力资源）" class="headerlink" title="Human Resources（人力资源）"></a>Human Resources（人力资源）</h3><ul>
<li> Company and Department Structure</li>
<li> Manage Job Positions, Skills and Performance Reviews</li>
<li> Manage Recruitment Process, Applications, Interviews</li>
<li> Salaries and Payments</li>
<li> Employment Contracts</li>
<li> Employee Expenses</li>
<li> Training</li>
</ul>
<h3 id="Inventory-Management（库存管理）"><a href="#Inventory-Management（库存管理）" class="headerlink" title="Inventory Management（库存管理）"></a>Inventory Management（库存管理）</h3><ul>
<li>Manage and setup single, multiple warehouses</li>
<li> Inventory Locations</li>
<li> Serialized on non serialized Inventory</li>
<li> Lot Management</li>
<li> Shipment Integration</li>
<li> Picklist and Package Management</li>
<li> Receiving</li>
<li> Returns</li>
</ul>
<h3 id="Catalog-Management（目录管理）"><a href="#Catalog-Management（目录管理）" class="headerlink" title="Catalog Management（目录管理）"></a>Catalog Management（目录管理）</h3><ul>
<li> Support unlimited stores, catalogs, categories, and products</li>
<li> Handles a range of products (physical, digital, downloadable products, variant, configurable)</li>
<li> Gift Certificates and gift cards</li>
<li> Price rules for customer or group-specific pricing</li>
<li> Online store promotion engine</li>
<li> Integration with major payment gateway providers</li>
<li> Fully integrated online and Point of Sales (POS) stores out-of-the-box</li>
<li> Keyword search capability in all the applications using hibernate search</li>
</ul>
<h3 id="CRM-amp-Order-Management（客户关系管理-amp-订单管理）"><a href="#CRM-amp-Order-Management（客户关系管理-amp-订单管理）" class="headerlink" title="CRM &amp; Order Management（客户关系管理 &amp; 订单管理）"></a>CRM &amp; Order Management（客户关系管理 &amp; 订单管理）</h3><ul>
<li> Lead and Sales Opportunity Management</li>
<li> Sales ForecastsManage sales opportunities</li>
<li> Shared Sales Team Documents, Calendar and Tasks</li>
<li> Email Integration</li>
<li> Customer Service and Case Managment</li>
<li> Quotes, Order Entry and Order Management</li>
<li> Manage marketing campaign including tracking code reporting</li>
</ul>
<h3 id="e-Commerce-e-Shop（电子商务-电子商店）"><a href="#e-Commerce-e-Shop（电子商务-电子商店）" class="headerlink" title="e-Commerce/e-Shop（电子商务/电子商店）"></a>e-Commerce/e-Shop（电子商务/电子商店）</h3><ul>
<li> Unlimited stores, catalogs, categories and products</li>
<li> Cross-sell and upsell products</li>
<li> Supports physical, digital, downloadable, variant and configurable products</li>
<li> Gift Certificates and Gift Cards</li>
<li> Pricing rules and Discounts</li>
<li> Online store promotion engine</li>
<li> Integrations with payment gateways</li>
<li> Product searching</li>
<li> Customer portal</li>
</ul>
]]></content>
      <categories>
        <category>Framework</category>
      </categories>
      <tags>
        <tag>Application</tag>
        <tag>Framework</tag>
        <tag>Business</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 1604 TLS Server 上的 openssh-server</title>
    <url>/2018/03/12/openssh-server-at-ubuntu-1604-tls-server/</url>
    <content><![CDATA[<blockquote>
<p>环境： Unbuntu 16.04 TLS Server</p>
</blockquote>
<h2 id="SSH-简介"><a href="#SSH-简介" class="headerlink" title="SSH 简介"></a>SSH 简介</h2><blockquote>
<p><a href="https://zh.wikipedia.org/wiki/Secure_Shell">Secure Shell</a>（安全外壳协议，简称SSH）是一种加密的网络传输协议，可在不安全的网络中为网络服务提供安全的传输环境。</p>
</blockquote>
<h2 id="安装-openssh-server"><a href="#安装-openssh-server" class="headerlink" title="安装 openssh-server"></a>安装 openssh-server</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br><span class="line"></span><br><span class="line">sudo /etc/init.d/ssh start</span><br></pre></td></tr></table></figure>


<h2 id="启用-root-用户-SSH-登录"><a href="#启用-root-用户-SSH-登录" class="headerlink" title="启用 root 用户 SSH 登录"></a>启用 root 用户 SSH 登录</h2><ol>
<li>设置 root 密码</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo passwd root</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>启用 root 登录</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>
<p>将 <code>PermitRootLogin prohibit-password</code> 修改为 <code>PermitRootLogin yes</code> 。</p>
<ol start="3">
<li>重启 ssh 服务</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo service ssh restart</span><br></pre></td></tr></table></figure>


<h2 id="验证-root-用户-SSH-登录"><a href="#验证-root-用户-SSH-登录" class="headerlink" title="验证 root 用户 SSH 登录"></a>验证 root 用户 SSH 登录</h2><p>在终端命令行输入以下命令，其中 <code>server-host</code> 为服务器地址。按照提示输入密码，登录成功即可。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh root@server-host</span><br></pre></td></tr></table></figure>


<h2 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h2><h3 id="ssh-connect-to-host-172-16-18-131-port-22-Connection-refused"><a href="#ssh-connect-to-host-172-16-18-131-port-22-Connection-refused" class="headerlink" title="ssh: connect to host 172.16.18.131 port 22: Connection refused"></a>ssh: connect to host 172.16.18.131 port 22: Connection refused</h3><p>原因是Ubuntu没有默认提供ssh服务，因此首先安装ssh服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure>
<p>如果安装完后该服务没有自动启动，则手工启动：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo /etc/init.d/ssh start</span><br></pre></td></tr></table></figure>


<h3 id="Write-failed-Broken-pipe-问题解决"><a href="#Write-failed-Broken-pipe-问题解决" class="headerlink" title="Write failed Broken pipe 问题解决"></a>Write failed Broken pipe 问题解决</h3><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>用 ssh 命令连接服务器之后，如果一段时间不操作，再次进入 Terminal 时会有一段时间没有响应，然后就出现错误提示：</p>
<blockquote>
<p>Write failed: Broken pipe</p>
</blockquote>
<p>只能重新用 ssh 命令进行连接。</p>
<h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><ul>
<li>如果你有多台服务器，不想在每台服务器上设置，只需在客户端的 ~/.ssh/ 文件夹中添加 config 文件，并添加下面的配置：</li>
</ul>
<blockquote>
<p>ServerAliveInterval 60</p>
</blockquote>
<ul>
<li>如果你有多个人管理服务器，不想在每个客户端进行设置，只需在服务器的 /etc/ssh/sshd_config 中添加如下的配置：</li>
</ul>
<blockquote>
<p>ClientAliveInterval 60</p>
</blockquote>
<ul>
<li>如果您只想让当前的 ssh 保持连接，可以使用以下的命令：</li>
</ul>
<p><code>$ ssh -o ServerAliveInterval=60 user@sshserver</code></p>
<p><em><a href="http://www.cnblogs.com/dudu/archive/2013/02/07/ssh-write-failed-broken-pipe.html">参考原文</a></em></p>
]]></content>
      <categories>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL 笔记</title>
    <url>/2020/02/24/postgresql-notes/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>The World’s Most Advanced Open Source Relational Database. —— <a href="https://www.postgresql.org/">PostgreSQL</a></p>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p>…</p>
<blockquote>
<p>示例，其中 /usr/local/nakadi4cbh/database/nakadi 路径包含了初始化 Nakadi 数据库脚本。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name eventbus_pg -d \</span><br><span class="line">   -p 5432:5432 \</span><br><span class="line">   -e POSTGRES_USER=nakadi \</span><br><span class="line">   -e POSTGRES_PASSWORD=nakadi \</span><br><span class="line">   -e POSTGRES_DB=local_nakadi_db \</span><br><span class="line">   -v /usr/local/nakadi4cbh/database/nakadi:/docker-entrypoint-initdb.d \</span><br><span class="line">   postgres:9.6.16</span><br></pre></td></tr></table></figure>


<h2 id="psql"><a href="#psql" class="headerlink" title="psql"></a>psql</h2><ul>
<li><p><code>psql</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bash-4.2$ psql</span><br><span class="line">psql (12.2)</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"></span><br><span class="line">postgres=# </span><br></pre></td></tr></table></figure></li>
<li><p><code>\l</code> 数据库列表</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">postgres=# \l</span><br></pre></td></tr></table></figure></li>
<li><p><code>\c</code> 连接数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">postgres=# \c icosregistry_icos</span><br><span class="line">You are now connected to database &quot;icosregistry_icos&quot; as user &quot;postgres&quot;.</span><br><span class="line">icosregistry_icos=# </span><br></pre></td></tr></table></figure></li>
<li><p><code>select * from [table]</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">icosregistry_icos=# select * from asset_deploy;</span><br><span class="line"> asset_code | handler_type | opr_type | opr_status | opr_message | deploy_url | created </span><br><span class="line">------------+--------------+----------+------------+-------------+------------+---------</span><br><span class="line">(0 rows)</span><br><span class="line"></span><br><span class="line">icosregistry_icos=#</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h2 id="pg-dump-OPTION-…-DBNAME"><a href="#pg-dump-OPTION-…-DBNAME" class="headerlink" title="pg_dump [OPTION]… [DBNAME]"></a>pg_dump [OPTION]… [DBNAME]</h2><h3 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h3><p><code>-s</code> -s, –schema-only            dump only the schema, no data</p>
<p><code>-t</code> -t, –table=PATTERN          dump the specified table(s) only</p>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><ul>
<li>导出表结构示例</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pg_dump -s -t asset -t asset_group -t asset_group_membership -t asset_relationship -t asset_relationship_type -t asset_type -t asset_deploy icosregistry_icos</span><br></pre></td></tr></table></figure>


<p>（待续）</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgreSQL</tag>
        <tag>Postgre</tag>
        <tag>PG</tag>
      </tags>
  </entry>
  <entry>
    <title>Pushpin Notes</title>
    <url>/2020/06/01/pushpin-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --name pushpin -p 7999:7999 -p 5560:5560 -p 5561:5561 -p 5562:5562 -p 5563:5563 fanout&#x2F;pushpin:1.28.0</span><br><span class="line"></span><br><span class="line">docker run -d --name pushpin -p 7999:7999 -p 5560:5560 -p 5561:5561 -p 5562:5562 -p 5563:5563 -v &#x2F;Users&#x2F;shankai&#x2F;Desktop&#x2F;pushpin-config:&#x2F;etc&#x2F;pushpin&#x2F; fanout&#x2F;pushpin:1.28.0</span><br><span class="line"></span><br><span class="line">docker run -d --name pushpin -p 7999:7999 -p 5560:5560 -p 5561:5561 -p 5562:5562 -p 5563:5563 -v &#x2F;Users&#x2F;shankai&#x2F;Desktop&#x2F;pushpin-config:&#x2F;etc&#x2F;pushpin&#x2F; fanout&#x2F;pushpin:1.31.0</span><br></pre></td></tr></table></figure>
<h3 id="Port"><a href="#Port" class="headerlink" title="Port"></a>Port</h3><ul>
<li>7999</li>
<li>5560</li>
<li>5561</li>
<li>5562</li>
</ul>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><ul>
<li><p>conf: /etc/pushpin/pushpin.conf</p>
</li>
<li><p>routes: /etc/pushpin/routes</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">* 192.168.130.40:8099</span><br><span class="line">*,proto&#x3D;ws 192.168.130.40:8098,over_http</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><h4 id="Mock-Backend-test"><a href="#Mock-Backend-test" class="headerlink" title="Mock Backend [test]"></a>Mock Backend [test]</h4><ul>
<li>subscribe</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;localhost:7999&#x2F;stream</span><br></pre></td></tr></table></figure>
<ul>
<li>publish </li>
</ul>
<p>cli: </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pushpin-publish test &quot;hello there&quot;</span><br></pre></td></tr></table></figure>
<p>restful:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -d &#39;&#123; &quot;items&quot;: [ &#123; &quot;channel&quot;: &quot;test&quot;, &quot;formats&quot;: &#123;</span><br><span class="line">    &quot;http-stream&quot;: &#123; &quot;content&quot;: &quot;hello there\n&quot; &#125; &#125; &#125; ] &#125;&#39; \</span><br><span class="line">    http:&#x2F;&#x2F;localhost:5561&#x2F;publish&#x2F;</span><br></pre></td></tr></table></figure>
<p>curl -d ‘{ “items”: [ { “channel”: “test”, “formats”: {<br>    “http-stream”: { “content”: “hello there\n” } } } ] }’ <br>    <a href="http://localhost:5561/publish/">http://localhost:5561/publish/</a></p>
<h4 id="Backend-myChannel"><a href="#Backend-myChannel" class="headerlink" title="Backend [myChannel]"></a>Backend [myChannel]</h4><ul>
<li>http ( * 192.168.130.40:8099)</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>);</span><br><span class="line">http.createServer(<span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> headers = req.headers;</span><br><span class="line">    <span class="keyword">var</span> channel = headers[<span class="string">&#x27;channel&#x27;</span>] || <span class="string">&#x27;myChannel&#x27;</span>;</span><br><span class="line">    res.writeHead(<span class="number">200</span>, &#123;</span><br><span class="line">        <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;text/plain&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Grip-Hold&#x27;</span>: <span class="string">&#x27;stream&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Grip-Channel&#x27;</span>: channel</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="built_in">console</span>.log(headers);</span><br><span class="line">    res.end(<span class="string">&#x27;Stream opened, prepare yourself!\n&#x27;</span>);</span><br><span class="line">&#125;).listen(<span class="number">8099</span>, <span class="string">&#x27;0.0.0.0&#x27;</span>);</span><br></pre></td></tr></table></figure>


<ul>
<li>over_http ( *,proto=ws 192.168.130.40:8098,over_http )</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// npm install --save grip</span></span><br><span class="line"><span class="keyword">var</span> grip = <span class="built_in">require</span>(<span class="string">&#x27;grip&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> http = <span class="built_in">require</span>(<span class="string">&#x27;http&#x27;</span>);</span><br><span class="line"></span><br><span class="line">http.createServer(<span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</span><br><span class="line">    res.writeHead(<span class="number">200</span>, &#123;</span><br><span class="line">        <span class="string">&#x27;Sec-WebSocket-Extensions&#x27;</span>: <span class="string">&#x27;grip&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/websocket-events&#x27;</span></span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> body = <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">    req.on(<span class="string">&#x27;data&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params">chunk</span>) </span>&#123;</span><br><span class="line">        body += chunk;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    req.on(<span class="string">&#x27;end&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> inEvents = grip.decodeWebSocketEvents(body);</span><br><span class="line">        <span class="keyword">var</span> outEvents = [];</span><br><span class="line">        <span class="keyword">if</span> (inEvents[<span class="number">0</span>].getType() == <span class="string">&#x27;OPEN&#x27;</span>) &#123;</span><br><span class="line">            outEvents.push(<span class="keyword">new</span> grip.WebSocketEvent(<span class="string">&#x27;OPEN&#x27;</span>));</span><br><span class="line">            outEvents.push(<span class="keyword">new</span> grip.WebSocketEvent(<span class="string">&#x27;TEXT&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;c:&#x27;</span> + grip.webSocketControlMessage(</span><br><span class="line">                <span class="string">&#x27;subscribe&#x27;</span>,</span><br><span class="line">                &#123;<span class="string">&#x27;channel&#x27;</span>: <span class="string">&#x27;mychannel&#x27;</span>&#125;)));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        res.end(grip.encodeWebSocketEvents(outEvents));</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;).listen(<span class="number">8098</span>, <span class="string">&#x27;0.0.0.0&#x27;</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>zhttp.py</li>
</ul>
<p>Routes: <code>* zhttpreq/tcp://127.0.0.1:10000</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> zmq</span><br><span class="line"><span class="keyword">import</span> tnetstring</span><br><span class="line"></span><br><span class="line">zmq_context = zmq.Context()</span><br><span class="line">sock = zmq_context.socket(zmq.REP)</span><br><span class="line">sock.connect(<span class="string">&#x27;tcp://127.0.0.1:10000&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    req = tnetstring.loads(sock.recv()[<span class="number">1</span>:])</span><br><span class="line">    print(req[<span class="string">&#x27;headers&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    resp = &#123;</span><br><span class="line">        <span class="string">&#x27;id&#x27;</span>: req[<span class="string">&#x27;id&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;code&#x27;</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">&#x27;reason&#x27;</span>: <span class="string">&#x27;OK&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;headers&#x27;</span>: [</span><br><span class="line">            [<span class="string">&#x27;Grip-Hold&#x27;</span>, <span class="string">&#x27;stream&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;Grip-Channel&#x27;</span>, <span class="string">&#x27;test&#x27;</span>],</span><br><span class="line">            [<span class="string">&#x27;Content-Type&#x27;</span>, <span class="string">&#x27;text/plain&#x27;</span>]</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&#x27;body&#x27;</span>: <span class="string">&#x27;welcome to the stream\n&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sock.send(<span class="string">&#x27;T&#x27;</span> + tnetstring.dumps(resp))</span><br></pre></td></tr></table></figure>


<h4 id="ZMQ"><a href="#ZMQ" class="headerlink" title="ZMQ"></a>ZMQ</h4><ul>
<li>XPUB.py</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> zmq</span><br><span class="line"></span><br><span class="line">zmq_context = zmq.Context.instance()</span><br><span class="line">sock = zmq_context.socket(zmq.XPUB)</span><br><span class="line"></span><br><span class="line"><span class="comment"># unlimited subscriptions</span></span><br><span class="line">sock.rcvhwm = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># resend subscriptions after disconnect</span></span><br><span class="line">sock.immediate = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">sock.connect(<span class="string">&#x27;tcp://localhost:5562&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    m = sock.recv()</span><br><span class="line">    mtype = m[<span class="number">0</span>]</span><br><span class="line">    topic = m[<span class="number">1</span>:]</span><br><span class="line">    <span class="keyword">if</span> mtype == <span class="string">&#x27;\x01&#x27;</span>:</span><br><span class="line">        print(<span class="string">&#x27;SUB %s&#x27;</span> % topic)</span><br><span class="line">    <span class="keyword">elif</span> mtype == <span class="string">&#x27;\x00&#x27;</span>:</span><br><span class="line">        print(<span class="string">&#x27;UNSUB %s&#x27;</span> % topic)</span><br></pre></td></tr></table></figure>



<ul>
<li>stats</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tnetstring</span><br><span class="line"><span class="keyword">import</span> zmq</span><br><span class="line"></span><br><span class="line">ctx = zmq.Context()</span><br><span class="line">sock = ctx.socket(zmq.SUB)</span><br><span class="line">sock.connect(<span class="string">&#x27;ipc:///var/run/pushpin/pushpin-stats&#x27;</span>)</span><br><span class="line">sock.setsockopt(zmq.SUBSCRIBE, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    m_raw = sock.recv()</span><br><span class="line">    mtype, mdata = m_raw.split(<span class="string">&#x27; &#x27;</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> mdata[<span class="number">0</span>] != <span class="string">&#x27;T&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;unsupported format&#x27;</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    m = tnetstring.loads(mdata[<span class="number">1</span>:])</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;%s %s&#x27;</span> % (mtype, m)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Websocket</category>
      </categories>
      <tags>
        <tag>Websocket</tag>
        <tag>Proxy</tag>
        <tag>ZeroMQ</tag>
        <tag>ZMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Guide Notes</title>
    <url>/2020/08/01/python-guide-notes/</url>
    <content><![CDATA[<h3 id="Pipenv"><a href="#Pipenv" class="headerlink" title="Pipenv"></a>Pipenv</h3><h4 id="安装-pipenv"><a href="#安装-pipenv" class="headerlink" title="安装 pipenv"></a>安装 pipenv</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 安装 pipenv</span><br><span class="line">pip3 install --user pipenv</span><br><span class="line"></span><br><span class="line"># 输出用户基础目录</span><br><span class="line">python3 -m site --user-base </span><br><span class="line"></span><br><span class="line"># 将用户基础目录&#x2F;bin 添加到系统 PATH 中, 例如</span><br><span class="line"># export PATH&#x3D;$PAHT:&#x2F;python_user_base_path&#x2F;bin</span><br><span class="line"></span><br><span class="line">pipenv -h</span><br></pre></td></tr></table></figure>


<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>安装依赖 <code>requests</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入项目目录</span></span><br><span class="line">cd hellopython</span><br><span class="line"><span class="comment"># 安装依赖（requests), 成功后目录下包含 Pipfile 文件</span></span><br><span class="line">pipenv install requests</span><br></pre></td></tr></table></figure>


<p>创建 <code>main.py</code> 文件，使用  <code>requests</code> 依赖</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">&#x27;https://httpbin.org/ip&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Your IP is &#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(response.json()[<span class="string">&#x27;origin&#x27;</span>]))</span><br></pre></td></tr></table></figure>


<p>运行 <code>main.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pipenv run python main.py</span><br><span class="line"><span class="comment"># 输出示例</span></span><br><span class="line">Your IP <span class="keyword">is</span> <span class="number">123.123</span><span class="number">.123</span><span class="number">.123</span></span><br></pre></td></tr></table></figure>


<h3 id="Virtualenv"><a href="#Virtualenv" class="headerlink" title="Virtualenv"></a>Virtualenv</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip3 install virtualenv</span><br><span class="line">virtualenv --version</span><br></pre></td></tr></table></figure>


<h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><p>初始化工程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir hellopython-virtualenv</span><br><span class="line">cd hellopython-virtualenv</span><br></pre></td></tr></table></figure>
<p>创建虚拟环境 <code>venv</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">virtualenv venv</span><br><span class="line"># 激活 venv</span><br><span class="line">source venv&#x2F;bin&#x2F;activate</span><br><span class="line"># 停用当前虚拟环境</span><br><span class="line"># deactivate</span><br><span class="line"># 删除虚拟环境（删除对应文件夹）</span><br><span class="line"># rm -rf venv</span><br></pre></td></tr></table></figure>
<p>安装依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Programming Language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pipenv</tag>
        <tag>virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 2.7 Notes</title>
    <url>/2020/06/06/python-notes/</url>
    <content><![CDATA[<h2 id="安装-python-2-7"><a href="#安装-python-2-7" class="headerlink" title="安装 python 2.7"></a>安装 python 2.7</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt-get install python</span><br><span class="line">apt-get install python-pip</span><br></pre></td></tr></table></figure>
<h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><ol>
<li>安装通过 import 生成依赖文件（如果存在依赖文件，即可忽略）<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install pipreqs</span><br><span class="line">pipreqs .&#x2F;</span><br></pre></td></tr></table></figure></li>
<li>安装依赖<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>
<h2 id="执行程序"><a href="#执行程序" class="headerlink" title="执行程序"></a>执行程序</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python xxx.py</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <categories>
        <category>Programming Language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pipreqs</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ Practice - Architecture Learn</title>
    <url>/2017/11/09/rocketmq-practice-architecture-learn/</url>
    <content><![CDATA[<p>Apache RocketMQ 是一个分布式消息及流处理平台，具有低延迟、高性能和可靠性，以及万亿级容量和灵活的扩展性。</p>
<h2 id="体系架构"><a href="#体系架构" class="headerlink" title="体系架构"></a>体系架构</h2><p><img src="/images/rocketmq/rmq-basic-arc.png" alt="image"></p>
<p>RocketMQ 主要包含 4 部分，它们中的每一部分都可以在非单点失败的情况下进行水平扩展。</p>
<ul>
<li>NameServers</li>
<li>Brokers</li>
<li>Producers</li>
<li>Consumers</li>
</ul>
<h3 id="NameServer-Cluster（命名服务集群）"><a href="#NameServer-Cluster（命名服务集群）" class="headerlink" title="NameServer Cluster（命名服务集群）"></a>NameServer Cluster（命名服务集群）</h3><p>NameServers 提供发现和路由的轻量级服务。集群中每个 NameServer 记录完整的路由信息，提供相应的读写服务，支持快速存储扩展。</p>
<h4 id="NameServer（命名服务）"><a href="#NameServer（命名服务）" class="headerlink" title="NameServer（命名服务）"></a>NameServer（命名服务）</h4><p>NameServer 是一个功能齐全的服务，主要包含以下 2 个特性：</p>
<ul>
<li><p>Broker 管理 </p>
<p>NameServer 接受来自 Broker 集群的注册，并提供监测 Broker 是否存活的心跳机制。</p>
</li>
<li><p>路由管理</p>
<p>每个 NameServer 保存 Broker集群的整个路由信息以及客户端查询的队列信息。</p>
</li>
</ul>
<p>正如我们所知，RocketMQ 客户端（Producer &amp; Consumer）通过 NameServer 获取队列路由信息，但客户端是如何知道 NameServer 地址的呢？获取 NameServer 地址列表的 4 种方式：</p>
<ul>
<li>编写程序 <code>producer.setNamesrvAddr(&quot;ip:port&quot;)</code></li>
<li>Java 选项 <code>rocketmq.namesrv.addr</code></li>
<li>环境变量 <code>NAMESRV_ADDR</code></li>
<li>HTTP 端点</li>
</ul>
<h3 id="Broker-Cluster（代理集群）"><a href="#Broker-Cluster（代理集群）" class="headerlink" title="Broker Cluster（代理集群）"></a>Broker Cluster（代理集群）</h3><p>Brokers 通过轻量级的 TOPIC 和 QUEUE 机制满足消息存储。他们支持 Push 和 Pull 两种模式，包含容错机制（拷贝2-3份），并提供了强大的填补高峰和积累数以百亿计的消息在其原来的时间顺序的能力<code>(这句没看懂)</code> 。此外，Brokers 也提供灾难恢复，丰富的指标统计和预警机制。</p>
<h4 id="Broker-Server（代理服务）"><a href="#Broker-Server（代理服务）" class="headerlink" title="Broker Server（代理服务）"></a>Broker Server（代理服务）</h4><p>Broker Server 负责消息的存储、交付、消息查询与 HA 保证等。</p>
<p><img src="/images/rocketmq/rmq-basic-component.png" alt="image"></p>
<p>Broker Server 重要的子模块：</p>
<ul>
<li>远程模块 - Broker 入口，处理来自客户端的请求。</li>
<li>客户端管理 - 管理客户端（Producer &amp; Consumer）和维护消费者的主题订阅。</li>
<li>存储服务 - 提供简单的API来存储或查询物理磁盘中的消息。</li>
<li>HA 服务 - 提供主从 Broker 间的数据同步功能。</li>
<li>索引服务 - 按指定的键为消息建立索引，并提供快速的消息查询。</li>
</ul>
<h3 id="Producer-Cluster（生产者集群）"><a href="#Producer-Cluster（生产者集群）" class="headerlink" title="Producer Cluster（生产者集群）"></a>Producer Cluster（生产者集群）</h3><p>Producers 支持分布式部署。分布式 Producers 通过负载均衡模型向 Brokers 集群发送消息，发送过程支持快速失败及低延迟。</p>
<h3 id="Consumer-Cluster（消费者集群）"><a href="#Consumer-Cluster（消费者集群）" class="headerlink" title="Consumer Cluster（消费者集群）"></a>Consumer Cluster（消费者集群）</h3><p>Consumers 在 Push 和 Pull 两种模式下支持分布式部署。它也支持集群消费和消息广播。它提供实时的消息订阅机制，可以满足大多数消费者的需求。</p>
<hr>
<p>更多信息请参考官方：<a href="https://rocketmq.apache.org/">https://rocketmq.apache.org/</a></p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>Rocketmq Practice - Core Concept</title>
    <url>/2017/11/10/rocketmq-practice-core-concept/</url>
    <content><![CDATA[<blockquote>
<p>本文是对官方原文的理解翻译，利于自己更好的理解 RocketMQ。</p>
</blockquote>
<h2 id="Producer（生产者）"><a href="#Producer（生产者）" class="headerlink" title="Producer（生产者）"></a>Producer（生产者）</h2><p>Producer 将业务应用系统生成的消息发送到 Broker。RocketMQ 提供多种发送模式：同步、异步和单向。</p>
<h3 id="Producer-Group（生产者组）"><a href="#Producer-Group（生产者组）" class="headerlink" title="Producer Group（生产者组）"></a>Producer Group（生产者组）</h3><p>相同角色的 Producer 会组织在一起。当原有的 Producer 在交易之后崩溃时，Broker 会协调同一组内不同的 Producer 完成相应事务的提交或回退。</p>
<p>注意：每个 Producer 组只会允许一个实例，以避免不必要的实例初始化。</p>
<h2 id="Consumer（消费者）"><a href="#Consumer（消费者）" class="headerlink" title="Consumer（消费者）"></a>Consumer（消费者）</h2><p>Consumer 从 Broker 拉取消息并将其提供给应用程序。从应用的角度来看，有两种类型的 Consumer：</p>
<h3 id="PullConsumer（拉取消费者）"><a href="#PullConsumer（拉取消费者）" class="headerlink" title="PullConsumer（拉取消费者）"></a>PullConsumer（拉取消费者）</h3><p>PullConsumer 从 Broker 拉取消息。当消息被拉取后，应用程序启动相应的消费处理程序。</p>
<h3 id="PushConsumer（推送消费者）"><a href="#PushConsumer（推送消费者）" class="headerlink" title="PushConsumer（推送消费者）"></a>PushConsumer（推送消费者）</h3><p>PushConsumer 封装了消息拉取、消耗进度及其他维护工作，提供一个回调接口用于在消息最终到达时实现业务逻辑处理。</p>
<h3 id="Consumer-Group（消费者组）"><a href="#Consumer-Group（消费者组）" class="headerlink" title="Consumer Group（消费者组）"></a>Consumer Group（消费者组）</h3><p>类似上面提到的 Producer Group，相同角色的 Consumer 会组织在一起并命名为 Consumer Group。</p>
<p>Consumer Group 是一个很好的概念，在消息消费方面实现负载均衡和容错目标是非常容易的。</p>
<p>注意：Consumer Group 中的Consumer 实例必须有完全相同的主题订阅。</p>
<h2 id="Topic（主题）"><a href="#Topic（主题）" class="headerlink" title="Topic（主题）"></a>Topic（主题）</h2><p>Topic 是一个类别，用于 Producer 传递消息和 Consumer 拉取消息。Topic 与 Producer 和 Consumer 之间的关系是松散的。</p>
<p>具体来说，一个 Topic 可以由零个、一个或多个 Producer 向它发送消息；相反地，一个 Producer 能够发送消息到不同的 Topic。</p>
<p>从 Consumer 的角度来看，一个 Topic 可以由零个、一个或多个 Consumer Group 订阅。同样， 一个 Consumer Group 可以订阅一个或多个 Topic，只要这个组内保持订阅的一致。</p>
<h2 id="Message（消息）"><a href="#Message（消息）" class="headerlink" title="Message（消息）"></a>Message（消息）</h2><p>Message 是要传递的信息。一个消息必须有一个主题，就像信件的邮件地址一样。</p>
<p>一个消息可能包含可选的标签和额外的键值对。例如，你可能给消息设置一个业务密钥，能够在 Broker 上查找消息，在开发时期进行问题诊断。</p>
<h3 id="Message-Queue（消息队列）"><a href="#Message-Queue（消息队列）" class="headerlink" title="Message Queue（消息队列）"></a>Message Queue（消息队列）</h3><p>Topic 被分为一个或多个子主题，称为“消息队列”。</p>
<h3 id="Tag（标签）"><a href="#Tag（标签）" class="headerlink" title="Tag（标签）"></a>Tag（标签）</h3><p>Tag ，为用户提供额外的灵活性。使用 Tag ，来自相同的业务模块具有不同目的的消息，可能具体相同的主题和不同的标签。Tags 能够有助于保持代码的整洁与连贯，并且 Tags 也可以方便 RoketMQ 提供的查询系统。</p>
<h3 id="Broker（中间件）"><a href="#Broker（中间件）" class="headerlink" title="Broker（中间件）"></a>Broker（中间件）</h3><p>Broker 是 RocketMQ 系统的主要组件。它接收来自 Producers 的消息、存储他们并准备处理来自 Consumers 的请求。同时它还存储消息相关的元数据，包含 Consumer Groups，消费进度偏移和主题/队列信息。</p>
<h2 id="Name-Server（命名服务）"><a href="#Name-Server（命名服务）" class="headerlink" title="Name Server（命名服务）"></a>Name Server（命名服务）</h2><p>Name Server 提供路由信息。Producer 和 Consumer 客户端查找主题以获取相应的 Broker 列表。</p>
<h2 id="Message-Model（消息模型）"><a href="#Message-Model（消息模型）" class="headerlink" title="Message Model（消息模型）"></a>Message Model（消息模型）</h2><ul>
<li>Clustering（集群）</li>
<li>Broadcasting（广播）</li>
</ul>
<h2 id="Message-Order（消息顺序）"><a href="#Message-Order（消息顺序）" class="headerlink" title="Message Order（消息顺序）"></a>Message Order（消息顺序）</h2><p>当使用 DefaultMQPushConsumer 时，你可以决定是有序的或并发的。</p>
<ul>
<li><p>有序的</p>
<p>有序的消费消息意味着 Consumer 按照 Producer 发送的消息顺序进行消费。如果处理需要强制使用全局顺序的情况，请确保使用的主题只有一个消息队列。</p>
<p>如果指定有序消费，则消费消息的最大并发数是订阅消息的消费者组数量。</p>
</li>
<li><p>并发的</p>
<p>当消费消息是并发的，消费消息的最大并发数受限于为每个消费者指定的线程池。</p>
<p>在这种模式下，不再保证消息的顺序。</p>
</li>
</ul>
<hr>
<p>官方原文：<a href="https://rocketmq.apache.org/docs/core-concept/">https://rocketmq.apache.org/docs/core-concept/</a> </p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ Practice - Quickstart</title>
    <url>/2017/11/09/rocketmq-practice-quickstart/</url>
    <content><![CDATA[<blockquote>
<p>本文实践环境说明：Windows 10 专业版，JDK 1.8.0_65。</p>
</blockquote>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="http://rocketmq.apache.org/dowloading/releases/">http://rocketmq.apache.org/dowloading/releases/</a></p>
<p>解压 <code>rocketmq-all-4.1.0-incubating-bin-release.zip</code> 到 <code>&lt;rocketmq-installed-dir&gt;</code></p>
<h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><p>启动 NameServer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ROCKETMQ_HOME%&#x2F;bin&#x2F;mqnamesrv -n 127.0.0.1:9876 &gt;E:\logs\mqnamesrv.log</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The Name Server boot success. serializeType=JSON</p>
</blockquote>
<p>启动 Broker</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ROCKETMQ_HOME%&#x2F;bin&#x2F;mqbroker -n 127.0.0.1:9876 &gt;E:\mqbroker.log</span><br></pre></td></tr></table></figure>
<h2 id="运行客户端"><a href="#运行客户端" class="headerlink" title="运行客户端"></a>运行客户端</h2><p>配置环境变量： <code>NAMESRV_ADDR</code> -&gt; <code>127.0.0.1:9876</code></p>
<p>发送消息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ROCKETMQ_HOME%&#x2F;bin&#x2F;tools org.apache.rocketmq.example.quickstart.Producer</span><br></pre></td></tr></table></figure>
<blockquote>
<p>SendResult [sendStatus=SEND_OK, msgId=0A00BF859C787EA987AC2DCBCA8A0354, offsetMsgId=0A00BF8500002A9F00000000000256A2, messageQueue=MessageQueue [topic=TopicTest, brokerName=Dawn, queueId=0], queueOffset=213]<br>SendResult [sendStatus=SEND_OK, msgId=0A00BF859C787EA987AC2DCBCA8C0355, offsetMsgId=0A00BF8500002A9F0000000000025756, messageQueue=MessageQueue [topic=TopicTest, brokerName=Dawn, queueId=1], queueOffset=213]<br>SendResult [sendStatus=SEND_OK, ……</p>
</blockquote>
<p>接收消息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ROCKETMQ_HOME%&#x2F;bin&#x2F;tools org.apache.rocketmq.example.quickstart.Consumer</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ConsumeMessageThread_2 Receive New Messages: [MessageExt [queueId=1, storeSize=180, queueOffset=249, sysFlag=0, bornTimestamp=1510233930866, bornHost=/10.0.191.133:10130, storeTimestamp=1510233930867, storeHost=/10.0.191.133:10911, msgId=0A00BF8500002A9F000000000002BC96, commitLogOffset=179350, bodyCRC=1102156316, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties={MIN_OFFSET=0, MAX_OFFSET=250, CONSUME_START_TIME=1510233997434, UNIQ_KEY=0A00BF859C787EA987AC2DCBCC7203E5, WAIT=true, TAGS=TagA}, body=18]]]<br>ConsumeMessageThread_1 Receive New Messages: [MessageExt [queueId=1, storeSize=180, queueOffset=248, sysFlag=0, bornTimestamp=1510233930852, bornHost=/10.0.191.133:10130, storeTimestamp=1510233930854, storeHost=/10.0.191.133:10911, …</p>
</blockquote>
<h2 id="停止服务"><a href="#停止服务" class="headerlink" title="停止服务"></a>停止服务</h2><p>停止 Broker</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ROCKETMQ_HOME%&#x2F;bin&#x2F;mqshutdown broker</span><br></pre></td></tr></table></figure>
<blockquote>
<p>killing broker<br>成功: 已终止 PID 为 42376 的进程。<br>Done!</p>
</blockquote>
<p>停止 NameServer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%ROCKETMQ_HOME%&#x2F;bin&#x2F;mqshutdown namesrv</span><br></pre></td></tr></table></figure>
<blockquote>
<p>killing name server<br>成功: 已终止 PID 为 39464 的进程。<br>Done!</p>
</blockquote>
<hr>
<p>官方快速起步：<a href="https://rocketmq.apache.org/docs/quick-start/">https://rocketmq.apache.org/docs/quick-start/</a></p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Message Queue</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>JAAS 笔记</title>
    <url>/2021/03/04/security-jaas-notes/</url>
    <content><![CDATA[<h2 id="Introduce"><a href="#Introduce" class="headerlink" title="Introduce"></a>Introduce</h2><p><strong>Java身份认证和授权服务 (Java Authentication and Authorization Service，JAAS)</strong></p>
<p>JAAS 可用于两个目的:</p>
<ul>
<li>认证（对于用户身份验证，可以可靠且安全地确定谁正在执行Java代码，而不管代码是作为应用程序、applet、bean还是servlet运行）</li>
<li>授权（对用户进行授权，以确保他们拥有执行操作所需的访问控制权限）</li>
</ul>
<p>JAAS 实现了标准可插入的认证模块（PAM: Pluggable Authentication Module ）框架的 Java 版本。</p>
<p>传统上，Java 提供了基于代码源的访问控制(基于代码来源和代码签名人的访问控制)。然而，它缺乏根据运行代码的人来增加访问控制的能力。JAAS 提供了一个框架，用这种支持扩展 Java 安全架构。</p>
<p>JAAS 身份验证是以可插拔的方式执行的。这允许应用程序独立于底层的身份验证技术。可以在应用程序下插入新的或更新的身份验证技术，而无需对应用程序本身进行修改。应用程序通过实例化 LoginContext 对象来启用身份验证过程，该对象引用 Configuration 来确定用于执行身份验证的身份验证技术或技术，或 LoginModule。典型的 LoginModules 可能会提示输入并验证用户名和密码。其他人可以阅读和验证声音或指纹样本。</p>
<p>执行代码的用户或服务经过身份验证后，JAAS授权组件与核心Java SE访问控制模型一起工作，以保护对敏感资源的访问。访问控制决策既基于执行代码的 CodeSource，也基于运行代码的用户或服务(由Subject对象表示)。如果身份验证成功，则由带有相关主体和凭据的LoginModule更新主题。</p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><h3 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h3><p><img src="/images/jaas/jaas-authn.jpg" alt="jaas-authn"></p>
<h3 id="Authorization"><a href="#Authorization" class="headerlink" title="Authorization"></a>Authorization</h3><p><img src="/images/jaas/protdom.gif" alt="protdom"></p>
<h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><h3 id="核心类和接口"><a href="#核心类和接口" class="headerlink" title="核心类和接口"></a>核心类和接口</h3><p>JAAS 相关的核心类和接口可以分为三类: <strong>通用类</strong>、<strong>身份验证类</strong>和<strong>授权类</strong>。</p>
<h4 id="通用类"><a href="#通用类" class="headerlink" title="通用类"></a>通用类</h4><p>通用类是由 JAAS 身份验证和授权组件共享的类。</p>
<p>关键的 JAAS 类是 javax.security.auth.Subject，它表示单个实体(如个人)的相关信息的分组。它包含实体的主体、公共凭证和私有凭证。</p>
<ul>
<li><p>Subject</p>
<p>要授权对资源的访问，应用程序首先需要对请求的源进行身份验证。JAAS 框架定义了 Subject 这个术语来表示请求的来源。Subject 可以是任何实体，如个人或服务。一旦主体被认证，一个 javax.security.auth.Subject 由相关的标识或身份(Principal)填充。</p>
<p>Subject 还可以拥有与安全性相关的属性，这些属性称为凭据。需要特殊保护的敏感凭据(如私有密钥)存储在私有凭据集中。要共享的凭据(如公钥证书)存储在公共凭据集中。访问和修改不同的凭据集需要不同的权限。</p>
<p><strong>doAs versus doAsPrivileged</strong></p>
<p>doAsPrivileged 方法的行为与 doAs 方法完全相同，只是它们没有将提供的 Subject 与当前 Thread 的 AccessControlContext 关联起来，而是使用提供的 AccessControlContext。通过这种方式，可以通过与当前的 AccessControlContexts 不同的方式来限制操作。</p>
</li>
<li><p>Principals</p>
<p>一个主体(Subject)可能会有多个身份(Principal)。</p>
</li>
<li><p>Credentials</p>
<p>除了关联的主体之外，Subject 还可以拥有与安全相关的属性，这些属性称为凭据。凭据可以包含用于对新服务的主题进行身份验证的信息。这些凭据包括密码、 Kerberos 票证和公钥证书。凭据还可能包含仅允许主体执行某些活动的数据。例如，加密密钥表示允许主体签名或加密数据的凭据。公共和私有凭据类不是核心 JAAS 类库的一部分。因此，任何类都可以表示凭据。</p>
<p>公共和私有凭据类不是核心 JAAS 类库的一部分。然而，开发者可能会选择让他们的凭证类实现与凭证相关的两个接口:  Refreshable 和 Destroyable。</p>
<ul>
<li><code>javax.security.auth.Refreshable</code> 接口提供了凭据刷新自身的功能。</li>
<li><code>javax.security.auth.Destroyable</code> 接口提供了销毁凭证内容的功能。</li>
</ul>
</li>
</ul>
<h4 id="身份验证类和接口"><a href="#身份验证类和接口" class="headerlink" title="身份验证类和接口"></a>身份验证类和接口</h4><p>身份验证代表验证主体身份的过程，并且必须以安全的方式执行; 否则犯罪者可能冒充他人以获得对系统的访问权。认证通常涉及主体提供某种形式的凭证来证明其身份。这种证据可能是只有当事人可能知道或拥有的信息(如密码或指纹) ，也可能是只有当事人可以提供的信息(如使用私人钥匙签名的数据)。</p>
<ul>
<li><p>LoginContext</p>
<p>LoginContext 类提供了用于对 Subject 进行身份验证的基本方法，并提供了一种独立于底层身份验证技术的应用程序开发方法。LoginContext 查询 Configuration 以确定为特定应用程序配置的身份验证服务或 LoginModule。因此，可以在应用程序下插入不同的 LoginModule，而不需要对应用程序本身进行任何修改。</p>
</li>
<li><p>LoginModule</p>
<p>LoginModule 接口使开发人员能够实现应用程序下可以插入的各种身份验证技术。例如，一种类型的 LoginModule 可能执行基于用户名/密码的身份验证形式。其他的 LoginModule 可以与硬件设备接口，如智能卡或生物识别设备。</p>
</li>
<li><p>CallbackHandler</p>
<p>在某些情况下，LoginModule 必须与用户通信以获取身份验证信息。</p>
<p>应用程序实现 CallbackHandler 接口并将其传递给 LoginContext，后者直接将其转发给底层 LoginModules。LoginModule 使用 CallbackHandler 收集用户的输入(例如密码或智能卡密码) ，或者向用户提供信息(例如状态信息)。通过允许应用程序指定 CallbackHandler，底层 LoginModules 可以保持独立于应用程序与用户交互的不同方式。</p>
<p>LoginModule 向 CallbackHandler handle 方法传递一个适当的 Callbacks 数组，例如用于用户名的 NameCallback 和用于密码的 PasswordCallback，CallbackHandler 执行请求的用户交互并在 Callbacks 中设置适当的值。例如，要处理 NameCallback，CallbackHandler 可能会提示输入名称，从用户检索值，并调用 NameCallback 的 setName 方法来存储名称。</p>
</li>
<li><p>Callback</p>
<p>LoginModules 可以直接将 Callback 数组传递给 CallbackHandler 的 handle 方法。</p>
</li>
</ul>
<h4 id="授权类"><a href="#授权类" class="headerlink" title="授权类"></a>授权类</h4><p>要使 JAAS 授权发生，授予访问控制权限不仅要基于运行的代码，还要基于运行代码的人，需要以下几点：</p>
<ol>
<li><p>必须经过身份验证</p>
</li>
<li><p>身份验证结果的主体(Subject)必须与访问控制上下文关联</p>
</li>
<li><p>必须在安全策略中配置基于身份(Principal)的项</p>
</li>
</ol>
<ul>
<li><p>Policy</p>
<p>策略类是用于表示系统范围的访问控制策略的抽象类。策略 API 支持基于身份(Principal)的查询。</p>
<p>缺省情况下，JDK 提供了一个基于文件的子类实现，它被升级为支持策略文件中基于身份的授权条目。</p>
</li>
<li><p>AuthPermission<br>当前，AuthPermission 对象用于保护对 Policy、 Subject、 LoginContext 和 Configuration 对象的访问。</p>
</li>
</ul>
<h3 id="java-Security-Properties-文件中的-JAAS-设置"><a href="#java-Security-Properties-文件中的-JAAS-设置" class="headerlink" title="java.Security Properties 文件中的 JAAS 设置"></a>java.Security Properties 文件中的 JAAS 设置</h3><p>许多与 JAAS 相关的设置可以在 java.Security 主安全属性文件中配置，该文件位于 JDK 的 conf/Security 目录中。</p>
<ul>
<li><p>Login Configuration Provider</p>
<p>默认的 JAAS 登录配置实现可以通过在 login.configuration.provider 属性中指定替代的 provider 类实现来替换。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">login.configuration.provider</span>=<span class="string">com.foo.Config</span></span><br></pre></td></tr></table></figure>
<p>如果没有找到 Security 属性 login.configuration.provider，或者没有指定，那么它将被设置为缺省值:</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">login.configuration.provider</span>=<span class="string">com.sun.security.auth.login.ConfigFile</span></span><br></pre></td></tr></table></figure>
<p><strong>注意，没有办法从命令行动态设置登录配置提供程序。</strong></p>
</li>
<li><p>Login Configuration URLs</p>
<p>如果使用的登录配置实现期望在文件中指定配置信息，则可以通过在 login.configurl.n 属性中指定各自的 url 静态设置登录配置文件的位置。N’是一个连续编号的整数，从1开始。如果指定了多个配置文件(如果 n &gt; = 2) ，它们将被读取并合并为单个配置。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">login.config.url.1</span>=<span class="string">file:C:/config/.java.login.config</span></span><br><span class="line"><span class="meta">login.config.url.2</span>=<span class="string">file:C:/users/foo/.foo.login.config</span></span><br></pre></td></tr></table></figure>
<p>如果配置文件的位置没有在 java.security 属性文件中设置，也没有在命令行中动态指定(通过-Djava.security.auth.login.config 选项) ，JAAS 将尝试从 <code>file:$&#123;user.home&#125;/.java.login.config</code> 加载默认配置。</p>
</li>
<li><p>Policy Provider</p>
<p>可以通过在 policy.provider 属性中指定替代提供程序类实现来替换默认策略实现。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">policy.provider</span>=<span class="string">com.foo.Policy</span></span><br></pre></td></tr></table></figure>
<p>如果找不到 Security 属性 Policy.provider，或者未指定，则策略将设置为默认值:</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">policy.provider</span>=<span class="string">sun.security.provider.PolicyFile</span></span><br></pre></td></tr></table></figure>
<p><strong>请注意，不存在从命令行动态设置策略提供程序的方法。</strong></p>
</li>
<li><p>Policy File URLs</p>
<p>通过在 auth.policy.url.n 属性中指定各自的 url，可以静态设置访问控制策略文件的位置。N 是一个连续编号的整数，从1开始。如果指定了多个策略(如果 n &gt; = 2) ，它们将被读取并合并为一个策略。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">policy.url.1</span>=<span class="string">file:C:/policy/.java.policy</span></span><br><span class="line"><span class="meta">policy.url.2</span>=<span class="string">file:C:/users/foo/.foo.policy</span></span><br></pre></td></tr></table></figure>
<p>如果策略文件的位置没有在 java.security 属性文件中设置，也没有从命令行(通过 -Djava.security.policy 选项)动态指定，那么访问控制策略默认为与 JDK 安装的系统策略文件相同的策略。</p>
<ul>
<li>将所有权限授予标准扩展</li>
<li>允许任何人监听非特权端口</li>
<li>允许任何代码读取某些不敏感于安全性的“标准”属性，如 os.name 和 file.separator 属性。</li>
</ul>
</li>
</ul>
<h2 id="JAAS-教程和示例程序"><a href="#JAAS-教程和示例程序" class="headerlink" title="JAAS 教程和示例程序"></a>JAAS 教程和示例程序</h2><p><a href="https://github.com/shankai/sample-jaas">https://github.com/shankai/sample-jaas</a></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://docs.oracle.com/en/java/javase/11/security/java-authentication-and-authorization-service-jaas1.html">https://docs.oracle.com/en/java/javase/11/security/java-authentication-and-authorization-service-jaas1.html</a></p>
]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>JAAS</tag>
        <tag>Authentication</tag>
        <tag>Authorization</tag>
      </tags>
  </entry>
  <entry>
    <title>SASL 笔记</title>
    <url>/2021/03/07/security-sasl-notes/</url>
    <content><![CDATA[<h2 id="Introduce"><a href="#Introduce" class="headerlink" title="Introduce"></a>Introduce</h2><p>简单身份验证和安全层(Simple Authentication and Security Layer，简称SASL)是一种Internet标准(<a href="http://www.ietf.org/rfc/rfc2222.txt">RFC 2222</a>)，它指定了用于身份验证和可选地在客户机和服务器应用程序之间建立安全层的协议。SASL定义了如何交换身份验证数据，但本身并不指定该数据的内容。它是一个框架，指定身份验证数据的内容和语义的特定身份验证机制可以融入其中。</p>
<p>SASL被协议(如轻量级目录访问协议版本3 (LDAP v3)和Internet消息访问协议版本4 (IMAP v4))用于启用可插拔身份验证。LDAP v3和IMAP v4没有将身份验证方法硬连接到协议中，而是使用SASL执行身份验证，从而通过各种SASL机制启用身份验证。</p>
<p>Internet社区为不同级别的安全性和部署场景定义了许多标准的SASL机制。这些级别的范围从无安全性(例如，匿名身份验证)到高安全性(例如，Kerberos身份验证)以及介于两者之间的级别。</p>
<p><strong>The Java SASL API</strong></p>
<p>Java SASL API为使用SASL机制的应用程序定义了类和接口。它被定义为与机制无关的:使用API的应用程序不需要硬连接到使用任何特定的SASL机制。该API支持客户机和服务器应用程序。它允许应用程序根据所需的安全特性选择要使用的机制，比如它们是否容易受到被动字典攻击，或者它们是否接受匿名身份验证。<br>Java SASL API还允许开发人员使用他们自己的自定义SASL机制。通过使用Java加密体系结构(JCA)安装SASL机制。</p>
<p><strong>When to Use SASL</strong></p>
<p>SASL为网络应用程序提供了可插拔的身份验证和安全层。Java SE中还有其他特性提供类似的功能，包括Java安全套接字扩展(JSSE)和Java通用安全服务(Java GSS)。JSSE为SSL和TLS协议的Java语言版本提供了一个框架和实现。Java GSS是通用安全服务应用程序编程接口(GSS- api)的Java语言绑定。Java SE上这个API目前支持的唯一机制是Kerberos v5。<br>与JSSE和Java GSS相比，SASL是相对轻量级的，并且在最近的协议中很流行。它还有一个优点，就是定义了几种流行的轻量级(在基础设施支持方面)SASL机制。另一方面，主要的JSSE和Java GSS机制具有相对重量级的机制，需要更详细的基础设施(分别是公钥基础设施和Kerberos)。</p>
<p>SASL、JSSE 和 Java GSS 通常一起使用。例如，一个常见的模式是应用程序使用 JSSE 建立安全通道，使用 SASL 进行客户端基于用户名/密码的身份验证。在 GSS-API 机制之上还有 SASL 机制；一个流行的示例是与 LDAP 一起使用的 SASL GSS-API/Kerberos v5 机制。</p>
<p>除了从头定义和构建协议之外，协议定义通常是决定使用哪个 API 的最大因素。例如，LDAP 和 IMAP 被定义为使用 SASL，因此与这些协议相关的软件应该使用 Java SASL API。在构建Kerberos 应用程序和服务时，使用的 API 是Java GSS。当构建使用 SSL/TLS 作为协议的应用程序和服务时，使用的 API 是JSSE。</p>
<h2 id="SASL-Architechture"><a href="#SASL-Architechture" class="headerlink" title="SASL Architechture"></a>SASL Architechture</h2><h3 id="SASL-Architechture-1"><a href="#SASL-Architechture-1" class="headerlink" title="SASL Architechture"></a>SASL Architechture</h3><p><img src="/images/sasl/sasl-archit.png" alt="sasl-archit"></p>
<h3 id="SASL-Life-Cycle"><a href="#SASL-Life-Cycle" class="headerlink" title="SASL Life Cycle"></a>SASL Life Cycle</h3><p><img src="/images/sasl/sasl-flowchart-overview.png" alt="sasl-flowchart-overview"></p>
<h3 id="SASL-Session-Initialization"><a href="#SASL-Session-Initialization" class="headerlink" title="SASL Session Initialization"></a>SASL Session Initialization</h3><p><img src="/images/sasl/sasl-flowchart-init.png" alt="sasl-flowchart-init"></p>
<h3 id="SASL-Authentication-Sending-Client-Data"><a href="#SASL-Authentication-Sending-Client-Data" class="headerlink" title="SASL Authentication: Sending Client Data"></a>SASL Authentication: Sending Client Data</h3><p><img src="/images/sasl/sasl-flowchart-auth.png" alt="sasl-flowchart-auth"></p>
<h3 id="SASL-Authentication-Processing-Server-Data"><a href="#SASL-Authentication-Processing-Server-Data" class="headerlink" title="SASL Authentication: Processing Server Data"></a>SASL Authentication: Processing Server Data</h3><p><img src="/images/sasl/sasl-flowchart-auth2.png" alt="sasl-flowchart-auth2"></p>
<h2 id="Java-SASL-API-Overview"><a href="#Java-SASL-API-Overview" class="headerlink" title="Java SASL API Overview"></a>Java SASL API Overview</h2><p>SASL 是一种挑战-响应协议。服务器向客户机发出质疑，客户机根据质疑发送响应。这种交换一直持续到服务器满意并且不发出进一步的挑战为止。这些挑战和响应是任意长度的二进制标记。封装协议(例如 LDAP 或 IMAP)指定了这些令牌的编码和交换方式。例如，LDAP 指定 SASL 标记如何封装在 LDAP 绑定请求和响应中。</p>
<p>Java SASL API是根据这种交互和使用风格建模的。它具有分别表示客户端和服务器端机制的接口 SaslClient 和 SaslServer。应用程序通过表示挑战和响应的字节数组与机制交互。服务器端机制迭代、发出挑战并处理响应，直到它满意为止，而客户端机制迭代、评估挑战并发出响应，直到服务器满意为止。使用该机制的应用程序驱动每次迭代。也就是说，它从协议包中提取挑战或响应，并将其提供给该机制，然后将该机制返回的响应或响应放入协议包中，并将其发送给对等体。</p>
<h2 id="How-SASL-Mechanisms-are-Installed-and-Selected"><a href="#How-SASL-Mechanisms-are-Installed-and-Selected" class="headerlink" title="How SASL Mechanisms are Installed and Selected"></a>How SASL Mechanisms are Installed and Selected</h2><p>SASL 机制实现由 SASL 安全提供者提供。每个提供者可以支持一个或多个 SASL 机制，并在 JCA 注册。</p>
<p>默认情况下，SunSASL 提供程序自动注册为 JCA 提供程序。若要将其作为 JCA 提供程序移除或重新排列其优先级，请更改 Java 安全属性文件(Java-home/conf/security/Java.security)。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">security.provider.7</span>=<span class="string">SunSASL</span></span><br></pre></td></tr></table></figure>
<p>若要添加或删除 SASL 提供程序，请在安全属性文件中添加或删除相应的行。</p>
<p>或者，可以使用 java.security.Security 以编程方式添加自己的提供程序。例如，下面的示例代码将 com.example.MyProvider 注册到可用的 SASL 安全提供程序列表中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Security.addProvider(<span class="keyword">new</span> com.example.MyProvider());</span><br></pre></td></tr></table></figure>
<h2 id="The-SunSASL-Provider"><a href="#The-SunSASL-Provider" class="headerlink" title="The SunSASL Provider"></a>The SunSASL Provider</h2><p>SunSASL 提供程序支持以下客户机和服务器机制：</p>
<ul>
<li>Client Mechanisms<ul>
<li>PLAIN (<a href="http://www.ietf.org/rfc/rfc2595.txt">RFC 2595</a>). This mechanism supports cleartext user name/password authentication.</li>
<li>CRAM-MD5 (<a href="http://www.ietf.org/rfc/rfc2195.txt">RFC 2195</a>). This mechanism supports a hashed user name/password authentication scheme.</li>
<li>DIGEST-MD5 (<a href="http://www.ietf.org/rfc/rfc2831.txt">RFC 2831</a>). This mechanism defines how HTTP Digest Authentication can be used as a SASL mechanism.</li>
<li>EXTERNAL (<a href="http://www.ietf.org/rfc/rfc2222.txt">RFC 2222</a>). This mechanism obtains authentication information from an external channel (such as TLS or IPsec).</li>
<li>NTLM. This mechanism supports NTLM authentication.</li>
</ul>
</li>
<li>Server Mechanisms<ul>
<li>CRAM-MD5</li>
<li>DIGEST-MD5</li>
<li>NTLM</li>
</ul>
</li>
</ul>
<h2 id="The-JdkSASL-Provider"><a href="#The-JdkSASL-Provider" class="headerlink" title="The JdkSASL Provider"></a>The JdkSASL Provider</h2><p>JdkSASL 提供程序支持以下客户机和服务器机制：</p>
<ul>
<li>Client Mechanisms<ul>
<li>GSSAPI (<a href="http://www.ietf.org/rfc/rfc2222.txt">RFC 2222</a>). This mechanism uses the <a href="http://www.ietf.org/rfc/rfc2078.txt">GSSAPI</a> for obtaining authentication information. It supports Kerberos v5 authentication.</li>
</ul>
</li>
<li>Server Mechanisms<ul>
<li>GSSAPI (Kerberos v5)</li>
</ul>
</li>
</ul>
<h2 id="Debugging-and-Monitoring"><a href="#Debugging-and-Monitoring" class="headerlink" title="Debugging and Monitoring"></a>Debugging and Monitoring</h2><p>SunSASL 和 JdkSASL 提供程序使用 Logging api 提供实现日志输出。这个输出可以通过使用日志配置文件和编程 API (java.util.logging)来控制。SunSASL 提供程序使用的日志记录器名称是 javax.security.sasl。下面是一个样例日志配置文件，它为 SunSASL 提供程序启用了 FINEST 日志级别：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">javax.security.sasl.level</span>=<span class="string">FINEST</span></span><br><span class="line"><span class="attr">handlers</span>=<span class="string">java.util.logging.ConsoleHandler</span></span><br><span class="line"><span class="meta">java.util.logging.ConsoleHandler.level</span>=<span class="string">FINEST</span></span><br></pre></td></tr></table></figure>
<h2 id="Implementing-a-SASL-Security-Provider"><a href="#Implementing-a-SASL-Security-Provider" class="headerlink" title="Implementing a SASL Security Provider"></a>Implementing a SASL Security Provider</h2><p>实现 SASL 安全提供商有三个基本步骤：</p>
<ol>
<li>编写一个实现 SaslClient 或 SaslServer 接口的类。</li>
<li>编写一个工厂类(实现 SaslClientFactory 或 SaslServerFactory) ，创建类的实例。</li>
<li>编写注册工厂的 JCA 提供程序。</li>
</ol>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://docs.oracle.com/en/java/javase/11/security/java-sasl-api-programming-and-deployment-guide1.html#GUID-6D78EE33-62E6-4D85-9695-322EED493F72">https://docs.oracle.com/en/java/javase/11/security/java-sasl-api-programming-and-deployment-guide1.html#GUID-6D78EE33-62E6-4D85-9695-322EED493F72</a></p>
<p><a href="https://docs.oracle.com/cd/E53394_01/html/E54753/sasl.intro.20.html">https://docs.oracle.com/cd/E53394_01/html/E54753/sasl.intro.20.html</a></p>
<p>（完）</p>
]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Authentication</tag>
        <tag>SASL</tag>
      </tags>
  </entry>
  <entry>
    <title>Nuclio Notes</title>
    <url>/2020/10/01/serverless-nuclio-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><blockquote>
<p>…</p>
</blockquote>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><h3 id="通过-Docker-运行-Nuclio"><a href="#通过-Docker-运行-Nuclio" class="headerlink" title="通过 Docker 运行 Nuclio"></a>通过 Docker 运行 Nuclio</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -p 8070:8070 -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock -v &#x2F;Users&#x2F;shankai&#x2F;DockerTmp:&#x2F;tmp --name nuclio-dashboard quay.io&#x2F;nuclio&#x2F;dashboard:stable-amd64</span><br></pre></td></tr></table></figure>
<h3 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http:&#x2F;&#x2F;localhost:8070&#x2F;projects</span><br></pre></td></tr></table></figure>


<h2 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><h2 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h2><h3 id="nuctl"><a href="#nuctl" class="headerlink" title="nuctl"></a>nuctl</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;nuclio&#x2F;nuclio&#x2F;releases</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Serverless</category>
      </categories>
      <tags>
        <tag>Nuclio</tag>
        <tag>FaaS</tag>
        <tag>Serverless</tag>
      </tags>
  </entry>
  <entry>
    <title>Tile38 Notes</title>
    <url>/2020/08/01/tile38-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>GeoJSON Preview </p>
<ul>
<li><p><a href="https://geojson.io/">https://geojson.io/</a></p>
</li>
<li><p><a href="http://geojson.tools/">http://geojson.tools/</a></p>
</li>
</ul>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## pull</span><br><span class="line">docker pull tile38&#x2F;tile38</span><br><span class="line">## run </span><br><span class="line">docker run -d -p 9851:9851 --name tile38-dev tile38&#x2F;tile38</span><br><span class="line">## in</span><br><span class="line">docker exec -it tile38-dev sh</span><br><span class="line">## tile38-cli</span><br><span class="line">tile38-cli</span><br></pre></td></tr></table></figure>


<h2 id="Command-Usage"><a href="#Command-Usage" class="headerlink" title="Command Usage"></a>Command Usage</h2><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><blockquote>
<p>SET key id [FIELD name value …] [EX seconds] [NX|XX] (OBJECT geojson)|(POINT lat lon [z])|(BOUNDS minlat minlon maxlat maxlon)|(HASH geohash)|(STRING value)</p>
</blockquote>
<h3 id="FSET"><a href="#FSET" class="headerlink" title="FSET"></a>FSET</h3><blockquote>
<p>FSET key id [XX] field value [field value …]</p>
</blockquote>
<h3 id="GET"><a href="#GET" class="headerlink" title="GET"></a>GET</h3><blockquote>
<p>GET key id [WITHFIELDS] [OBJECT|POINT|BOUNDS|(HASH geohash)]</p>
</blockquote>
<h3 id="EXPIRE"><a href="#EXPIRE" class="headerlink" title="EXPIRE"></a>EXPIRE</h3><p>Set a timeout on an id.</p>
<blockquote>
<p>EXPIRE key  id [seconds]</p>
</blockquote>
<h3 id="DEL"><a href="#DEL" class="headerlink" title="DEL"></a>DEL</h3><p>Remove a specified object.</p>
<blockquote>
<p>DEL fleet truck1</p>
</blockquote>
<h3 id="DROP"><a href="#DROP" class="headerlink" title="DROP"></a>DROP</h3><p>Remove all objects from specified key.</p>
<blockquote>
<p>DROP fleet</p>
</blockquote>
<h3 id="JSET"><a href="#JSET" class="headerlink" title="JSET"></a>JSET</h3><blockquote>
</blockquote>
]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Tile38</tag>
        <tag>Geo</tag>
        <tag>GeoJson</tag>
      </tags>
  </entry>
  <entry>
    <title>证书常用命令</title>
    <url>/2019/09/13/tls-certification-common-commands/</url>
    <content><![CDATA[<h2 id="证书介绍"><a href="#证书介绍" class="headerlink" title="证书介绍"></a>证书介绍</h2><h2 id="证书生成与格式转换"><a href="#证书生成与格式转换" class="headerlink" title="证书生成与格式转换"></a>证书生成与格式转换</h2><h3 id="Openssl"><a href="#Openssl" class="headerlink" title="Openssl"></a>Openssl</h3><h4 id="pfx-gt-pem"><a href="#pfx-gt-pem" class="headerlink" title="pfx -&gt; pem"></a>pfx -&gt; pem</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl pkcs12 -clcerts -nokeys -out one123456.pem -in one123456.pfx</span><br><span class="line">openssl pkcs12 -nocerts -out one123456.key.pem -in one123456.pfx</span><br><span class="line"></span><br><span class="line">openssl pkcs12 -clcerts -nokeys -out two123456.pem -in two123456.pfx</span><br><span class="line">openssl pkcs12 -nocerts -out two123456.key.pem -in two123456.pfx</span><br></pre></td></tr></table></figure>


<h4 id="crt-key-gt-p12"><a href="#crt-key-gt-p12" class="headerlink" title="crt + key -&gt; p12"></a>crt + key -&gt; p12</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl pkcs12 -export -in dop.crt -inkey dop.key -out dop.p12 -name dop -password pass:abcdef</span><br><span class="line">openssl pkcs12 -export -in wiki.crt -inkey wiki.key -out wiki.p12 -name wiki -password pass:abcdef</span><br></pre></td></tr></table></figure>


<h3 id="Keytool"><a href="#Keytool" class="headerlink" title="Keytool"></a>Keytool</h3><h4 id="cer-gt-jks"><a href="#cer-gt-jks" class="headerlink" title="cer -&gt; jks"></a>cer -&gt; jks</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">keytool -importcert -file CFCA_RSA_TEST_OCA21.cer -keystore cfca.jks -alias cfca</span><br><span class="line"></span><br><span class="line">keytool -importcert -file ca.cer -keystore cfca.jks -alias cfca</span><br><span class="line"></span><br><span class="line">keytool -import -alias cfcaalias -file cfca.cer -keystore trusted.keystore</span><br></pre></td></tr></table></figure>


<h4 id="crt-gt-jks"><a href="#crt-gt-jks" class="headerlink" title="crt -&gt; jks"></a>crt -&gt; jks</h4><p>keytool -import -alias alias -file ca.crt -keypass keypass -keystore ca.jks -storepass 123456 -noprompt</p>
<p>p12 -&gt; jks</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">keytool -importkeystore -srckeystore ca.p12 -srcstoretype PKCS12 -destkeystore ca.jks -deststoretype JKS</span><br></pre></td></tr></table></figure>


<h2 id="客户端认证"><a href="#客户端认证" class="headerlink" title="客户端认证"></a>客户端认证</h2><h3 id="curl"><a href="#curl" class="headerlink" title="curl"></a>curl</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -v --cert .&#x2F;tls.crt --key .&#x2F;tls.key https:&#x2F;&#x2F;qmsauthn.paas.service.sd&#x2F;login</span><br><span class="line"></span><br><span class="line">curl -k -v --cert .&#x2F;authn.crt --key .&#x2F;authn.key https:&#x2F;&#x2F;qmsauthn.pditdop:6443&#x2F;login</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>TLS</tag>
        <tag>Security</tag>
        <tag>Certification</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Vagrant Notes</title>
    <url>/2020/02/20/vagrant-notes/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Vagrant 是在单个工作流中构建和管理虚拟机环境的工具。</p>
<p>通过易于使用的工作流程和对自动化的关注，Vagrant 降低了开发环境的设置时间，增加了生产等价性，并使“在我的机器上可以工作”成为过去的借口。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Vagrant"><a href="#Vagrant" class="headerlink" title="Vagrant"></a>Vagrant</h3><p>在 <a href="https://www.vagrantup.com/downloads.html">下载页</a> 选择适合自己平台的安装包并进一步安装。安装完成后命令行确认结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant -v</span><br></pre></td></tr></table></figure>
<p>版本号：<code>Vagrant 2.2.7</code></p>
<h3 id="Virtual-Machine-Providers"><a href="#Virtual-Machine-Providers" class="headerlink" title="Virtual Machine Providers"></a>Virtual Machine Providers</h3><ul>
<li>VirtualBox</li>
<li>VMWare</li>
<li>AWS</li>
<li>Other provider</li>
</ul>
<h2 id="命令笔记"><a href="#命令笔记" class="headerlink" title="命令笔记"></a>命令笔记</h2><ul>
<li>虚拟机列表<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant box list</span><br></pre></td></tr></table></figure></li>
<li>添加本地虚拟机<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant box add ubuntu&#x2F;trusty64 ~&#x2F;Downloads&#x2F;trusty-server-cloudimg-amd64-vagrant-disk1.box</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p>（待续）</p>
]]></content>
      <categories>
        <category>OS&amp;VM&amp;LXC</category>
      </categories>
      <tags>
        <tag>Virtual</tag>
        <tag>Vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title>Vault  Notes</title>
    <url>/2020/08/01/vault-notes/</url>
    <content><![CDATA[<p>启动实例（开发环境）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --cap-add&#x3D;IPC_LOCK -e &#39;VAULT_DEV_ROOT_TOKEN_ID&#x3D;myroot&#39; -p 8200:8200 -d --name&#x3D;dev-vault vault</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker run --cap-add&#x3D;IPC_LOCK -e &#39;VAULT_DEV_ROOT_TOKEN_ID&#x3D;myroot&#39; -e &#39;VAULT_DEV_LISTEN_ADDRESS&#x3D;0.0.0.0:8200&#39; vault</span><br></pre></td></tr></table></figure>
<p>启动成功后，在启动日志中获取默认的 Token。如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Unseal Key: BRGYd/8vJSl5101boUHdXDu2ZfYTsJy5tdgXlvOyysQ=</span><br><span class="line">Root Token: myroot</span><br></pre></td></tr></table></figure>


<p>认证</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vault login myroot</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Vault</tag>
      </tags>
  </entry>
  <entry>
    <title>websocket-notes</title>
    <url>/2021/03/05/websocket-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h2 id="Samples"><a href="#Samples" class="headerlink" title="Samples"></a>Samples</h2><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><h3 id="Javascript"><a href="#Javascript" class="headerlink" title="Javascript"></a>Javascript</h3><h3 id="Nodejs"><a href="#Nodejs" class="headerlink" title="Nodejs"></a>Nodejs</h3>]]></content>
      <categories>
        <category>Websocket</category>
      </categories>
      <tags>
        <tag>Websocket</tag>
        <tag>Protocol</tag>
        <tag>Realtime</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 10 Install MySQL Community Server</title>
    <url>/2017/11/21/windows-10-install-mysql-community-server/</url>
    <content><![CDATA[<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>下载页面：<a href="https://dev.mysql.com/downloads/mysql/">https://dev.mysql.com/downloads/mysql/</a></p>
<p>本文使用的版本下载链接：</p>
<p><a href="https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.20-winx64.zip">https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.20-winx64.zip</a></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol>
<li><p>将下载的zip文件解压到指定的路径，如：D:\Softwares\mysql-5.7.20-winx64，以下以 [MYSQL_DIR] 代替。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd [MYSQL_DIR]&#x2F;bin</span><br></pre></td></tr></table></figure></li>
<li><p>初始化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; mysqld --initialize --user mysql --console</span><br></pre></td></tr></table></figure>
<p>执行成功后会生成一个临时密码：</p>
<blockquote>
<p>A temporary password is generated for root@localhost: <code>WjdKaOdBt5+0</code></p>
</blockquote>
</li>
<li><p>安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; mysqld -install</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Service successfully installed.</p>
</blockquote>
</li>
<li><p>启动服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; net start mysql</span><br></pre></td></tr></table></figure>
<blockquote>
<p>MySQL 服务正在启动.</p>
<p>MySQL 服务已经启动成功.</p>
</blockquote>
</li>
</ol>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><ol>
<li><p>登录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; mysql -u root -p</span><br></pre></td></tr></table></figure>
<p>Enter password：输入上面生成的临时密码</p>
<blockquote>
<p>Welcome to the MySQL monitor.  Commands end with ; or \g.<br>Your MySQL connection id is 3<br>Server version: 5.7.20</p>
</blockquote>
</li>
<li><p>修改密码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; alter user root@localhost identified by &quot;root&quot;;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Query OK, 0 rows affected (0.00 sec)</p>
</blockquote>
</li>
</ol>
<p>（完）</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>ZeroMQ 笔记</title>
    <url>/2021/03/09/zeromq-notes/</url>
    <content><![CDATA[<h2 id="Introduce"><a href="#Introduce" class="headerlink" title="Introduce"></a>Introduce</h2><p>ZeroMQ, 一个开源的通用消息库。</p>
<p>ZeroMQ(也拼作ØMQ、0MQ 或 ZMQ)是一个高性能异步消息传递库，旨在在分布式或并发应用程序中使用。它提供了一个消息队列，但与面向消息的中间件不同，ZeroMQ系统可以在没有专用消息代理的情况下运行。</p>
<p>ZeroMQ支持各种传输(TCP、进程内、进程间、多播、WebSocket等等)上的通用消息传递模式(发布/订阅、请求/应答、客户端/服务器等)，使进程间消息传递像线程间消息传递一样简单。这使你的代码清晰，模块化和极容易扩展。</p>
<p>ZeroMQ是由一个大型贡献者社区开发的。许多流行的编程语言都有第三方实现，C# 和 Java 也有 Native Ports。</p>
<blockquote>
<p><strong>ZeroMQ的哲学是从零开始的。零代表零代理(ZeroMQ是无代理的)、零延迟、零成本(它是免费的)和零管理。更普遍地说，“零”指的是渗透到项目中的极简主义文化。我们通过消除复杂性而不是暴露新功能来增加功能。</strong></p>
</blockquote>
<h3 id="Libzmq-the-low-level-library"><a href="#Libzmq-the-low-level-library" class="headerlink" title="Libzmq - the low level library"></a>Libzmq - the low level library</h3><p>Libzmq (<a href="https://github.com/zeromq/libzmq">https://github.com/zeromq/libzmq</a>) 是大多数不同语言绑定背后的底层库。Libzmq 公开 C-API 及 C++ 的实现。</p>
<h2 id="Languages"><a href="#Languages" class="headerlink" title="Languages"></a>Languages</h2><p>C、C++、C#、Erlang、F#、Go、Haskell、Java、Node.js、Perl、Python、Ruby、Rust 等。</p>
<p>更多：<a href="http://wiki.zeromq.org/bindings:_start">http://wiki.zeromq.org/bindings:_start</a></p>
<h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul>
<li><a href="https://github.com/zeromq/jeromq">JeroMQ</a></li>
<li><a href="https://github.com/zeromq/jzmq">JZMQ</a></li>
<li><a href="https://github.com/zeromq/czmq/tree/master/bindings/jni">jczmq</a></li>
</ul>
<h2 id="Messages"><a href="#Messages" class="headerlink" title="Messages"></a>Messages</h2><h3 id="Messages-1"><a href="#Messages-1" class="headerlink" title="Messages"></a>Messages</h3><h4 id="Blob"><a href="#Blob" class="headerlink" title="Blob"></a>Blob</h4><p>ZeroMQ 消息是在应用程序或相同应用程序的组件之间传递的离散数据单元。从ZeroMQ本身的角度来看，消息被认为是不透明的二进制数据。</p>
<p>在网络上，ZeroMQ 消息是可以容纳内存的从 0 开始任意大小的 Blob。可以使用 Protocol Buffers、msgpack、JSON 或应用程序需要表达的任何东西来进行自己的序列化。选择可移植的数据表示是明智的，可以自己做出权衡的决定。</p>
<h4 id="Frame"><a href="#Frame" class="headerlink" title="Frame"></a>Frame</h4><p>最简单的 ZeroMQ 消息由一个帧(也称为消息部分)组成。</p>
<p>帧是 ZeroMQ 消息的基本格式，帧是指定长度的数据块。</p>
<p>ZeroMQ 保证传递消息的所有部分(一个或多个)，或者不传递任何部分。这允许以单个消息的形式发送或接收帧列表。</p>
<h4 id="Multipart"><a href="#Multipart" class="headerlink" title="Multipart"></a>Multipart</h4><p>消息(单个或多个部分)必须装入内存。如果想发送任意大小的文件，应该将它们分解为多个块(piece)，并将每个块(piece)作为单个部分消息(single-part)发送。</p>
<p><strong>使用 Multipart 数据不会减少内存消耗。</strong></p>
<h3 id="Working-with-strings"><a href="#Working-with-strings" class="headerlink" title="Working with strings"></a>Working with strings</h3><p>将数据作为字符串传递通常是进行通信的最简单方法，因为序列化非常简单。对于ZeroMQ，有这样的规则：<strong>字符串是指定长度的，并且在发送时不带末尾null</strong>。</p>
<p>以下函数（JeroMQ 为例）将字符串作为单帧消息发送到套接字，其中字符串的长度等于帧的长度。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">socket.send(<span class="string">&quot;HELLO&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>要从套接字读取字符串，只需调用 <code>recv</code> 函数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String hello = socket.recvStr()</span><br></pre></td></tr></table></figure>
<p>如果需要更多的控制帧，可以使用 ZFrame 类。下面的代码片段展示了如何从字符串创建帧并发送帧。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ZFrame stringFrame = <span class="keyword">new</span> ZFrame(<span class="string">&quot;HELLO&quot;</span>);</span><br><span class="line">stringFrame.send(socket, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>调用 ZFrame 类的静态 recvFrame 函数，从套接字中读取一个帧并返回一个 ZFrame 对象。如果内容是字符串，则可以通过提供用于序列化它的字符集的 getString 方法来检索它。</p>
<p>默认情况下，<code>ZMQ.CHARSET</code> 用于序列化和反序列化字符串的所有操作。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ZFrame stringFrame = ZFrame.recvFrame(socket);</span><br><span class="line">String hello = stringFrame.getString(ZMQ.CHARSET);</span><br></pre></td></tr></table></figure>


<p>因为我们利用帧的长度来反映字符串的长度，我们可以通过将每个字符串放入一个单独的帧来发送多个字符串。</p>
<p>在一个消息中发送多个字符串帧是可以使用 <code>sendMore</code>方法的。这个方法将延迟消息的实际发送，直到最后一帧被发送。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">socket.sendMore(socket, <span class="string">&quot;HELLO&quot;</span>);</span><br><span class="line">socket.sendMore(socket, <span class="string">&quot;beautiful&quot;</span>);</span><br><span class="line">socket.send(socket, <span class="string">&quot;WORLD!&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>可以使用 ZMsg 类构造多帧消息，而不必使用套接字的 send API。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ZMsg *strings = <span class="keyword">new</span> ZMsg();</span><br><span class="line">strings.add(<span class="string">&quot;HELLO&quot;</span>);</span><br><span class="line">strings.add(<span class="string">&quot;beautiful&quot;</span>);</span><br><span class="line">strings.add(<span class="string">&quot;WORLD&quot;</span>);</span><br><span class="line">strings.send(socket);</span><br></pre></td></tr></table></figure>
<p>若要接收一系列字符串帧，请多次调用 <code>recvStr</code> 函数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String hello     = socket.recvStr();</span><br><span class="line">String beautiful = socket.recvStr();</span><br><span class="line">String world 	 = socket.recvStr();</span><br></pre></td></tr></table></figure>
<p>为了在一次调用中检索整个消息，可以使用 ZMsg 类的静态 <code>recvMsg</code> 方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ZMsg strings = ZMsg.recvMsg(socket);</span><br><span class="line">String hello     = strings.popString();</span><br><span class="line">String beautiful = strings.popString();</span><br><span class="line">String world     = strings.popString();</span><br></pre></td></tr></table></figure>
<h2 id="Socket-API"><a href="#Socket-API" class="headerlink" title="Socket API"></a>Socket API</h2><p>套接字实际上是网络编程的标准 API。这就是为什么 ZeroMQ 提供了一个熟悉的基于套接字的API。ZeroMQ 对开发人员特别有吸引力的一点是，它使用不同的套接字类型来实现任何任意的消息传递模式。此外，ZeroMQ 套接字对底层网络协议提供了一个清晰的抽象，这隐藏了这些协议的复杂性，使它们之间的切换非常容易。</p>
<h3 id="与传统套接字的关键区别"><a href="#与传统套接字的关键区别" class="headerlink" title="与传统套接字的关键区别"></a>与传统套接字的关键区别</h3><p>一般来说，传统套接字为面向连接的可靠字节流(SOCK_STREAM)或不可靠数据报(SOCK_DGRAM)提供同步接口。相比之下，ZeroMQ 套接字提供了异步消息队列的抽象，其确切的队列语义取决于所使用的套接字类型。传统套接字传输字节流或离散数据报，ZeroMQ 套接字传输离散消息。</p>
<p>ZeroMQ 套接字是异步的，这意味着物理连接的建立和断开、重新连接和有效交付的时间对用户是透明的，并由 ZeroMQ 自己组织。此外，如果对等端无法接收消息，则消息可能被排队。</p>
<p>传统套接字只允许严格的一对一(两个对等体)、多对一(多个客户端、一个服务器)或在某些情况下一对多(多播)关系。除了 PAIR 套接字之外，ZeroMQ 套接字可以连接到多个端点，同时接受来自绑定到套接字的多个端点的入站连接，从而允许多对多关系。</p>
<h3 id="套接字生命"><a href="#套接字生命" class="headerlink" title="套接字生命"></a>套接字生命</h3><p>ZeroMQ 套接字生命有四部分，类似 BSD 套接字：</p>
<ul>
<li>创建和销毁套接字，它们共同形成了一个套接字生命的因果循环；</li>
<li>通过在套接字上设置选项并在必要时检查它们来配置套接字；</li>
<li>通过创建与套接字的ZeroMQ连接，将套接字插入到网络拓扑中；</li>
<li>通过在套接字上写入和接收消息来传递数据。</li>
</ul>
<h3 id="绑定与连接-Bind-vs-Connect"><a href="#绑定与连接-Bind-vs-Connect" class="headerlink" title="绑定与连接(Bind vs Connect)"></a>绑定与连接(Bind vs Connect)</h3><p>ZeroMQ 套接字并不在乎谁在绑定，谁在连接。在之前的示例中，你可能注意到的是服务端使用了绑定，客户端使用了连接。为什么是这样的，有什么区别？</p>
<p>ZeroMQ 为每个基础的连接创建队列。如果你的套接字连接到了 3 个对等的套接字，那么在后台将有 3 个消息队列。</p>
<p>使用绑定(Bind)，允许任意的对等套接字连接(Connect)上来，因此在绑定端不清楚到底会有多少个对等点，也不能提前创建队列。相反，队列是作为连接(Connect)到绑定套接字的单个对等体创建的。</p>
<p>使用连接(Connect)，ZeroMQ 知道至少会有一个对等体，因此它可以立即创建单个队列。这适用于所有的套接字类型，除了路由器(ROUTER)，只有在我们连接的对等体确认我们的连接后才创建队列。</p>
<p>因此，<strong>当向没有对等体的绑定(Bind)套接字或没有实时连接的路由器(ROUTER)发送消息时，没有队列来存储消息。</strong></p>
<h4 id="何时用绑定-Bind-，何时用连接-Connect-？"><a href="#何时用绑定-Bind-，何时用连接-Connect-？" class="headerlink" title="何时用绑定(Bind)，何时用连接(Connect)？"></a>何时用绑定(Bind)，何时用连接(Connect)？</h4><p>一般情况下，在体系结构最稳定的点(Points)使用绑定(Bind)，在具有不稳定端点(Endpoints)的动态组件使用连接(Connect)。对于请求/应答(request/reply)，服务提供者可能是您绑定和客户端使用 Connect 的地方。就像普通的旧 TCP 一样。</p>
<p>如果不知道哪个部分更稳定(比如点对点) ，可以考虑中间的一个稳定设备，这样所有的部分都可以去连接。</p>
<h3 id="高水位标记-High-Water-Mark"><a href="#高水位标记-High-Water-Mark" class="headerlink" title="高水位标记(High-Water-Mark)"></a>高水位标记(High-Water-Mark)</h3><p>高水位线是对 ZeroMQ 在内存中排队的未完成消息的<strong>最大数量的硬性限制</strong>。</p>
<p>如果达到此限制，套接字将进入异常状态，根据套接字类型，ZeroMQ 将采取适当的操作，如<strong>阻塞(Blocking)**或</strong>丢弃(Dropping)**发送的消息。请参考下面的套接字描述，以了解为每种套接字类型所采取的具体操作。</p>
<h3 id="消息传递模式-Messaging-Patterns"><a href="#消息传递模式-Messaging-Patterns" class="headerlink" title="消息传递模式(Messaging Patterns)"></a>消息传递模式(Messaging Patterns)</h3><p>在 ZeroMQ 套接字 API 是对消息传递模式(Messaging Patterns)的包装。ZeroMQ 模式通过具有<strong>匹配类型</strong>的<strong>套接字对</strong>来实现。</p>
<p>套接字类型定义了套接字的语义、它用于向内向外路由消息的策略、队列等。可以将某些类型的套接字连接在一起，例如，发布服务器套接字和订阅服务器套接字。套接字在“消息传递模式”中协同工作。</p>
<p>内置的 ZeroMQ 核心模式如下：</p>
<ul>
<li><p><a href="https://zeromq.org/socket-api/#request-reply-pattern"><strong>Request-reply</strong></a>(请求/应答)，它将一组客户端连接到一组服务端。这是一种远程过程调用(RPC)和任务分布(Task Distribution)模式。</p>
</li>
<li><p><a href="https://zeromq.org/socket-api/#publish-subscribe-pattern"><strong>Pub-sub</strong></a>(发布-订阅)，它将一组发布者连接到一组订阅者。这是一种数据分布(Data Distribution)模式。</p>
</li>
<li><p><a href="https://zeromq.org/socket-api/#pipeline-pattern"><strong>Pipeline</strong></a>(管道)，它以扇出(fan-out)/扇入(fan-in)模式连接节点，该模式可以有多个步骤和循环。这是一个并行任务分配和收集(Parallel task distribution and collection)模式。</p>
</li>
<li><p><a href="https://zeromq.org/socket-api/#exclusive-pair-pattern"><strong>Exclusive pair</strong></a>(独占对)，专门连接两个套接字。这是一种在进程中连接两个线程的模式，不要与“普通”的套接字对混淆。</p>
</li>
</ul>
<p>还有更多ZeroMQ模式仍处于草案状态：</p>
<ul>
<li><a href="https://zeromq.org/socket-api/#client-server-pattern"><strong>Client-server</strong></a>(客户端-服务器)，它允许单个 ZeroMQ 服务器与一个或多个 ZeroMQ 客户机通话。客户端始终启动会话，在此之后，任何一方都可以异步地向另一方发送消息。</li>
<li><a href="https://zeromq.org/socket-api/#radio-dish-pattern"><strong>Radio-dish</strong></a>(无线接收天线)，用于一对多的数据分发，以扇形方式(fan out)将数据从一个发布者发送到多个订阅者。</li>
</ul>
<h4 id="Request-reply"><a href="#Request-reply" class="headerlink" title="Request-reply"></a>Request-reply</h4><blockquote>
<p><a href="https://rfc.zeromq.org/spec/28/">https://rfc.zeromq.org/spec/28/</a></p>
</blockquote>
<p>请求-应答(Request-reply)模式适用于各种面向服务的体系结构。它有两种基本形式：** 同步(REQ 和 REP)<strong>和</strong>异步(DEALER 和 ROUTER) **，可以以各种方式混合使用。DEALER 和 ROUTER 套接字是许多高级协议的构建块，比如 rfc.zeromq.org/spec:18/mdp 协议。</p>
<h5 id="REQ"><a href="#REQ" class="headerlink" title="REQ"></a>REQ</h5><p>客户端使用 <code>REQ</code> 套接字向服务发送请求并从服务接收响应。这种套接字类型只允许交替的发送和随后的接收调用。一个 <code>REQ</code> 套接字可以连接到任意数量的 <code>REP</code> 或 <code>ROUTER</code> 套接字。发送的每个请求都在所有连接的服务之间循环，接收到的每个应答都与最后发出的请求匹配。它是为简单的请求-应答模型而设计的，在这种模型中，针对失败对等体的可靠性不是问题。</p>
<p>如果没有可用的服务，那么套接字上的任何发送操作都将阻塞，直到至少有一个服务可用。<code>REQ</code> 套接字不会丢弃任何消息。</p>
<h5 id="REP"><a href="#REP" class="headerlink" title="REP"></a>REP</h5><p>服务使用 <code>REP</code> 套接字接收来自客户机的请求并向客户机发送应答。这种套接字类型只允许接收和随后的发送调用交替序列。接收到的每个请求都是来自所有客户机的公平队列(fair-queued)，发送的每个应答都被路由到发出最后一个请求的客户机。如果原始请求者不再存在，则静默丢弃应答。</p>
<h5 id="DEALER"><a href="#DEALER" class="headerlink" title="DEALER"></a>DEALER</h5><p><code>DEALER</code> 套接字类型与一组匿名对等体通信，使用循环(round-robin)算法发送和接收消息。只要它不丢弃消息，它就是可靠的。对于与 <code>REP</code> 或 <code>ROUTER</code> 通信的客户端，<code>DEALER</code> 作为 <code>REQ</code> 的异步替代。<code>DEALER</code> 收到的消息从所有连接的对等体公平排队(fair-queued)。</p>
<p>当 <code>DEALER</code> 由于达到了所有对等体的高水位而进入静音状态，或者如果根本没有对等体，那么套接字上的任何发送操作都将<strong>阻塞</strong>(Block)，直到静音状态结束或至少有一个对等体可用来发送；消息不会被丢弃。</p>
<p>当 <code>DEALER</code> 连接到 <code>REP</code> 套接字时，发送的消息必须包含一个空帧作为消息的第一部分(分隔符)，然后是一个或多个正文部分。</p>
<h5 id="ROUTER"><a href="#ROUTER" class="headerlink" title="ROUTER"></a>ROUTER</h5><p><code>ROUTER</code> 套接字类型与一组对等体对话，使用显式寻址，以便每个传出的消息被发送到一个特定的对等体连接。<code>ROUTER</code> 作为<code>REP</code>的异步替代品，经常用作服务器与 <code>DEALER</code> 通信的基础。</p>
<p>当 <code>ROUTER</code> 套接字接收消息时，在将消息传递给应用程序之前，将包含原始对等体的路由id的消息部分预先添加到消息部分。接收到的消息从所有连接的对等体中公平排队(fair-queued)。当发送消息时，一个 <code>ROUTER</code> 套接字将删除消息的第一部分，并使用它来确定消息应该被路由到的对等体的路由id。如果对等体已经不存在或从未存在过，则该消息将被静默<strong>丢弃</strong>。</p>
<p>当 <code>ROUTER</code> 套接字由于达到了对所有对等体的最高水位而进入静音状态时，发送到该套接字的任何消息都将被丢弃，直到静音状态结束。同样，路由到已达到单个高水位标记的对等点的任何消息也将被丢弃。</p>
<p>当一个 <code>REQ</code> 套接字连接到一个 <code>ROUTER</code> 套接字时，除了原始对等体的路由id外，每个收到的消息还应该包含一个空的分隔符消息部分。因此，应用程序看到的每个接收到的消息的整个结构变成：一个或多个路由id部分、分隔符部分、一个或多个主体部分。当向 <code>REQ</code> 套接字发送应答时，应用程序必须包含分隔符部分。</p>
<h4 id="Publish-subscribe"><a href="#Publish-subscribe" class="headerlink" title="Publish-subscribe"></a>Publish-subscribe</h4><blockquote>
<p><a href="https://rfc.zeromq.org/spec/29/">https://rfc.zeromq.org/spec/29/</a></p>
</blockquote>
<p>发布-订阅(Publish-subscribe)模式用于以扇形方式将数据从一个发布者分发到多个订阅者的一对多分布。</p>
<p>ZeroMQ 通过四种套接字类型来支持发布/订阅：<code>PUB</code>,<code>XPUB</code>,<code>SUB</code>,<code>XSUB</code>。</p>
<h5 id="Topics"><a href="#Topics" class="headerlink" title="Topics"></a>Topics</h5><p>ZeroMQ 使用多部分(Multipart)消息来传递主题(Topic)信息。<code>Topic</code> 表示为字节数组，但也可以使用字符串和适当的文本编码。</p>
<p>发布者必须在消息有效负载之前的第一个帧中包含主题。例如，向<code>status</code>主题的订阅者发布状态消息：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  Send a message on the &#x27;status&#x27; topic</span></span><br><span class="line">pub.sendMore(<span class="string">&quot;Status&quot;</span>);</span><br><span class="line">pub.send(<span class="string">&quot;All is well&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>订阅者通过 Socket 类的 subscribe 方法指定他们感兴趣的主题：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  Subscribe to the &#x27;status&#x27;</span></span><br><span class="line">sub.subscribe(<span class="string">&quot;status&quot;</span>);</span><br></pre></td></tr></table></figure>
<p><strong>一个订阅者(subscriber)套接字可以有多个订阅筛选器(filter)。</strong></p>
<p>使用前缀检查将消息的主题(Topic)与订阅者的订阅主题进行比较，也就是说，订阅了 <code>topic</code> 的订阅者会收到主题为：<code>topic</code>或<code>topic/subtopic</code>或<code>topical</code>的消息，然而，它不会接收 <code>topi</code> 和 <code>TOPIC</code> 的主题消息。</p>
<h5 id="PUB"><a href="#PUB" class="headerlink" title="PUB"></a>PUB</h5><p>发布者使用 <code>PUB</code> 套接字来分发数据。发送的消息以扇出的方式分发到所有连接的对等体。<strong>此套接字类型无法接收任何消息。</strong></p>
<p>当 <code>PUB</code> 套接字由于达到了订阅者的高水位而进入静音状态时，将发送到有问题的订阅者的任何消息都将被<strong>丢弃</strong>，直到静音状态结束。对于这种套接字类型，Send 函数永远不会阻塞。</p>
<h5 id="SUB"><a href="#SUB" class="headerlink" title="SUB"></a>SUB</h5><p>订阅者使用<code>SUB</code>套接字订阅由发布者分发的数据。最初，<code>SUB</code>套接字不订阅任何消息。<strong>此套接字类型没有实现 send 函数。</strong></p>
<h5 id="XPUB"><a href="#XPUB" class="headerlink" title="XPUB"></a>XPUB</h5><p>与 <code>PUB</code> 相同，只是可以以传入消息的形式从对等节点接收订阅(Subscription)。订阅消息由两部分组成，一是<strong>字节1</strong>(用于订阅)或<strong>字节0</strong>(用于取消订阅)，二是在一后面跟着订阅主体。没有订阅或取消订阅前缀的消息也会被接收，但对订阅状态没有影响。</p>
<h5 id="XSUB"><a href="#XSUB" class="headerlink" title="XSUB"></a>XSUB</h5><p>与<code>SUB</code>相同，不同的是您是通过向套接字发送订阅(Subscription)消息来进行订阅的。订阅消息由两部分组成，一是<strong>字节1</strong>(用于订阅)或<strong>字节0</strong>(用于取消订阅)，二是在一后面跟着订阅主体。没有订阅或取消订阅前缀的消息也会被发送，但对订阅状态没有影响。</p>
<h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><blockquote>
<p><a href="https://rfc.zeromq.org/spec/30/">https://rfc.zeromq.org/spec/30/</a></p>
</blockquote>
<p>管道(pipeline)模式用于任务分配，通常是在一个多阶段管道中，其中一个或几个节点将工作推给多个工作人员，然后这些工作人员又将结果推给一个或几个收集器。该模式大多是可靠的，除非节点意外断开连接，否则它不会丢弃消息。它是可扩展的，节点可以在任何时候加入。</p>
<p>ZeroMQ通过两种套接字类型支持流水线：<code>PUSH</code> 和 <code>PULL</code></p>
<h5 id="PUSH"><a href="#PUSH" class="headerlink" title="PUSH"></a>PUSH</h5><p><code>PUSH</code> 套接字类型与一组匿名的 <code>PULL</code> 对等体对话，使用循环算法发送消息。<strong>没有为该套接字类型实现接收(<em>receive</em>)操作。</strong></p>
<p>当由于到达所有下游节点的高水位，或没有下游节点，则套接字进入静音状态，此时任何套接字上发送操作将被<strong>阻塞</strong>，直到静音状态结束或至少一个下游节点发送可用；<strong>消息不会被丢弃</strong>。</p>
<h5 id="PULL"><a href="#PULL" class="headerlink" title="PULL"></a>PULL</h5><p><code>PULL</code>套接字类型与一组匿名 <code>PUSH</code> 对等体对话，使用公平排队算法接收消息。<strong>没有为该套接字类型实现发送(<em>send</em>)操作。</strong></p>
<h4 id="Exclusive-Pair"><a href="#Exclusive-Pair" class="headerlink" title="Exclusive Pair"></a>Exclusive Pair</h4><blockquote>
<p><a href="https://rfc.zeromq.org/spec/31/">https://rfc.zeromq.org/spec/31/</a></p>
</blockquote>
<p>独占对 <code>PAIR</code> 不是一个通用套接字，用于两个对等体在结构上稳定的特定用例。这通常限制了 <code>PAIR</code> 只能在单个进程中使用，用于线程间通信。</p>
<p><code>PAIR</code> 类型的套接字在任何时候只能连接到单个对等点。对通过 <code>PAIR</code> 套接字发送的消息不执行<strong>路由</strong>和<strong>筛选</strong>。</p>
<p>当一个 <code>PAIR</code> 套接字由于已连接的对等点达到了高水位标记而进入静音状态，或者如果没有对等点被连接，那么套接字上的任何发送操作都会被阻塞，直到对等点可以发送为止；消息不会被丢弃。</p>
<p>虽然 <code>PAIR</code> 套接字可以通过 <code>inproc</code> 以外的传输方式使用，但是它们不能自动重新连接，而且新连入的连接将被终止，而以前存在的任何连接(包括处于关闭状态的连接)在大多数情况下都不适合 TCP。</p>
<h2 id="zguide"><a href="#zguide" class="headerlink" title="zguide"></a>zguide</h2><h3 id="Advanced-Request-Reply-Pattern"><a href="#Advanced-Request-Reply-Pattern" class="headerlink" title="Advanced Request-Reply Pattern"></a>Advanced Request-Reply Pattern</h3><p>路由的本质是消息中包含了一个身份帧（信封地址）。</p>
<p>REQ 和 REP 是同步的；DEALER 和 ROUTER 是异步的，无视应答信封。</p>
<p>DEALER 类似于异步 REQ 套接字，ROUTER 类似于异步 REP 套接字。在使用 REQ 套接字的地方，我们可以使用 DEALER; 我们只需要自己读写信封。在使用 REP 套接字的地方，我们可以粘贴 ROUTER; 我们只需要自己管理标识。</p>
<p>可以将 REQ 和 DEALER 套接字视为“客户端”，将 REP 和 ROUTER 套接字视为“服务器”。通常，您需要 <code>bind</code> REP 和 ROUTER 套接字，并将 REQ 和 DEALER 套接字 <code>connect</code> 到它们。</p>
<p>Identity 标识当前套接字的身份信息；envelope(Envelope Frame) 标识将要路由到的套接字地址</p>
<p>请求-应答模式套接字有效的组合：</p>
<ul>
<li>REQ to REP</li>
<li>DEALER to REP</li>
<li>REQ to ROUTER</li>
<li>DEALER to ROUTER</li>
<li>DEALER to DEALER</li>
<li>ROUTER to ROUTER</li>
</ul>
<p>无效组合：</p>
<ul>
<li>REQ to REQ  双方都希望通过相互发送消息来开始。</li>
<li>REQ to DEALER 当有多个 REQ 时，DEALER 无法原路返回。</li>
<li>REP to REP 双方都会等待对方发送第一条消息。</li>
<li>REP to ROUTER ROUTER 不知道 REP 的地址。</li>
</ul>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>ZMQ</tag>
        <tag>MQ</tag>
        <tag>0MQ</tag>
        <tag>Socket</tag>
        <tag>Messaging</tag>
      </tags>
  </entry>
  <entry>
    <title>「区块链技术指南」书摘</title>
    <url>/2018/01/22/excerpts-of-blockchain-guide/</url>
    <content><![CDATA[<blockquote>
<p>本书适用于对区块链技术感兴趣，且具备一定信息和金融基础知识的读者；无技术背景的读者也可以从中了解到区块链的应用现状。</p>
</blockquote>
<p>「区块链技术指南」在线阅读：<a href="https://www.gitbook.com/book/yeasy/blockchain_guide/details">https://www.gitbook.com/book/yeasy/blockchain_guide/details</a></p>
<p><img src="/images/blockchain/Blockchain-1.jpg" alt="image"></p>
<p>以下为书摘（为了保持前后连贯顺畅，部分内容经过简单重组，仍与原文含义保持一致）：</p>
<h2 id="区块链技术的概念与展望"><a href="#区块链技术的概念与展望" class="headerlink" title="区块链技术的概念与展望"></a>区块链技术的概念与展望</h2><p>无论是货币，还是信用卡模式，都需要额外的系统（例如银行）来完成生产、分发、管理等操作，带来很大的额外成本和使用风险。诸如伪造、信用卡诈骗、盗刷、转账等安全事件屡见不鲜。</p>
<p>很自然的，如果能实现一种数字货币，保持既有货币的这些特性，消除纸质货币的缺陷，无疑将带来巨大的社会变革，极大提高经济活动的运作效率。</p>
<p><strong>比特币是首次从实践意义上实现了一套去中心化的数字货币系统。</strong></p>
<p>最早区块链技术雏形出现在比特币项目中。作为比特币背后的分布式记账平台，在无集中式管理的情况下，比特币网络稳定运行了近八年时间，支持了海量的交易记录，并未出现严重的漏洞。</p>
<p>公认的最早关于区块链的描述性文献是中本聪所撰写的「比特币：一种点对点的电子现金系统」，但该文献重点在于讨论比特币系统，实际上没有明确提出区块链的定义和概念。在其中，区块链被描述为用于记录比特币交易的账目历史。</p>
<p><strong>从记账的角度来看，区块链是首个自带对账功能的数字记账技术实现。</strong></p>
<p>区块链的基本概念包括：</p>
<ul>
<li>交易（Transaction）：一次操作，导致账本状态的一次改变，如添加一条记录；</li>
<li>区块（Block）：记录一段时间内发生的交易和状态结果，是对当前账本状态的一次共识；</li>
<li>链（Chain）：由一个个区块按照发生顺序串联而成，是整个状态变化的日志记录。</li>
</ul>
<p>如果把区块链作为一个状态机，则每次交易就是试图改变一次状态，而每次共识生成的区块，就是参与者对于区块中所有交易内容导致状态改变的结果进行确认。</p>
<p><strong>区块链不是数据库</strong>。虽然区块链也可以用来存储数据，但它要解决的问题是多方的互信问题。单纯从存储数据角度，它的效率可能不高，笔者也不推荐把大量的原始数据放到区块链上。<strong>区块链不是要颠覆现有技术</strong>，作为基于多项已有技术而出现的新事物，区块链跟现有技术的关系是一脉相承的。</p>
<h3 id="商业价值"><a href="#商业价值" class="headerlink" title="商业价值"></a>商业价值</h3><p>现代商业的典型模式为，交易方通过协商和执行合约，完成交易过程。区块链擅长的正是如何管理合约，确保合约的顺利执行。</p>
<p>从技术特点上，区块链一般被认为具有：</p>
<ul>
<li>分布式容错性：网络极其鲁棒，容错 1/3 左右节点的异常状态。</li>
<li>不可篡改性：一致提交后的数据会一致存在，不可被销毁或修改。</li>
<li>隐私保护性：密码学保证了未经授权者能访问到数据，但无法解析。</li>
</ul>
<p>随之带来的业务特性将可能包括：</p>
<ul>
<li>可信任性：区块链技术可以提供天然可信的分布式账本平台，不需要额外第三方中介机构。</li>
<li>降低成本：跟传统技术相比，区块链技术可能带来更短的时间、更少的人力和维护成本。</li>
<li>增强安全：区块链技术将有利于安全可靠的审计管理和账目清算，减少犯罪可能性和各种风险。</li>
</ul>
<p>区块链并非凭空诞生的新技术，更像是技术演化到一定程度突破应用阈值后的产物，因此，其商业应用场景也跟促生其出现的环境息息相关。基于区块链技术，任何基于数字交易的活动成本和追踪成本都会降低，并且能提高安全性。<strong>笔者认为，能否最终带来成本的降低，将是一项技术能否被深入应用的关键。</strong></p>
<p>区块链系统跟传统的分布式系统不同，其处理性能无法通过单纯增加节点数来进行扩展，实际上，很大程度上取决于单个节点的处理能力。<strong>高性能、安全、稳定性、硬件辅助加解密能力，都将是考察节点性能的核心要素。</strong></p>
<p><strong>世界上并没有绝对安全的系统。</strong>系统是由人设计的，系统也是由人来运营的，只要有人参与的系统，就容易出现漏洞。</p>
<p><strong>最早出现的未必是先驱，也可能是先烈。</strong>创新固然很好，但过早播撒的种子，没有合适的土壤，往往也难长大。技术创新与科研创新很不同的一点便是，技术创新必须立足于需求，过早过晚都会错失良机。科研创新则要越早越好，最好像二十世纪那批物理巨匠们一样，让后人吃了一百多年老本。</p>
<h3 id="区块链种类"><a href="#区块链种类" class="headerlink" title="区块链种类"></a>区块链种类</h3><p>根据参与者的不同，可以分为公开链、联盟链和私有链。</p>
<p>从功能上看，可以分为以货币交易为主的初代区块链（如比特币网络）、支持智能合约的二代区块链（如以太坊网络）、面向复杂商业应用场景支持链上代码的新一代区块链或分布式账本（如超级账本）。</p>
<h2 id="分布式系统核心问题"><a href="#分布式系统核心问题" class="headerlink" title="分布式系统核心问题"></a>分布式系统核心问题</h2><h3 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a>一致性问题</h3><p>如果一个分布式系统无法保证处理结果一致的话，那任何建立于其上的业务系统都无法正常工作。</p>
<p>将可能引发不一致的并行操作进行串行化，就是现在计算机系统里处理分布式一致性问题的基础思路和唯一秘诀。</p>
<p>理想的分布式系统一致性应该满足：</p>
<ul>
<li>可终止行（Termination）：一致的结果在有限时间内完成；</li>
<li>共识性（Consensus）：不同节点最终完成决策的结果应该相同；</li>
<li>合法性（Validity）：决策的结果必须是其他进程提出的提案。</li>
</ul>
<p>绝对理想的强一致性代价很大。除非不发生任何故障，所有节点之间的通信无需任何时间，这个时候其实就等价于一台机器了。实际上，超强的一致性要求往往意味着越弱的性能。</p>
<p>强一致性主要包含：顺序一致性、线性一致性。</p>
<p>强一致性的系统往往比较难实现。很多时候，人们发现实际需求并没有那么强，可以适当放宽一致性要求，降低系统实现的难度。例如在一定约束下实现所谓最终一致性，即总会存在一个时刻（而不是立刻），系统达到一致的状态，这对于大部分的 Web 系统来说已经足够了。这一类弱化的一致性，被笼统称为弱一致性。</p>
<p>实际上，要保障系统满足不同程度的一致性，往往需要通过共识算法来达成。</p>
<h3 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h3><p>共识算法解决的是对某个提案，大家达成一致意见的过程。</p>
<p>搞学术的人都喜欢对问题先确定一个界限，那么，这个问题的最坏界限在哪里呢？很不幸，一般情况下，分布式系统的共识问题无解。</p>
<p>当节点间网络不可靠时，很显然，无法确保实现共识。然而，即便在网络通信可靠的情况下，一个可扩展的分布式系统的共识问题的下限是无解。</p>
<p>这个结论，被称为 <strong>FLP 不可能性</strong> 原理，可以看做分布式领域的“测不准原理”。</p>
<h3 id="FLP不可能性原理"><a href="#FLP不可能性原理" class="headerlink" title="FLP不可能性原理"></a>FLP不可能性原理</h3><blockquote>
<p>FLP 不可能原理：在网络可靠，存在节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性算法。</p>
</blockquote>
<p>FLP 不可能原理实际上告诉人们，不要浪费时间去为异步分布式系统设计在任意场景下都能实现共识的算法。</p>
<p>但，学术界做研究，考虑的是数据和物理意义上极端的情形，很多时候现实生活要美好的多。<strong>科学告诉你什么是不可能的；工程则告诉你，付出一些代价，我可以把它变成可能。</strong>这就是工程的魅力。</p>
<p><em>科学上告诉你去赌场赌博从概率上总会是输钱的；工程则告诉你，如果你愿意接受最终输钱的结果，中间说不定偶尔能小赢几笔呢！？</em></p>
<p>在付出一定代价的情况下，我们能做到多少？回答这一问题的另一个很出名的原理：CAP 原理。</p>
<h3 id="CAP-原理"><a href="#CAP-原理" class="headerlink" title="CAP 原理"></a>CAP 原理</h3><p>分布式系统不可能同时确保一致性（Consistency）、可用性（Availability）和分区容忍性（Partition），设计中往往需要弱化对某个特性的保证。</p>
<ul>
<li>一致性（Consistency）：任何操作应该都是原子的，发生在后面的事件能看到前面事件发生导致的结果（强一致性）；</li>
<li>可用性（Availability）：在有限时间内，任何非失败节点都能应答请求；</li>
<li>分区容忍性（Partition）：网络可能发生分区，即节点之间的通信不可保障。</li>
</ul>
<h3 id="Paxos-与-Raft"><a href="#Paxos-与-Raft" class="headerlink" title="Paxos 与 Raft"></a>Paxos 与 Raft</h3><p>Paxos 问题是指分布式的系统中存在故障（fault），但不存在恶意（corrupt）节点场景（即可能消息丢失或重复，但无错误消息）下的共识达成（Consensus）问题。</p>
<p>Paxos 能保证在超过 1/2 的正常节点存在时，系统能达成共识。</p>
<p>Paxos 存在两个阶段：准备（prepare）阶段和提交（commit）阶段。准备阶段解决大家对哪个提案进行投票的问题，提交阶段解决最终值的问题。</p>
<p>Raft 算法是 Paxos 算法的一种简化实现。</p>
<h3 id="拜占庭问题"><a href="#拜占庭问题" class="headerlink" title="拜占庭问题"></a>拜占庭问题</h3><p>拜占庭问题更为广泛，讨论的是允许存在少数节点作恶（消息可能被伪造）场景下的一致性达成问题。</p>
<p>拜占庭算法讨论的是最坏情况下的保障。</p>
<p>面向拜占庭问题的容错算法，解决的是网络通信可靠，但节点可能故障情况下的一致性达成。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">以函数来表示，将军的总数为 n，n 里面背叛者的数量为 t，则只要 n &gt; 3t 就可以容错。</span><br></pre></td></tr></table></figure>
<p>拜占庭问题之所以难解，在于任何时候系统中都可能存在多个提案（因为提案成本很低），并且要完成最终的一致性确认过程十分困难，容易受干扰。但一旦确认，即为最终确认。</p>
<p>比特币的区块链网络在设计时提出了创新的 PoW（Proof of Work）算法思路。一个是限制一段时间内整个网络中出现提案的个数（增加提案成本），另外一个是放宽对最终一致性确认的需求，约定好大家都确认并沿着已知最长的链进行拓宽。系统的最终确认是概率意义上的存在。这样，即便有人试图恶意破坏，也会付出很大的经济代价（付出超过系统一半的算力）。</p>
<p>后来的各种 PoX 系列算法，也都是沿着这个思路进行改进，采用经济上的惩罚来制约破坏者。</p>
<h3 id="可靠性指标"><a href="#可靠性指标" class="headerlink" title="可靠性指标"></a>可靠性指标</h3><table>
<thead>
<tr>
<th align="center">指标</th>
<th align="center">概率可靠性</th>
<th align="center">每年允许不可用时间</th>
<th align="center">典型场景</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1个9</td>
<td align="center">90%</td>
<td align="center">1.2 月</td>
<td align="center">不可用</td>
</tr>
<tr>
<td align="center">2个9</td>
<td align="center">99%</td>
<td align="center">3.6 天</td>
<td align="center">普通单点</td>
</tr>
<tr>
<td align="center">3个9</td>
<td align="center">99.9%</td>
<td align="center">8.6 小时</td>
<td align="center">普通企业</td>
</tr>
<tr>
<td align="center">4个9</td>
<td align="center">99.99%</td>
<td align="center">51.6 分钟</td>
<td align="center">高可用</td>
</tr>
<tr>
<td align="center">5个9</td>
<td align="center">99.999%</td>
<td align="center">5 分钟</td>
<td align="center">电信级</td>
</tr>
<tr>
<td align="center">6个9</td>
<td align="center">99.9999%</td>
<td align="center">31 秒</td>
<td align="center">极高要求</td>
</tr>
<tr>
<td align="center">7个9</td>
<td align="center">99.99999%</td>
<td align="center">3 秒</td>
<td align="center">N/A</td>
</tr>
<tr>
<td align="center">8个9</td>
<td align="center">99.999999%</td>
<td align="center">0.3 秒</td>
<td align="center">N/A</td>
</tr>
<tr>
<td align="center">9个9</td>
<td align="center">99.9999999%</td>
<td align="center">30 毫秒</td>
<td align="center">N/A</td>
</tr>
</tbody></table>
<p>依靠单点实现的可靠性毕竟是有限的，要想进一步的提升，那就只好消灭单点，通过主从、多活等模式让多个节点集体完成原先单点的工作。这可以从概率意义上改善服务的可靠性，也是分布式系统的一个重要用途。</p>
<h2 id="密码学与安全技术"><a href="#密码学与安全技术" class="headerlink" title="密码学与安全技术"></a>密码学与安全技术</h2><h3 id="Hash-算法"><a href="#Hash-算法" class="headerlink" title="Hash 算法"></a>Hash 算法</h3><p>Hash（哈希或散列）算法是信息技术领域非常基础也非常重要的技术。它能使任意长度的二进制值（明文）映射为较短的固定长度的二进制值（Hash 值），并且不同的明文很难映射为相同的 Hash 值。</p>
<p>一个优秀的 Hash 算法，将能实现：</p>
<ul>
<li>正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。</li>
<li>逆向困难：给定（若干）hash 值，在有限时间内很难（基本不可能）逆推出明文。</li>
<li>输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。</li>
<li>冲突避免：很难找到两段内容不同的明文，使得他们的 hash 值一致（发生冲突）。冲突避免有时候又被称为“抗碰撞性”。如果给定一个明文前提下，无法找到碰撞的另一个明文，称为“弱抗碰撞性”；如果无法找到任意两个明文，发生碰撞，则称算法具有“强抗碰撞性”。</li>
</ul>
<p>一般的，Hash 算法都是算力敏感型，意味着计算资源是瓶颈，主频越高的 CPU 进行 Hash 的速度也越快。也有一些 Hash 算法不是算力敏感的， 例如 scrypt，需要大量的内存资源，节点不能通过简单的增加更多的 CPU 来获得 hash 性能的提升。</p>
<p>数字摘要是 Hash 算法最重要的一个用途。数字摘要是解决确保内容没被篡改过的问题（利用 Hash 函数的抗碰撞性特点）。在网络上下载软件或文件时，往往同时会提供一个数字摘要值，用户下载下来原始文件可以自行进行计算，并同提供的摘要值进行比对，以确保内容没有被修改过。</p>
<h3 id="加解密算法"><a href="#加解密算法" class="headerlink" title="加解密算法"></a>加解密算法</h3><p>现代加密算法的典型组件包括：加解密算法、加密密钥、解密密钥。其中，加解密算法自身是固定不变的，一般是公开可见的；密钥则往往每次不同，并且需要保护起来，一般来说，对同一种算法，密钥长度越长，则加密强度越大。</p>
<p>加密过程中，通过加密算法和加密密钥，对明文进行加密，获得密文；解密过程中，通过解密算法和解密密钥，对密文进行解密，获得明文。</p>
<p>根据加解密的密钥是否相同，算法可以分为对称加密（symmetric cryptography，又称公共密钥加密，common-key cryptography）和非对称加密（asymmetric cryptography，又称公钥加密，public-key cryptography）。两种模式适用于不同的需求，恰好形成互补，很多时候也可以组合使用，形成混合加密机制。</p>
<p>并非所有加密算法的强度都可以从数学上进行证明。公认的高强度加密算法是在经过长时间各方面实践论证后，被大家所认可，不代表其不存在漏洞。但任何时候，自行发明加密算法都是一种不太明智的行为。</p>
<h3 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h3><p>类似在纸质合同上签名确认合同内容，数字签名用于证实某数字内容的完整性（integrity）和来源（或不可抵赖，non-repudiation）。</p>
<ul>
<li>HMAC：Hash-based Message Authentication Code，即“基于 Hash 的消息认证码”。</li>
<li>盲签名</li>
<li>多重签名</li>
<li>群签名</li>
<li>环签名</li>
</ul>
<h3 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h3><p>数字证书用来证明某个公钥是谁的，并且内容是正确的。</p>
<p>对于非对称加密算法和数字签名来说，很重要的一点就是公钥的分发。一旦公钥被人替换（典型的如中间人攻击），则整个安全体系将被破坏掉。怎么确保一个公钥确实是某个人的原始公钥？这就需要数字证书机制。</p>
<p>顾名思义，数字证书就是像一个证书一样，证明信息和合法性。由证书认证机构（Certification Authority，CA）来签发，权威的 CA 包括 Verisign 等。</p>
<h3 id="PKI-体系"><a href="#PKI-体系" class="headerlink" title="PKI 体系"></a>PKI 体系</h3><p>在非对称加密中，公钥则可以通过证书机制来进行保护，如何管理和分发证书则可以通过 PKI （Public Key Infrastructure）来保障。顾名思义，PKI 体系在现代密码学应用领域处于十分基础的地位，解决了十分核心的证书管理问题。</p>
<p>一般情况下， PKI 至少包含如下组件：</p>
<ul>
<li>CA（Certification Authority）：负责证书的颁发和作废，接收来自 RA 的请求，是最核心的部分；</li>
<li>RA（Registration Authority）：对用户身份进行验证，校验数据合法性，负责登记，审核过了就发给 CA；</li>
<li>证书数据库：存放证书，一般采用 LDAP 目录服务，标准格式采用 X.500 系列。</li>
</ul>
<p>常见的流程为，用户通过 RA 登记申请证书，CA 完成证书的制造，颁发给用户。用户需要撤销证书则向 CA 发出申请。</p>
<h3 id="Merkle-树"><a href="#Merkle-树" class="headerlink" title="Merkle 树"></a>Merkle 树</h3><p>默克尔树（哈希树）是一种二叉树，由一个根节点、一组中间节点和一组叶子节点组成。最下面的叶节点包含存储数据或其哈希值，每个中间节点是它的两个孩子节点内容的哈希值，根节点也是由它的两个子节点内容的哈希值组成。</p>
<p>默克尔树的特点是，底层数据的任何变动，都会传递到其父亲节点，一直到树根。</p>
<h3 id="同态加密"><a href="#同态加密" class="headerlink" title="同态加密"></a>同态加密</h3><p>同态加密（Homomorphic Encryption）是一种特殊的加密方法，允许对密文进行处理得到仍然是加密的结果，即对密文直接进行处理，跟对明文进行处理再加密，得到的结果相同。从代数的角度讲，即同态性。</p>
<p>与同态加密相关的一个问题是函数加密。</p>
<p>同态加密保护的是数据本身，而函数加密顾名思义保护的是处理函数本身，即让第三方看不到处理过程的前提下，对数据进行处理。</p>
<h2 id="比特币-Bitcoin"><a href="#比特币-Bitcoin" class="headerlink" title="比特币 - Bitcoin"></a>比特币 - Bitcoin</h2><p><strong>做设计，很多时候都是在权衡（trade-off）。</strong></p>
<p>比特币项目是区块链技术首个大规模的成功应用，并且是首个得到实践检验的数字货币实现，在金融学和信息技术历史上都具有十分重要的意义。</p>
<p>比特币是基于密码学和经济博弈的一种数字货币，也是历史上首个经过大规模长时间运作检验的数字货币系统。</p>
<h3 id="区块"><a href="#区块" class="headerlink" title="区块"></a>区块</h3><h3 id="如何避免作恶"><a href="#如何避免作恶" class="headerlink" title="如何避免作恶"></a>如何避免作恶</h3><p>基于经济博弈原理。</p>
<p>在一个开放的网络中，无法通过技术手段保证每个人都是合作的。但可以通过经济博弈来让合作者得到利益，让非合作者遭受损失和风险。</p>
<blockquote>
<p>一个典型的例子</p>
<p>两个人来分一个蛋糕，如果都想拿到较大的一块，在没有第三方的前提下，该怎么指定规则才公平？</p>
<p>最简单的一个方案是负责切蛋糕的人后选。</p>
</blockquote>
<p>比特币网络需要所有试图参与者（矿工）都首先要付出挖矿的代价，进行算力消耗，越想拿到新区块的决定权，意味着抵押的算力越多。一旦失败，这些算力都会被没收掉，成为沉默成本。当网络中存在众多参与者时，个体试图拿到新区块决定权要付出的算力成本是巨大的，意味着进行一次作恶付出的代价已经超过可能带来的好处。</p>
<h3 id="负反馈调节"><a href="#负反馈调节" class="headerlink" title="负反馈调节"></a>负反馈调节</h3><p>比特币网络中矿工越多，系统就越稳定，比特币价值就越高，但挖到矿的概率会降低。反之，网络中矿工减少，会让系统更容易导致被攻击，比特币价值越低，但挖到矿的概率会提高。</p>
<p>因此，比特币的价格理论上应该稳定在一个合适的值（网络稳定性也会稳定在相应的值），这个价格乘以挖到矿的概率，恰好达到矿工的收益预期。</p>
<p>从长远角度看，硬件成本是下降的，但每个区块的比特币奖励每隔 4 年减半，最终将在 2140 年达到 2100 万枚，之后将完全依靠交易的服务费来鼓励矿工对网络的维护。</p>
<h3 id="共识机制"><a href="#共识机制" class="headerlink" title="共识机制"></a>共识机制</h3><p>目前，Proof of 系列中比较出名的一致性协议包括 PoW 和 PoS，都是通过经济惩罚来限制恶意参与。</p>
<ul>
<li><p>PoW</p>
<p>工作量证明， Proof of Work，通过计算来猜测一个数值（nonce），得以解决规定的 hash 问题。保证在一段时间内，系统中只能出现少数合法提案。同时，这些少量的合法提案会在网络中进行广播，收到的用户进行验证后会基于它认为的最长链上继续难题的计算。因此，系统中可能出现链的分叉（Fork），但最终会有一条链成为最长的链。</p>
<blockquote>
<p>超市付款需要排成一队，可能有人不守规矩要插队。超市管理员会检查队伍，认为最长的一条队伍是合法的，并让不合法的分叉队伍重新排队。只要大部分人不傻，就会自觉在最长的队伍上排队。</p>
</blockquote>
</li>
<li><p>PoS</p>
<p>权益证明，Proof of Stake，类似现实生活中的股东机制，拥有股份越多的人越容易获取记账权。</p>
</li>
</ul>
<h3 id="闪电网络"><a href="#闪电网络" class="headerlink" title="闪电网络"></a>闪电网络</h3><p>比特币的区块链机制自身提供了很好的可信保障，但是很慢；另一方面考虑，对于大量的小额交易来说，是否真实需要这么高的可信性？闪电网络通过智能合约来完善链下的交易渠道。</p>
<p>核心概念：</p>
<ul>
<li><p>RSMS（Recoverable Sequence Maturity Contract）：解决链下交易确认的问题。</p>
<p>中文可翻译为“可撤销的顺序成熟度合同”。这个词很绕，其实主要原理很简单，就是类似准备金机制。</p>
</li>
</ul>
<ul>
<li><p>HTLC（Hashed Timelock Contract）：解决了支付通道的问题。</p>
<p>中文意思是“哈希的带时钟的合约”。这个其实就是限时转账。通过智能合约，双方约定转账方先冻结一笔钱，并提供一个哈希值，如果在一定时间内有人能提出一个字符串，使得它哈希后的值跟已知值匹配（实际上意味着转账方授权了接收方来提现），则这笔钱转给接收方。</p>
</li>
</ul>
<p>RSMC 保障了两个人之间的直接交易可以在链下完成，HTLC 保障了任意两个人之间的转账都可以通过一条“支付”通道来完成。整合这两种机制，就可以实现任意两个人之间的交易都可以在链下完成了。</p>
<p>在整个交易中，智能合约起到了中介的重要角色，而区块链则确保最终的交易结果被确认。</p>
<h3 id="侧链"><a href="#侧链" class="headerlink" title="侧链"></a>侧链</h3><p>允许资产在比特币区块链和其它链之间互转。降低核心的区块链上发生交易的次数。</p>
<h2 id="以太坊-Ethereum"><a href="#以太坊-Ethereum" class="headerlink" title="以太坊 - Ethereum"></a>以太坊 - Ethereum</h2><p><strong>君子和而不同</strong>。</p>
<p>以太坊项目进一步扩展了区块链网络的能力，从交易延伸为智能合约（ Smart Contract ）。</p>
<p>根据以太坊官方的宣称，以太坊（ Ehtereum ）目标是打造成一个运行智能合约的去中心化平台（ Platform for Smart Contract ），平台上的应用按程序设定运行，不存在停机、审查、欺诈、第三方人为干预的可能。</p>
<p>以太坊平台由 Golang、C++、Python 等多种编程语言实现。</p>
<p>当然，为了打造这个平台，以太坊提供了一条公开的区块链，并制定了面向智能合约的一套编程语言。智能合约开发者可以在其上使用官方提供的工具来开发支持以太坊区块链协议的应用（即所谓的 DAPP ）。</p>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ul>
<li>EVM：以太坊虚拟机，轻量级虚拟机环境，是以太坊中智能合约的运行环境。</li>
<li>Account：账户，分两类：合约账户存储执行的合约代码；外部账户为以太币拥有者账户，对应到某公钥。</li>
<li>Transaction：交易，从一个账户到另一个账户的消息，包括以太币或者合约执行参数。</li>
<li>Gas：燃料，每执行一条合约指令会消耗一定的燃料，当某个交易还未执行结束，而燃料消耗完时，合约执行终止并回滚状态。</li>
</ul>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>目前采用了 PoW 作为一致达成保证，未来可能迁移到 PoS 上。</p>
<h3 id="降低攻击"><a href="#降低攻击" class="headerlink" title="降低攻击"></a>降低攻击</h3><p>设计核心思想是通过经济激励机制防止少数人作恶：</p>
<ul>
<li>所有交易都要提供交易费用，避免 DDoS 攻击；</li>
<li>程序运行指令数通过 gas 来限制，所消耗的费用超过设定上限时会被取消，避免恶意合约。</li>
</ul>
<h3 id="提高扩展性"><a href="#提高扩展性" class="headerlink" title="提高扩展性"></a>提高扩展性</h3><p>以太坊未来希望通过分片机制可以提高整个网络的扩展性。</p>
<p>分片之前整个网络的处理取决于单个节点的处理。分片后，只有同一片内的处理是同步的、一致的，不同分片之间则可以是异步的。</p>
<h2 id="超级账本-Hyperledger"><a href="#超级账本-Hyperledger" class="headerlink" title="超级账本 - Hyperledger"></a>超级账本 - Hyperledger</h2><p>Hyperledger 项目是首个面向企业的开放区块链技术的重要探索。在 Linux 基金会的支持下，吸引了包括 IBM、Intel、摩根等在内的众多科技和金融巨头的参与。</p>
<p>该项目的出现，实际上宣布区块链技术已经不再是仅面向“社会实践”性质的应用场景，它已经正式被主流机构和企业市场认可；同时，Hyperledger 首次提出和实现的完备权限管理、创新的一致性算法和可插拔、可扩展的框架，对于区块链相关技术和产业的发展都将产生深远的影响。</p>
<h2 id="区块链即服务"><a href="#区块链即服务" class="headerlink" title="区块链即服务"></a>区块链即服务</h2><p><strong>懒惰和好奇，是创新与进步的源泉。</strong></p>
<p>云的出现，让传统信息行业变得前所未有的便捷。只要云中有的服务，通过简单的几下点击，就可以获得一个运行中的服务实例，节约了大量的研发和运维的时间和成本。</p>
<p>现有的区块链分为三种：私有链、联盟链和公有链。私有链存在于机构内部，必要性较低，且在性能上弱于现有的分布式系统。联盟链建立在多个联盟机构之间，每个联盟成员之间各自拥有一个核心节点。公有链向社会开放，可以用于信息认证、公共资源共享。任何团体或个人可以加入公有链。</p>
<p>目前，业界已经开始有少数区块链前沿技术团队开发了区块链即服务（ Blockchain as a Service，BaaS ）的平台。根据上述划分，BaaS 平台可以面向用户群体提供联盟链及公开链两种服务，并根据不同的服务类型进行不同的结构设计及优化。</p>
<p>（完）</p>
]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>BlockChain</tag>
        <tag>Fintech</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka Connect 笔记</title>
    <url>/2021/02/23/kafka-connect-notes/</url>
    <content><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Kafka Connect 是一个可伸缩、可靠地在 Apache Kafka 和其他系统之间传输数据的工具框架。</p>
<p>Kafka Connect 功能特性：</p>
<ul>
<li><strong>通用框架</strong> Kafka Connect 为其他系统与 Kafka 集成提供了标准化，简化了 Connector 开发、部署和管理。</li>
<li><strong>分布式和独立模式</strong> Kafka Connect 扩展到支持整个组织的大型集中管理服务，或者缩减到开发、测试和小型生产部署。</li>
<li><strong>REST 接口</strong> 通过一个易于使用的 REST API 向 Kafka Connect 集群提交和管理连接器。</li>
<li><strong>自动偏移量管理</strong> 只需要从连接器获得一点点信息，Kafka Connect 就可以自动管理偏移提交过程，因此连接器开发人员不必担心连接器开发中容易出错的部分。</li>
<li><strong>默认分布式可伸缩</strong> Kafka Connect 基于现有的组管理协议，可以添加更多的 Worker 来扩展 Kafka Connect 集群。</li>
<li><strong>流/批处理集成</strong> Kafka Connect 是连接流式和批处理数据系统的理想解决方案。</li>
</ul>
<h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><ul>
<li>Connectors  通过管理任务来协调数据流的高级抽象</li>
<li>Tasks 实现从 Kafka 读取数据或将数据写入 Kafka</li>
<li>Workers 用于执行 Connectors 与 Tasks 的服务进程</li>
<li>Converters 用于实现在 Kafka 与目标/源系统之间的数据转换程序</li>
<li>Transforms 用于转换通过 Connect 的每条数据的简单逻辑实现</li>
<li>Dead Letter Queue 死信队列，用于处理连接器错误</li>
</ul>
<h3 id="Connectors"><a href="#Connectors" class="headerlink" title="Connectors"></a>Connectors</h3><p>Kafka Connect 中的 Connector 定义数据应该从哪里复制或复制到哪里去。Connector 实例是一个逻辑工作，负责管理 Kafka 和另一个系统之间的数据复制。</p>
<p>连接器模型</p>
<p><img src="/images/kafka/connector-model-simple.png" alt="connector-model-simple"></p>
<h4 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h4><p>Connector Configuration 配置是简单的键值映射。</p>
<p>对于独立（Standalone）模式，它们在属性文件中定义，并在命令行上传递给 Connect 进程。</p>
<p>在分布式（Distributed）模式，它们将包含在创建(或修改) Connector 的 REST 请求的 JSON 有效负载中。</p>
<p>通用的配置：</p>
<ul>
<li><code>name</code> Connector 的唯一名称。再次尝试注册相同名称将会失败。</li>
<li><code>connector.class</code> Connector 的 Java 类，<br>（多种格式，如org.apache.kafka.connect.file.FileStreamSinkConnector、FileStreamSink、FileStreamSinkConnector）</li>
<li><code>tasks.max</code> 为此 Connector 应创建的最大任务数。如果 Connector 无法实现此级别的并行性，则可以创建较少的任务。</li>
<li><code>key.converter</code> - (可选) 覆盖由 Worker 设置的默认键转换器。</li>
<li><code>value.converter</code> - (可选) 覆盖由 Worker 设置的默认值转换器。</li>
</ul>
<p>Sink Connector 还需要设置下列其中一个配置项：</p>
<ul>
<li><code>topics</code> 用逗号分隔的主题列表，用作此 Connector 的输入。</li>
<li><code>topics.regex</code> 用 Java 正则表达式匹配到的主题，用作此 Connector 的输入。</li>
</ul>
<p>更多的配置项，将由具体的 Connector 提供文档说明。</p>
<h3 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h3><p>Task 是用于连接的数据模型中的主要参与者。每个 Connector 实例协调一组实际复制数据的 Task。通过允许 Connector 将单个工作分解成多个 Task，Kafka Connect 对并行和可伸缩的数据复制提供了很好的支持，且只需要很少的配置。这些 Task 中没有存储状态。Task 状态存储在 Kafka 的特殊主题 config.storage 和 status.storage，并由关联连接器管理。因此，可以在任何时候启动、停止或重新启动 Task，以提供一个弹性的、可伸缩的数据管道。</p>
<p><img src="/images/kafka/data-model-simple.png" alt="data-model-simple" title="Data Model"></p>
<h4 id="Task-Rebalancing"><a href="#Task-Rebalancing" class="headerlink" title="Task Rebalancing"></a>Task Rebalancing</h4><p>当 Connector 首次提交给集群时，Worker 将重新平衡集群中的全部 Connectors 集及其 Tasks，以便每个 Worker 的工作量大致相同。</p>
<p>当 Connector 增加或减少它们所需的 Task 数量时，或者当 Connector 的配置更改时，也使用同样的重新平衡过程。</p>
<p>当一个 Worker 失败时，Task 会在活跃的 Worker 之间重新平衡。</p>
<p>当 Task 失败时，不会触发 Task 失败的再平衡，因为 Task 失败被认为是一个特例。因此，失败的 Task 不会由框架自动重新启动，应该通过 REST API 重新启动。</p>
<p>下图为 Worker 失败时 Task 故障转移示例</p>
<p><img src="/images/kafka/task-failover.png" alt="task-failover" title="Task 故障转移"></p>
<h3 id="Workers"><a href="#Workers" class="headerlink" title="Workers"></a>Workers</h3><p>Connectors 和 Tasks 是必须在进程中执行的逻辑工作单元，Kafka Connect 称这些进程为 Worker。</p>
<p>有两种类型的 Worker: <code>Standalone</code> 和 <code>Distributed</code>。</p>
<h4 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h4><p>Standalone 模式是最简单的模式，其中单个进程负责执行所有连接器和任务。因为它是一个单一的进程，所以只需要最少的配置。在开发过程中，以及在某些只有一个进程有意义的情况下，如从主机收集日志时，Standalone 模式非常方便。但是，由于只有一个进程，它的功能也更有限：可伸缩性仅限于单个进程，除了添加到单个进程的任何监视之外，没有容错能力。</p>
<h4 id="Distributed"><a href="#Distributed" class="headerlink" title="Distributed"></a>Distributed</h4><p>Distributed 模式为 Kafka Connect 提供了可伸缩性和自动容错能力。在 Distributed 模式下，使用相同的 <code>group.id</code> 启动许多辅助进程，它们自动协调来调度所有可用辅助 Workers 之间的Connectors 和 Tasks 的执行。如果添加了一个 Worker，关闭了一个 Worker，或者一个 Worker 意外地失败了，其余的 Worker 会检测到这一点，并自动协调在更新的可用 Workers 集中重新分配 Connectors 和 Tasks。请注意它们与 Consumer Group 再平衡的相似之处，在掩护之下，Worker 正在利用 Consumer Group 来协调和平衡。</p>
<p><img src="/images/kafka/worker-model-basics.png" alt="worker-model-basics" title="Worker 模型"></p>
<h3 id="Converters"><a href="#Converters" class="headerlink" title="Converters"></a>Converters</h3><p>当写入或从 Kafka 读取数据时，必须有一个 Kafka Connect 部署支持特定的数据格式。任务使用转换器将数据格式从字节转换为 Connect 内部数据格式，反之亦然。</p>
<ul>
<li><strong>AvroConverter</strong> <code>io.confluent.connect.avro.AvroConverter</code> 使用 <a href="https://docs.confluent.io/platform/current/schema-registry/connect.html#schemaregistry-kafka-connect">Schema Registry</a></li>
<li><strong>ProtobufConverter</strong> <code>io.confluent.connect.protobuf.ProtobufConverter</code> 使用 <a href="https://docs.confluent.io/platform/current/schema-registry/connect.html#schemaregistry-kafka-connect">Schema Registry</a></li>
<li><strong>JsonSchemaConverter</strong> <code>io.confluent.connect.json.JsonSchemaConverter</code>  使用 <a href="https://docs.confluent.io/platform/current/schema-registry/connect.html#schemaregistry-kafka-connect">Schema Registry</a></li>
<li><strong>JsonConverter</strong> <code>org.apache.kafka.connect.json.JsonConverter</code> (没有模式注册表):与结构化数据一起使用</li>
<li><strong>StringConverter</strong> <code>org.apache.kafka.connect.storage.StringConverter</code>简单的字符串格式</li>
<li><strong>ByteArrayConverter</strong> <code>org.apache.kafka.connect.converters.ByteArrayConverter</code>提供不进行转换的“直通”选项</li>
</ul>
<h4 id="Converter-Graphic"><a href="#Converter-Graphic" class="headerlink" title="Converter Graphic"></a>Converter Graphic</h4><p><img src="/images/kafka/converter-basics.png" alt="converter-basics" title="SourceConnector &amp; SinkConnector"></p>
<h3 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h3><p>单个消息转换（Single Message Transformations，下列简称SMT）应用于通过 Connect 的消息。</p>
<p>SMT 在源连接器（Source Connector）生成入站消息之后进行转换，但在它们被写入Kafka之前进行转换。<br>SMT 在出站消息发送到接收器连接器（Sink Connecors）之前对其进行转换。</p>
<p>可以在连接器配置中指定转换链。</p>
<ul>
<li><code>transforms</code> 转换别名列表，指定应用转换的顺序。</li>
<li><code>transforms.$alias.type</code> 转换的完全限定类名。</li>
<li><code>transforms.$alias.$transformationSpecificConfig</code> 转换的配置属性。</li>
</ul>
<p>示例：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># connector common config</span></span><br><span class="line"><span class="attr">name</span>=<span class="string">local-file-source</span></span><br><span class="line"><span class="meta">connector.class</span>=<span class="string">FileStreamSource</span></span><br><span class="line"><span class="meta">tasks.max</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">file</span>=<span class="string">test.txt</span></span><br><span class="line"><span class="attr">topic</span>=<span class="string">connect-test</span></span><br><span class="line"><span class="comment"># transforms chain: MakeMap--InsertSource</span></span><br><span class="line"><span class="attr">transforms</span>=<span class="string">MakeMap, InsertSource</span></span><br><span class="line"><span class="comment"># config for MakeMap transform</span></span><br><span class="line"><span class="meta">transforms.MakeMap.type</span>=<span class="string">org.apache.kafka.connect.transforms.HoistField$Value</span></span><br><span class="line"><span class="meta">transforms.MakeMap.field</span>=<span class="string">line</span></span><br><span class="line"><span class="comment"># config for InsertSource transform</span></span><br><span class="line"><span class="meta">transforms.InsertSource.type</span>=<span class="string">org.apache.kafka.connect.transforms.InsertField$Value</span></span><br><span class="line"><span class="meta">transforms.InsertSource.static.field</span>=<span class="string">data_source</span></span><br><span class="line"><span class="meta">transforms.InsertSource.static.value</span>=<span class="string">test-file-source</span></span><br></pre></td></tr></table></figure>
<p>Kafka Connect 包含了一些广泛适用的数据和路由转换：</p>
<ul>
<li><code>InsertField</code> 使用静态数据或记录元数据添加字段</li>
<li><code>ReplaceField</code> 过滤或重命名字段</li>
<li><code>MaskField</code>将字段替换为类型的有效null值(如 0，false 及空字符串等等)</li>
<li><code>ValueToKey</code> 将记录键替换为由记录值中的字段子集形成的新键</li>
<li><code>HoistField</code> 将整个事件作为单个字段包装在结构或映射中</li>
<li><code>ExtractField</code>从 Struct 和 Map 中提取一个特定的字段，并在结果中只包含这个字段</li>
<li><code>SetSchemaMetadata</code> 修改模式名称或版本</li>
<li><code>TimestampRouter</code>基于原始主题和时间戳修改记录的主题。当使用接收器时，需要根据时间戳写入不同的表或索引</li>
<li><code>RegexRouter</code> 基于原始主题、替换字符串和正则表达式修改记录的主题</li>
</ul>
<h3 id="Dead-Letter-Queue"><a href="#Dead-Letter-Queue" class="headerlink" title="Dead Letter Queue"></a>Dead Letter Queue</h3><p>出现无效记录的原因有很多。一个例子是，当一条记录以 JSON 格式序列化到达 Sink Connector 时，但 Sink Connector 配置要求为 Avro 格式。当 Sink Connector 无法处理无效记录时，将根据 Connector 配置属性 <code>errors.tolerance</code> （错误容忍）处理错误。<strong>Dead Letter Queue 仅适用于 Sink Connector。</strong></p>
<p>此配置属性有两个有效值: <code>none</code> (默认值)或 <code>all</code>。</p>
<p>当 <code>errors.tolerance</code> 设置为 <code>none</code> 时，错误或无效记录将导致 Connector Task 立即失败，并且 Connector 进入失败状态。要解决此问题，需要查看 Kafka Connect Worker 日志以找出导致故障的原因，进行纠正，然后重新启动 Connector。</p>
<p>当 <code>errors.tolerance</code> 设置为 <code>all</code> 时，将忽略所有错误或无效记录，并继续处理。Connect Worker 日志中没有写入错误。为了确定记录是否失败，必须使用内部度量或计算源处的记录数量，并将其与所处理的记录数量进行比较。</p>
<p>有一个错误处理特性，它将把所有无效的记录路由到一个特殊的主题并报告错误。该主题包含 Sink Connector 无法处理的记录的 <strong>Dead Letter Queue</strong>。</p>
<p>SinkConnector 配置：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">errors.tolerance</span> = <span class="string">all</span></span><br><span class="line"><span class="meta">errors.deadletterqueue.topic.name</span> = <span class="string">&lt;dead-letter-topic-name&gt;</span></span><br></pre></td></tr></table></figure>
<p>即使 <strong>Dead Letter Queue</strong> 包含失败的记录，它也没有显示原因。可以添加以下附加配置属性以包含失败的记录头信息。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">errors.deadletterqueue.context.headers.enable</span> = <span class="string">true</span></span><br></pre></td></tr></table></figure>


<p>当该参数设置为 <code>true</code> (默认为<code>false</code>)时，记录头被添加到死信队列中。然后可以查看记录头，并确定记录失败的原因。错误也被发送到 <a href="https://docs.confluent.io/home/connect/userguide.html#userguide-connect-reporter">Connect Reporter</a>。为了避免与原始记录头冲突，<strong>Dead Letter Queue</strong> 上下文头键以 <code>_connect.errors</code> 开头。</p>
<h2 id="Deployment-Configuration"><a href="#Deployment-Configuration" class="headerlink" title="Deployment Configuration"></a>Deployment Configuration</h2><p>Common（Standalone &amp; Distributed）</p>
<ul>
<li><code>bootstrap.servers</code> Kafka 服务器列表。</li>
<li><code>key.converter</code> 用于在 Kafka 连接格式和写入 Kafka 的序列化格式之间转换的转换器类。它控制了写入或从 Kafka 读取的消息中的<strong>键</strong>的格式，并且由于它独立于连接器，它允许任何连接器使用任何序列化格式。常见的格式包括JSON和Avro。</li>
<li><code>value.converter</code> 用于在 Kafka 连接格式和写入 Kafka 的序列化格式之间转换的转换器类。它控制了写入或从 Kafka 读取的消息中的<strong>值</strong>的格式，并且由于它独立于连接器，它允许任何连接器使用任何序列化格式。常见的格式包括JSON和Avro。</li>
</ul>
<p>Standalone</p>
<ul>
<li><code>offset.storage.file.filename</code> 文件中存储偏移量数据</li>
</ul>
<p>Distributed</p>
<ul>
<li><code>group.id</code> (默认为 connect-cluster`) 集群的唯一名称，用于形成Connect集群组；<strong>注意，这一定不能与消费组id冲突</strong></li>
<li><code>config.storage.topic</code> (默认为<code>connect-configs</code>) 用于存储 Connector 和 Task 配置的主题；注意，这应该是一个单独的分区，高度复制，压缩主题（您可能需要手动创建主题，以确保正确的配置，因为自动创建的主题可能有多个分区，或者自动配置为删除而不是压缩）</li>
<li><code>offset.storage.topic</code> (默认为 <code>connect-offsets</code>) 用于存储偏移量的主题；这个主题应该有许多分区，可以复制，并配置为压缩</li>
<li><code>status.storage.topic</code> (默认为 <code>connect-status</code>) 用于存储状态的主题；这个主题可以有多个分区，应该进行复制和配置以进行压缩</li>
</ul>
<h2 id="Connect-Plugins"><a href="#Connect-Plugins" class="headerlink" title="Connect Plugins"></a>Connect Plugins</h2><p>Kafka Connect 被设计为可扩展的，因此开发人员可以创建自定义连接器(Connectors)，变形器(Transforms)或转换器(Converters)，用户可以安装和运行它们。</p>
<p>Kafka Connect 插件是一组 JAR 文件，其中包含一个或多个 Connectors、Transforms 或 Converters 的实现。Connect 将每个插件彼此隔离，这样一个插件中的库就不会受到任何其他插件中的库的影响。这在混合和匹配来自多个供应商的连接器时非常重要。</p>
<p>一个 Kafka Connect 插件可以是：</p>
<ul>
<li><p>文件系统上的一个目录，包含所有需要的 JAR 文件和插件的第三方依赖项。<strong>这是最常见和首选的。</strong></p>
</li>
<li><p>一个包含插件及其第三方依赖项的所有类文件的 uber JAR。</p>
<p>(<code>Über</code> is the German word for <code>above</code> or <code>over</code> (it’s actually cognate with the English <code>over</code>).  <a href="https://stackoverflow.com/questions/11947037/what-is-an-uber-jar">https://stackoverflow.com/questions/11947037/what-is-an-uber-jar</a>)</p>
</li>
</ul>
<blockquote>
<p><strong>一个插件不应该包含 Kafka Connect 运行时提供的任何库。</strong></p>
</blockquote>
<p>Kafka Connect 在 Worker Configuration 的  <code>plugin.path</code> 属性中使用一个以逗号分隔的目录路径列表定义的插件路径查找插件。</p>
<p>当启动 Connect Worker 时，每个 Worker 都会在插件路径的目录中发现所有 Connectors、Transforms 和 Converters 插件。当使用 Connectors、Transforms 和 Converters 时，Connect Worker 首先从各自的插件加载类，然后是 Kafka Connect 运行时和 Java 库。</p>
<h2 id="Connect-API"><a href="#Connect-API" class="headerlink" title="Connect API"></a>Connect API</h2><h3 id="Java-API"><a href="#Java-API" class="headerlink" title="Java API"></a>Java API</h3><blockquote>
<p>本节列举了一般需要重写的方法，更详尽的 Java API 请参见</p>
<p><a href="http://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/connect">http://kafka.apache.org/24/javadoc/index.html?org/apache/kafka/connect</a></p>
</blockquote>
<h4 id="SinkConnector"><a href="#SinkConnector" class="headerlink" title="SinkConnector"></a>SinkConnector</h4><ul>
<li><code>public abstract void start(Map&lt;String,String&gt; props)</code><br>启动这个连接器。这个方法只会在一个干净的连接器上被调用，也就是说，它要么刚刚被实例化和初始化，要么已经调用了stop()。</li>
<li><code>public abstract void stop()</code><br>停止这个连接器。</li>
<li><code>public abstract Class&lt;? extends Task&gt; taskClass()</code><br>返回此连接器的任务实现。</li>
<li><code>public abstract ConfigDef config()</code><br>定义连接器的配置。</li>
<li><code>public abstract List&lt;Map&lt;String,String&gt;&gt; taskConfigs(int maxTasks)</code><br>根据当前配置返回任务的一组配置。</li>
<li><code>String version()</code><br>获取该连接器的版本。</li>
</ul>
<h4 id="SinkTask"><a href="#SinkTask" class="headerlink" title="SinkTask"></a>SinkTask</h4><ul>
<li><code>public abstract void start(Map&lt;String,String&gt; props)</code><br>启动任务。这应该可以处理任何配置解析和任务的一次性设置。</li>
<li><code>public abstract void put(Collection&lt;SinkRecord&gt; records)</code><br>将事件记录数据传递到此任务。</li>
<li><code>public abstract void stop()</code><br>执行清理操作以停止此任务。</li>
<li><code>String version()</code><br>获取此任务的版本。通常这应该与对应的连接器类的版本相同。</li>
</ul>
<h3 id="REST-API"><a href="#REST-API" class="headerlink" title="REST API"></a>REST API</h3><blockquote>
<p>Default Port: <code>8083</code></p>
</blockquote>
<ul>
<li><code>GET /connectors</code> 返回连接器的列表。</li>
<li><code>POST /connectors</code> 创建一个新的连接器。请求主体应该是一个JSON对象，其中包含一个字符串 <code>name</code> 字段和一个带有连接器 <code>config</code> 参数的对象配置字段。</li>
<li><code>GET /connectors/&#123;name&#125;</code>获取指定连接器的信息。</li>
<li><code>GET /connectors/&#123;name&#125;/config</code> 获取指定连接器的配置参数。</li>
<li><code>PUT /connectors/&#123;name&#125;/config</code> 更新指定连接器的配置参数。</li>
<li><code>GET /connectors/&#123;name&#125;/status</code> 获取连接器的当前状态，包括它是否正在运行、失败、暂停等、它被分配给哪个工作器、失败时的错误信息以及它所有任务的状态。<ul>
<li><code>UNASSIGNED</code>: Connector/Task 暂未分配到 Worker。</li>
<li><code>RUNNING</code>: Connector/Task 正在运行。</li>
<li><code>PAUSED</code>: Connector/Task 在管理上已暂停。</li>
<li><code>FAILED</code>: Connector/Task 运行失败，通常是发生了异常。</li>
<li><code>DESTROYED</code>: Connector/Task 在管理上已被删除，将被移除集群。</li>
</ul>
</li>
<li><code>GET /connectors/&#123;name&#125;/tasks</code> 获取连接器当前正在运行的任务列表。</li>
<li><code>GET /connectors/&#123;name&#125;/tasks/&#123;taskid&#125;/status</code> 获取任务的当前状态，包括它是否正在运行、失败、暂停等，它被分配给哪个 Worker，以及失败时的错误信息。</li>
<li><code>PUT /connectors/&#123;name&#125;/pause</code> 暂停连接器及其任务，这将停止消息处理，直到连接器恢复。</li>
<li><code>PUT /connectors/&#123;name&#125;/resume</code> 恢复暂停的连接器(如果连接器没有暂停，则不做任何操作)。</li>
<li><code>POST /connectors/&#123;name&#125;/restart</code> 重新启动连接器(通常是因为它失败了)。</li>
<li><code>POST /connectors/&#123;name&#125;/tasks/&#123;taskId&#125;/restart</code> 重新启动单个任务(通常是因为它失败了)。</li>
<li><code>DELETE /connectors/&#123;name&#125;</code> 删除连接器，停止所有任务并删除其配置。</li>
<li><code>GET /connector-plugins</code> 返回一个Kafka Connect集群中安装的连接器插件列表。</li>
<li><code>PUT /connector-plugins/&#123;connector-type&#125;/config/validate</code> 根据配置定义验证提供的配置值。这个API执行每个配置验证，并在验证过程中返回建议值和错误消息。</li>
</ul>
<h3 id="Ops"><a href="#Ops" class="headerlink" title="Ops"></a>Ops</h3><h4 id="Kafka-Connect-Logging"><a href="#Kafka-Connect-Logging" class="headerlink" title="Kafka Connect Logging"></a>Kafka Connect Logging</h4><blockquote>
<p><a href="https://docs.confluent.io/platform/current/connect/logging.html#">https://docs.confluent.io/platform/current/connect/logging.html#</a></p>
</blockquote>
<ul>
<li><p>Check log levels</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -Ss http:&#x2F;&#x2F;localhost:8083&#x2F;admin&#x2F;loggers | jq</span><br></pre></td></tr></table></figure></li>
<li><p>Change the log level for a specific logger</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -s -X PUT -H &quot;Content-Type:application&#x2F;json&quot; \</span><br><span class="line">http:&#x2F;&#x2F;localhost:8083&#x2F;admin&#x2F;loggers&#x2F;city.icos.icmsevent.connect \</span><br><span class="line">-d &#39;&#123;&quot;level&quot;: &quot;DEBUG&quot;&#125;&#39; | jq &#39;.&#39;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h2 id="Lenses-io"><a href="#Lenses-io" class="headerlink" title="Lenses.io"></a>Lenses.io</h2><h3 id="Kakfa-Connect-UI"><a href="#Kakfa-Connect-UI" class="headerlink" title="Kakfa Connect UI"></a>Kakfa Connect UI</h3><blockquote>
<p><a href="https://github.com/lensesio/kafka-connect-ui">https://github.com/lensesio/kafka-connect-ui</a></p>
</blockquote>
<h3 id="Kafka-Connect-CLI"><a href="#Kafka-Connect-CLI" class="headerlink" title="Kafka Connect CLI"></a>Kafka Connect CLI</h3><blockquote>
<p><a href="https://github.com/lensesio/kafka-connect-tools">https://github.com/lensesio/kafka-connect-tools</a></p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">connect-cli 1.0.8</span><br><span class="line">Usage: connect-cli [ps|get|rm|create|run|diff|status|plugins|describe|validate|restart|pause|resume] [options] [<span class="xml"><span class="tag">&lt;<span class="name">connector-name</span>&gt;</span></span>]</span><br><span class="line"></span><br><span class="line">  --help</span><br><span class="line"><span class="code">        prints this usage text</span></span><br><span class="line"><span class="code">  -e &lt;value&gt; | --endpoint &lt;value&gt;</span></span><br><span class="line"><span class="code">        Kafka Connect REST URL, default is http://localhost:8083/</span></span><br><span class="line"><span class="code">  -f &lt;value&gt; | --format &lt;value&gt;</span></span><br><span class="line"><span class="code">        Format of the config, default is PROPERTIES. Valid options are &#x27;properties&#x27; and &#x27;json&#x27;.</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">  Command: ps</span></span><br><span class="line"><span class="code">  list active connectors names.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: get</span></span><br><span class="line"><span class="code">  get the configuration of the specified connector.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: rm</span></span><br><span class="line"><span class="code">  remove the specified connector.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: create</span></span><br><span class="line"><span class="code">  create the specified connector with the config from stdin; the connector cannot already exist.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: run</span></span><br><span class="line"><span class="code">  create or update the specified connector with the config from stdin.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: diff</span></span><br><span class="line"><span class="code">  diff the specified connector with the config from stdin.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: status</span></span><br><span class="line"><span class="code">  get connector and it&#x27;s task(s) state(s).</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: plugins</span></span><br><span class="line"><span class="code">  list the available connector class plugins on the classpath.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: describe</span></span><br><span class="line"><span class="code">  list the configurations for a connector class plugin on the classpath.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: pause</span></span><br><span class="line"><span class="code">  pause the specified connector.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: restart</span></span><br><span class="line"><span class="code">  restart the specified connector.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: resume</span></span><br><span class="line"><span class="code">  resume the specified connector.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: validate</span></span><br><span class="line"><span class="code">  validate the connector config from stdin against a connector class plugin on the classpath.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: task_ps</span></span><br><span class="line"><span class="code">  list the tasks belonging to a connector.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: task_status</span></span><br><span class="line"><span class="code">  get the status of a connector task.</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  Command: task_restart</span></span><br><span class="line"><span class="code">  restart the specified connector task.</span></span><br></pre></td></tr></table></figure>


<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://kafka.apache.org/24/documentation.html#connect">http://kafka.apache.org/24/documentation.html#connect</a></p>
<p><a href="https://docs.confluent.io/5.5.0/connect/index.html">https://docs.confluent.io/5.5.0/connect/index.html</a></p>
]]></content>
      <categories>
        <category>EventBus</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Kafka Connect</tag>
        <tag>Streaming</tag>
        <tag>Sink</tag>
        <tag>Source</tag>
      </tags>
  </entry>
  <entry>
    <title>RedisGears 笔记</title>
    <url>/2021/04/22/redisgears-notes/</url>
    <content><![CDATA[<p>RedisGears 版本: <code>v1.0</code></p>
<h2 id="Home"><a href="#Home" class="headerlink" title="Home"></a>Home</h2><blockquote>
<p>RedisGears -  Redis 中数据处理的可编程引擎。</p>
</blockquote>
<p>RedisGears 是一个 Serverless 的引擎，用于处理 Redis 中的事务、批处理和事件驱动的数据。它是一个动态的执行函数的框架，而这些函数反过来又实现了 Redis 的数据流，同时(几乎)完全抽象了数据的分布和部署的选择(如单机vs集群，OSS vs企业级)。函数可以用不同的语言实现，包括 Python and C APIs。</p>
<h3 id="Diagram-Components"><a href="#Diagram-Components" class="headerlink" title="Diagram Components"></a>Diagram Components</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+---------------------------------------------------------------------+</span><br><span class="line">| Redis Server               +--------------------------------------+ |</span><br><span class="line">|                            | RedisGears Module                    | |</span><br><span class="line">| +----------------+         |                                      | |</span><br><span class="line">| | Data           | Input   | +------------+ +-------------------+ | |</span><br><span class="line">| |                +--------&gt;+ | Function   | | APIs              | | |</span><br><span class="line">| | Key1 : Value1  |         | | +--------+ | | C, Python, ...    | | |</span><br><span class="line">| | Key2 : Value2  | Output  | | | Reader | | +-------------------+ | |</span><br><span class="line">| | Key3 : Value3  &lt;---------+ | +---+----+ | +-------------------+ | |</span><br><span class="line">| |      ...       |         | |     v      | | Redis commands    | | |</span><br><span class="line">| +----------------+         | | +---+----+ | | Gears admin &amp; ops | | |</span><br><span class="line">|                            | | | Step 1 | | +-------------------+ | |</span><br><span class="line">|                            | | +---+----+ | +-------------------+ | |</span><br><span class="line">| +----------------+         | |     v      | | Coordinator       | | |</span><br><span class="line">| | Events         |         | | +---+----+ | | Cluster MapReduce | | |</span><br><span class="line">| |                | Trigger | | | Step 2 | | +-------------------+ | |</span><br><span class="line">| | Data update    +--------&gt;+ | +---+----+ | +-------------------+ | |</span><br><span class="line">| | Stream message |         | |     v      | | Engine            | | |</span><br><span class="line">| | Time interval  |         | |    ...     | | Runtime execution | | |</span><br><span class="line">| |      ...       |         | +------------+ +-------------------+ | |</span><br><span class="line">| +----------------+         +--------------------------------------+ |</span><br><span class="line">+---------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>


<h2 id="Quickstart"><a href="#Quickstart" class="headerlink" title="Quickstart"></a>Quickstart</h2><h3 id="RedisGears-Cluster"><a href="#RedisGears-Cluster" class="headerlink" title="RedisGears Cluster"></a>RedisGears Cluster</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -p 30001:30001 -p 30002:30002 -p 30003:30003 redislabs&#x2F;rgcluster:latest</span><br></pre></td></tr></table></figure>


<h3 id="RedisGears-Standalone"><a href="#RedisGears-Standalone" class="headerlink" title="RedisGears Standalone"></a>RedisGears Standalone</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> run</span> </span><br><span class="line">docker run -d --name redisgears -p 6379:6379 redislabs/redisgears:latest</span><br><span class="line"><span class="meta">#</span><span class="bash"> redis-cli</span> </span><br><span class="line">docker exec -it redisgears redis-cli</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">function</span></span></span><br><span class="line">RG.PYEXECUTE &quot;GearsBuilder().run()&quot;</span><br></pre></td></tr></table></figure>


<p><code>RG</code> 是 <code>GearsBuilder()</code> 的别名。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Reader"><a href="#Reader" class="headerlink" title="Reader"></a>Reader</h3><ul>
<li>KeysReader</li>
</ul>
<h3 id="Keys-Pattern"><a href="#Keys-Pattern" class="headerlink" title="Keys Pattern"></a>Keys Pattern</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RG.PYEXECUTE &quot;GearsBuilder().run(&#39;person:*&#39;)&quot;</span><br></pre></td></tr></table></figure>


<h3 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h3><h4 id="执行复杂函数"><a href="#执行复杂函数" class="headerlink" title="执行复杂函数"></a>执行复杂函数</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat mygear.py | docker exec -i redisgears redis-cli -x RG.PYEXECUTE</span><br></pre></td></tr></table></figure>


<h4 id=""><a href="#" class="headerlink" title=""></a></h4><ul>
<li><p><code>filter</code></p>
</li>
<li><p><code>map</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gb = GearsBuilder()                       # declare a function builder</span><br><span class="line">gb.map(lambda x: int(x[&#x27;value&#x27;][&#x27;age&#x27;]))  # map each record to just an age</span><br><span class="line">gb.run(&#x27;person:*&#x27;)                        # run it</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Expected result: [70, 14]</span></span></span><br></pre></td></tr></table></figure>

</li>
<li><p><code>accumulate</code></p>
</li>
</ul>
<h3 id="Blocking-vs-Nonblocking-Execution"><a href="#Blocking-vs-Nonblocking-Execution" class="headerlink" title="Blocking vs. Nonblocking Execution"></a>Blocking vs. Nonblocking Execution</h3><h4 id="UNBLOCKING"><a href="#UNBLOCKING" class="headerlink" title="UNBLOCKING"></a>UNBLOCKING</h4><blockquote>
<p>非阻塞模式执行</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; RG.PYEXECUTE &quot;GB().run()&quot; UNBLOCKING</span><br><span class="line">&quot;0000000000000000000000000000000000000000-0&quot;</span><br></pre></td></tr></table></figure>
<h4 id="RG-DUMPEXECUTIONS"><a href="#RG-DUMPEXECUTIONS" class="headerlink" title="RG.DUMPEXECUTIONS"></a>RG.DUMPEXECUTIONS</h4><blockquote>
<p>执行状态</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; RG.DUMPEXECUTIONS</span><br><span class="line">1) 1) &quot;executionId&quot;</span><br><span class="line">   2) &quot;0000000000000000000000000000000000000000-0&quot;</span><br><span class="line">   3) &quot;status&quot;</span><br><span class="line">   4) &quot;done&quot;</span><br></pre></td></tr></table></figure>
<h4 id="RG-GETRESULTS"><a href="#RG-GETRESULTS" class="headerlink" title="RG.GETRESULTS"></a>RG.GETRESULTS</h4><blockquote>
<p>获取结果</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; RG.GETRESULTS 0000000000000000000000000000000000000000-0</span><br><span class="line">1) 1) &quot;&#123;&#x27;key&#x27;: &#x27;foo&#x27;, &#x27;value&#x27;: &#x27;bar&#x27;&#125;&quot;</span><br><span class="line">   2) &quot;&#123;&#x27;key&#x27;: &#x27;person:1&#x27;, &#x27;value&#x27;: &#123;&#x27;age&#x27;: &#x27;70&#x27;, &#x27;name&#x27;: &#x27;Rick Sanchez&#x27;&#125;&#125;&quot;</span><br><span class="line">   3) &quot;&#123;&#x27;key&#x27;: &#x27;person:2&#x27;, &#x27;value&#x27;: &#123;&#x27;age&#x27;: &#x27;14&#x27;, &#x27;name&#x27;: &#x27;Morty Smith&#x27;&#125;&#125;&quot;</span><br><span class="line">2) (empty list or set)</span><br></pre></td></tr></table></figure>
<h4 id="RG-GETRESULTSBLOCKING"><a href="#RG-GETRESULTSBLOCKING" class="headerlink" title="RG.GETRESULTSBLOCKING"></a>RG.GETRESULTSBLOCKING</h4><blockquote>
<p>转入阻塞模式，等待结果</p>
</blockquote>
<h3 id="Event-Processing"><a href="#Event-Processing" class="headerlink" title="Event Processing"></a>Event Processing</h3><blockquote>
<p>默认是非阻塞执行</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gb.register()</span><br><span class="line">RG.DUMPEXECUTIONS      ## 执行状态</span><br><span class="line">RG.GETRESULTS          ## 获取结果</span><br></pre></td></tr></table></figure>


<h3 id="Writing-Data"><a href="#Writing-Data" class="headerlink" title="Writing Data"></a>Writing Data</h3><blockquote>
<p>execute()</p>
<p>RedisGears Python API 附带 execute ()函数，该函数允许在数据库中执行任意 Redis 命令。</p>
</blockquote>
<h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name rgcluster -p 30001:30001 -p 30002:30002 -p 30003:30003 redislabs/rgcluster:latest</span><br><span class="line"></span><br><span class="line">docker exec -i rgcluster redis-cli -c -p 30001 &lt; data.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认情况下，cli 不遵循集群的重定向。要让 cli 自动在分片之间跳转，请使用 -c 命令行开关启动它。</span></span><br></pre></td></tr></table></figure>
<p>data.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET foo bar</span><br><span class="line">HSET person:1 name &quot;Rick Sanchez&quot; age 70</span><br><span class="line">HSET person:2 name &quot;Morty Smith&quot; age 14</span><br><span class="line">HSET person:3 name &quot;Summer Smith&quot; age 17</span><br><span class="line">HSET person:4 name &quot;Beth Smith&quot; age 35</span><br><span class="line">HSET person:5 name &quot;Shrimply Pibbles&quot; age 87</span><br></pre></td></tr></table></figure>


<h3 id="Distributed-Processing"><a href="#Distributed-Processing" class="headerlink" title="Distributed Processing"></a>Distributed Processing</h3><blockquote>
<p>当 RedisGears 在集群中运行时，默认情况下它将在集群的所有分片上执行函数。通过向 run ()操作提供 collect = False 参数来禁用。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:30001&gt; RG.PYEXECUTE &quot;GB().run(collect=False)&quot;</span><br><span class="line">1) 1) &quot;&#123;&#x27;key&#x27;: &#x27;person:1&#x27;, &#x27;value&#x27;: &#123;&#x27;age&#x27;: &#x27;70&#x27;, &#x27;name&#x27;: &#x27;Rick Sanchez&#x27;&#125;&#125;&quot;</span><br><span class="line">   2) &quot;&#123;&#x27;key&#x27;: &#x27;person:5&#x27;, &#x27;value&#x27;: &#123;&#x27;age&#x27;: &#x27;87&#x27;, &#x27;name&#x27;: &#x27;Shrimply Pibbles&#x27;&#125;&#125;&quot;</span><br><span class="line">2) (empty list or set)</span><br></pre></td></tr></table></figure>


<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><h3 id="Cluster-Map-and-Reduce"><a href="#Cluster-Map-and-Reduce" class="headerlink" title="Cluster Map and Reduce"></a>Cluster Map and Reduce</h3><blockquote>
<p>accumulate-collect，这种情况只会将每个分片的最大值收集起来</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">def maximum(a, x):</span><br><span class="line">  &#x27;&#x27;&#x27; Returns the maximum &#x27;&#x27;&#x27;</span><br><span class="line">  a = a if a else 0       # initialize the accumulator</span><br><span class="line">  return max(a, x)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Original, non-reduced, maximum <span class="keyword">function</span> version</span></span><br><span class="line">gb = GearsBuilder()</span><br><span class="line">gb.map(lambda x: int(x[&#x27;value&#x27;][&#x27;age&#x27;]))</span><br><span class="line">gb.accumulate(maximum)</span><br><span class="line">gb.run(&#x27;person:*&#x27;)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Expected result: [87, 35, 14]</span></span></span><br></pre></td></tr></table></figure>


<blockquote>
<p> accumulate-collect-accumulate，这种情况会将所有分片的最大值收集起来后再计算最大值，得到最佳结果（1 个最大值）</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">def maximum(a, x):</span><br><span class="line">  &#x27;&#x27;&#x27; Returns the maximum &#x27;&#x27;&#x27;</span><br><span class="line">  a = a if a else 0       # initialize the accumulator</span><br><span class="line">  return max(a, x)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Reduced maximum <span class="keyword">function</span></span></span><br><span class="line">gb = GearsBuilder()</span><br><span class="line">gb.map(lambda x: int(x[&#x27;value&#x27;][&#x27;age&#x27;]))</span><br><span class="line">gb.accumulate(maximum)</span><br><span class="line">gb.collect()</span><br><span class="line">gb.accumulate(maximum)</span><br><span class="line">gb.run(&#x27;person:*&#x27;)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Expected result: [87]</span></span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>aggregate()</p>
</blockquote>
<p>RedisGears Python API 包含 <code>aggregate()</code> 操作，该操作将<code>accumulate-collect-accumulate</code>步骤包装为单个步骤：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Aggregated maximum version</span></span><br><span class="line">gb = GearsBuilder()</span><br><span class="line">gb.map(lambda x: int(x[&#x27;value&#x27;][&#x27;age&#x27;]))</span><br><span class="line">gb.aggregate(0,</span><br><span class="line">             lambda a, x: max(a, x),</span><br><span class="line">             lambda a, x: max(a, x))</span><br><span class="line">gb.run(&#x27;person:*&#x27;)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Expected result: [87]</span></span></span><br></pre></td></tr></table></figure>
<p><code>aggregate()</code> 接受三个参数: 第一个是累加器的零值，另外两个是对累加函数的回调，这些函数将分别在本地和全局执行。</p>
<h3 id="Local-vs-Global"><a href="#Local-vs-Global" class="headerlink" title="Local vs. Global"></a>Local vs. Global</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">localgroupby  ## 由每个分片的引擎在本地执行</span><br><span class="line">groupby       ## 将结果重新分区，再由每个分片的引擎在本地执行 &#x3D; repartition + localgroupby</span><br></pre></td></tr></table></figure>


<h4 id="Diagram-localgroupby-groupby"><a href="#Diagram-localgroupby-groupby" class="headerlink" title="Diagram(localgroupby, groupby)"></a>Diagram(localgroupby, groupby)</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+----------------------+   +----------------------+   +----------------------+</span><br><span class="line">| Shard A              |   | Shard B              |   | Shard C              |</span><br><span class="line">| +----------+-------+ |   | +----------+-------+ |   | +----------+-------+ |</span><br><span class="line">| | Key      | Value | |   | | Key      | Value | |   | | Key      | Value | |</span><br><span class="line">| +------------------+ |   | +------------------+ |   | +------------------+ |</span><br><span class="line">| | person:1 | &#123;...&#125; | |   | | person:3 | &#123;...&#125; | |   | | foo      | bar   | |</span><br><span class="line">| | person:5 | &#123;...&#125; | |   | | person:4 | &#123;...&#125; | |   | | person:2 | &#123;...&#125; | |</span><br><span class="line">| +-+--------+-------+ |   | +-+--------+-------+ |   | +-+--------+-------+ |</span><br><span class="line">|   v localgroupby()   |   |   v localgroupby()   |   |   v localgroupby()   |</span><br><span class="line">| +-+--------+-------+ |   | +-+--------+-------+ |   | +-+--------+-------+ |</span><br><span class="line">| | Key      | Value | |   | | Key      | Value | |   | | Key      | Value | |</span><br><span class="line">| +------------------+ |   | +------------------+ |   | +------------------+ |</span><br><span class="line">| | Sanchez  | 1     | |   | | Smith    | 2     | |   | | Smith    | 1     | |</span><br><span class="line">| | Pibbles  | 1     | |   | +-+----------------+ |   | +-+----------------+ |</span><br><span class="line">| +-+--------+-------+ |   |                      |   |                      |</span><br><span class="line">+----------------------+   +----------------------+   +----------------------+</span><br><span class="line">|   v repartition()    |   |   v repartition()    |   |   v repartition()    |</span><br><span class="line">| +-+--------+-------+ |   | +-+--------+-------+ |   | +-+--------+-------+ |</span><br><span class="line">| | Key      | Value | |   | | Key      | Value | |   | | Key      | Value | |</span><br><span class="line">| +------------------+ |   | +------------------+ |   | +------------------+ |</span><br><span class="line">| | Pibbles  | 1     | |   | | Sanchez  | 1     | |   | | Smith    | 2     | |</span><br><span class="line">| +------------------+ |   | +------------------+ |   | | Smith    | 1     | |</span><br><span class="line">|                      |   |                      |   | +------------------+ |</span><br><span class="line">|   v localgroupby()   |   |   v localgroupby()   |   |   v localgroupby()   |</span><br><span class="line">| +-+--------+-------+ |   | +-+--------+-------+ |   | +-+--------+-------+ |</span><br><span class="line">| | Key      | Value | |   | | Key      | Value | |   | | Key      | Value | |</span><br><span class="line">| +------------------+ |   | +------------------+ |   | +------------------+ |</span><br><span class="line">| | Pibbles  | 1     | |   | | Sanchez  | 1     | |   | | Smith    | 3     | |</span><br><span class="line">| +------------------+ |   | +------------------+ |   | +------------------+ |</span><br><span class="line">|                      |   +---|------------------+   +---|------------------+</span><br><span class="line">|                      |       |                          |</span><br><span class="line">| +-+--------+-------+ |       |   Implicit collect()     |</span><br><span class="line">| | Key      | Value |&lt;--------+--------------------------+</span><br><span class="line">| +------------------+ |</span><br><span class="line">| | Sanchez  | 1     | |</span><br><span class="line">| | Pibbles  | 1     | |</span><br><span class="line">| | Smith    | 3     | |</span><br><span class="line">| +------------------+ |</span><br><span class="line">+----------------------+</span><br></pre></td></tr></table></figure>


<p>当绝对需要时，函数可以使用任意键对集群中的数据进行重新分区。当数据被重新分区时，每个工作线程被分配一个记录键的子集，并且这些键从所有其他工作线程传递到它。</p>
<h4 id="Mock-localgroupby-repartition-localgroupby"><a href="#Mock-localgroupby-repartition-localgroupby" class="headerlink" title="Mock(localgroupby, repartition, localgroupby)"></a>Mock(localgroupby, repartition, localgroupby)</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def fname(x):</span><br><span class="line">  &#39;&#39;&#39; Extracts the family name from a person&#39;s record &#39;&#39;&#39;</span><br><span class="line">  return x[&#39;value&#39;][&#39;name&#39;].split(&#39; &#39;)[1]</span><br><span class="line"></span><br><span class="line">def key(x):</span><br><span class="line">  &#39;&#39;&#39; Extracts the key of a record &#39;&#39;&#39;</span><br><span class="line">  return x[&#39;key&#39;]</span><br><span class="line"></span><br><span class="line">def counter(k, a, r):</span><br><span class="line">  &#39;&#39;&#39; Counts records &#39;&#39;&#39;</span><br><span class="line">  return (a if a else 0) + 1</span><br><span class="line"></span><br><span class="line">def summer(k, a, r):</span><br><span class="line">  &#39;&#39;&#39; Sums record values &#39;&#39;&#39;</span><br><span class="line">  return (a if a else 0) + r[&#39;value&#39;]</span><br><span class="line"></span><br><span class="line"># Repartition for storing counts</span><br><span class="line">gb &#x3D; GearsBuilder()</span><br><span class="line">gb.localgroupby(fname, counter)</span><br><span class="line">gb.repartition(key)</span><br><span class="line">gb.localgroupby(key, summer)</span><br><span class="line">gb.foreach(lambda x: execute(&#39;SET&#39;, x[&#39;key&#39;], x[&#39;value&#39;]))</span><br><span class="line">gb.run(&#39;person:*&#39;)</span><br><span class="line"></span><br><span class="line"># Expected result: the same + stored in Redis String keys</span><br></pre></td></tr></table></figure>
<p><strong>RedisGears 的 Python API 包含了 aggregateby ()操作，它等同于使用 GB () . localgroupby () . repartition () . localgroupby ()流。</strong></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><h3 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h3><blockquote>
<p><a href="https://oss.redislabs.com/redisgears/runtime.html">https://oss.redislabs.com/redisgears/runtime.html</a></p>
</blockquote>
<p>Python RedisGears 函数使用嵌入式 Python 解释器运行。每个函数都使用一个单独的子解释器。所有函数共享相同的环境和依赖关系。导入的环境有几个默认值。</p>
<h4 id="Python-Interpreter"><a href="#Python-Interpreter" class="headerlink" title="Python Interpreter"></a>Python Interpreter</h4><p>embeds python 3.7.2+</p>
<h4 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h4><p>解释器的环境可以用任何依赖的包进行扩展，这些包以后可以被它们各自的子解释器中的函数导入和使用。</p>
<h4 id="GearsBuilder"><a href="#GearsBuilder" class="headerlink" title="GearsBuilder"></a>GearsBuilder</h4><p>默认环境提供的函数上下文构造器。</p>
<h4 id="execute"><a href="#execute" class="headerlink" title="execute"></a>execute</h4><p>执行命令函数，默认环境提供的执行 Redis 命令的函数。</p>
<h5 id="Python-API"><a href="#Python-API" class="headerlink" title="Python API"></a>Python API</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute</span>(<span class="params">command, *args</span>)</span></span><br></pre></td></tr></table></figure>
<h5 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Pings the server (reply should be &#x27;PONG&#x27;)</span></span><br><span class="line">reply = execute(<span class="string">&#x27;PING&#x27;</span>)</span><br></pre></td></tr></table></figure>


<h4 id="atomic"><a href="#atomic" class="headerlink" title="atomic"></a>atomic</h4><p>原子操作函数，上下文通过阻塞主 Redis 进程来确保它中的所有操作都以原子的方式执行。</p>
<h5 id="Python-API-1"><a href="#Python-API-1" class="headerlink" title="Python API"></a>Python API</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">atomic</span>()</span></span><br></pre></td></tr></table></figure>
<h5 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Increments two keys atomically</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transaction</span>(<span class="params">_</span>):</span></span><br><span class="line">    <span class="keyword">with</span> atomic():</span><br><span class="line">        execute(<span class="string">&#x27;INCR&#x27;</span>, <span class="string">f&#x27;&#123;&#123;<span class="subst">&#123;hashtag()&#125;</span>&#125;&#125;:foo&#x27;</span>)</span><br><span class="line">        execute(<span class="string">&#x27;INCR&#x27;</span>, <span class="string">f&#x27;&#123;&#123;<span class="subst">&#123;hashtag()&#125;</span>&#125;&#125;:bar&#x27;</span>)</span><br><span class="line"></span><br><span class="line">gb = GB(<span class="string">&#x27;ShardsIDReader&#x27;</span>)</span><br><span class="line">gb.foreach(transaction)</span><br><span class="line">gb.run()</span><br></pre></td></tr></table></figure>
<h4 id="configGet"><a href="#configGet" class="headerlink" title="configGet"></a>configGet</h4><p>这个函数获取 RedisGears 配置选项的当前值。</p>
<h4 id="gearsConfigGet"><a href="#gearsConfigGet" class="headerlink" title="gearsConfigGet"></a>gearsConfigGet</h4><p>这个函数获取RedisGears配置选项的当前值，如果该键不存在，则返回默认值。</p>
<h4 id="hashtag"><a href="#hashtag" class="headerlink" title="hashtag"></a>hashtag</h4><p>这个函数返回一个 hashtag，该 hashtag 映射到本地引擎的分片所服务的最低哈希槽。换句话说，它作为一个 hashtag 在集群中进行分区时非常有用。</p>
<h4 id="log"><a href="#log" class="headerlink" title="log"></a>log</h4><p>这个函数打印一条消息到Redis的日志中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log</span>(<span class="params">message, level=<span class="string">&#x27;notice&#x27;</span></span>)</span></span><br></pre></td></tr></table></figure>
<p><code>level</code> 取值 <code>debug</code>,<code>verbose</code>,<code>notice</code>,<code>warning</code></p>
<h3 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h3><p>RedisGears 函数是数据流中处理步骤的正式描述。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                  +------------+</span><br><span class="line">                  | Function   |</span><br><span class="line">+-------------+   | +--------+ |</span><br><span class="line">| Input data  +--&gt;+ | Reader | |</span><br><span class="line">+-------------+   | +---+----+ |</span><br><span class="line">                  |     v      |</span><br><span class="line">                  | +---+----+ |</span><br><span class="line">                  | | Step 1 | |</span><br><span class="line">                  | +---+----+ |</span><br><span class="line">                  |     |      |</span><br><span class="line">                  |    ...     |</span><br><span class="line">                  |     v      |</span><br><span class="line">                  | +---+----+ |</span><br><span class="line">                  | | Step n | |</span><br><span class="line">                  | +---+----+ |</span><br><span class="line">                  |     v      |</span><br><span class="line">+-------------+   | +---+----+ |</span><br><span class="line">| Results     +&lt;--+ | Action | |</span><br><span class="line">+-------------+   | +--------+ |</span><br><span class="line">                  +------------+</span><br></pre></td></tr></table></figure>
<p>一个函数总是：</p>
<ol>
<li>始于一个 Reader</li>
<li>操作零个或多个 Records</li>
<li>包含零个或多个 Operations (Step)</li>
<li>终于一个 Action</li>
<li>返回零个或多个 Results</li>
<li>可能会产生更多错误。</li>
</ol>
<h4 id="Execution"><a href="#Execution" class="headerlink" title="Execution"></a>Execution</h4><p>一个函数由 RedisGears 引擎以以下两种方式之一执行:</p>
<ul>
<li><code>Batch</code> 立即执行，对已有数据执行</li>
<li><code>Event</code>由新事件及其数据触发执行</li>
</ul>
<p>函数的执行方式是由它的动作决定的。有两种类型的行动:</p>
<ul>
<li><code>Run</code> 批量运行函数</li>
<li><code>Register</code> 注册由事件触发的函数</li>
</ul>
<p>当以批处理或事件的形式执行时，函数的上下文由引擎管理。除了函数的逻辑之外，上下文还包括内部执行步骤、状态、统计数据、结果和遇到的任何错误。</p>
<h4 id="Execution-ID"><a href="#Execution-ID" class="headerlink" title="Execution ID"></a>Execution ID</h4><p>每个函数的执行都在内部分配了一个惟一的值，称为 <code>Execution ID</code>。</p>
<p>ID 是由两部分组成的字符串值，以“-”分隔，如下所示:</p>
<ul>
<li><code>Shard ID</code> 集群中一个 Shard 的标识符，长度为40个字节</li>
<li><code>Sequence</code> 一个不断增加的计数器</li>
</ul>
<p><code>Execution ID</code>示例：</p>
<p>Redis Standalone Mode: <code>0000000000000000000000000000000000000000-1</code></p>
<p>Redis Cluster Mode: <code>a007297351b007297351c007297351d007297351-1</code></p>
<h4 id="Execution-Plan"><a href="#Execution-Plan" class="headerlink" title="Execution Plan"></a>Execution Plan</h4><p>在执行该功能之前，引擎会生成一个执行计划。该计划包含引擎执行功能将采取的基本步骤。</p>
<h4 id="Execution-Parallelization"><a href="#Execution-Parallelization" class="headerlink" title="Execution Parallelization"></a>Execution Parallelization</h4><p>在集群中执行时，执行计划由启动器生成。然后，默认情况下，它将在所有碎片上共享并并行执行。</p>
<p>发起者的协调器协调分布式操作。</p>
<h4 id="Execution-Status"><a href="#Execution-Status" class="headerlink" title="Execution Status"></a>Execution Status</h4><p><code>Execution Status</code>描述了功能当前的执行状态。它可以是以下几种之一：<br><code>created</code> 已创建<br><code>running</code> 正在执行<br><code>done</code>执行完成<br><code>aborted</code>执行被终止<br><code>pending_cluster</code>启动器正在等待所有 Worker 执行完成<br><code>pending_run</code>Worker 挂起等待启动器确认执行<br><code>pending_receive</code>启动器在接收执行时挂起 Worker 的确认(ACK)<br><code>pending_termination</code>Worker 正在等待来自启动器的终止消息</p>
<p>下图演示了状态转换：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">       Initiator                                  Worker</span><br><span class="line">+---------------------+  execution plan   +---------------------+</span><br><span class="line">|             created +------------------&gt;+ created             |</span><br><span class="line">+----------+----------+                   +----------+----------+</span><br><span class="line">           v                                         v</span><br><span class="line">+----------+----------+  acknowledgement  +----------+----------+</span><br><span class="line">|     pending_receive +&lt;------------------+ pending_run         |</span><br><span class="line">+----------+----------+                   +---------------------+</span><br><span class="line">           v</span><br><span class="line">+----------+----------+  start execution  +---------------------+</span><br><span class="line">|             running +------------------&gt;+ running             |</span><br><span class="line">+----------+----------+                   +----------+----------+</span><br><span class="line">           v                                         v</span><br><span class="line">+----------+----------+      results      +----------+----------+</span><br><span class="line">|     pending_cluster +&lt;------------------+ pending_termination |</span><br><span class="line">+----------+----------+                   +---------------------+</span><br><span class="line">           v</span><br><span class="line">+----------+----------+     terminate     +---------------------+</span><br><span class="line">|                done +------------------&gt;+ done                |</span><br><span class="line">+---------------------+                   +---------------------+</span><br></pre></td></tr></table></figure>
<h4 id="Registration"><a href="#Registration" class="headerlink" title="Registration"></a>Registration</h4><p>事件驱动函数的表示称为注册(Registration)。</p>
<p>注册被持久化在 Redis 的快照中，也就是 RDB 文件中。这允许在发生故障时恢复数据库中的数据和事件处理程序。</p>
<h4 id="Registration-ID"><a href="#Registration-ID" class="headerlink" title="Registration ID"></a>Registration ID</h4><p>每个注册都有一个唯一的内部标识符，称为 <code>Registration ID</code>。它以与 <code>Execution ID</code> 相同的方式生成，尽管看起来相同，但两者不应该混淆。</p>
<h4 id="Context-Builder"><a href="#Context-Builder" class="headerlink" title="Context Builder"></a>Context Builder</h4><p>Python 中的 RedisGears 函数总是以一个上下文构建器——<code>GearsBuilder</code> 类开始。</p>
<h4 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h4><p>动作 (<code>Action</code>) 是一种特殊类型的操作。它总是函数的最后一步。</p>
<h5 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h5><p><code>Run</code>动作作为批处理(<code>Batch</code>)运行函数。函数只执行一次，一旦读取器耗尽数据就退出。</p>
<h6 id="Python-API-2"><a href="#Python-API-2" class="headerlink" title="Python API"></a>Python API</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GearsBuilder</span>.<span class="title">run</span>(<span class="params">arg=<span class="literal">None</span>, convertToStr=<span class="literal">True</span>, collect=<span class="literal">True</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>Arguments</p>
<ul>
<li>arg<ul>
<li>一个类似于全局的模式，用于 <code>KeysReader</code> 和 <code>KeysOnlyReader</code></li>
<li><code>StreamReader</code> 的密钥名称</li>
<li>用于 <code>PythonReader</code> 的 Python 生成器</li>
</ul>
</li>
<li>convertToStr 当为 <code>true</code>时将在流程末尾添加一个 <code>map</code>操作，用于字符串化记录</li>
<li>collect 当为 <code>true</code> 时将在流程末尾添加一个 <code>collect</code> 操作</li>
</ul>
<h5 id="Register"><a href="#Register" class="headerlink" title="Register"></a>Register</h5><p>Register 操作将函数注册为事件处理程序。每次有事件出现时都执行该函数。每次执行时，函数对事件的数据进行操作，完成后将暂停，直到新事件调用它。</p>
<h6 id="Python-API-3"><a href="#Python-API-3" class="headerlink" title="Python API"></a>Python API</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GearsBuilder</span>.<span class="title">register</span>(<span class="params">convertToStr=<span class="literal">True</span>, collect=<span class="literal">True</span>, mode=<span class="string">&#x27;async&#x27;</span>, onRegistered=<span class="literal">None</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>Arguments</p>
<ul>
<li>convertToStr 当为 <code>true</code>时将在流程末尾添加一个 <code>map</code>操作，用于字符串化记录</li>
<li>collect 当为 <code>true</code> 时将在流程末尾添加一个 <code>collect</code> 操作</li>
<li>mode 触发函数的执行方式。可以是：<ul>
<li><code>async</code> 在整个集群中异步执行</li>
<li><code>async_local</code>执行将是异步的，并且仅限于处理分片</li>
<li><code>sync</code>本地同步执行</li>
</ul>
</li>
<li>onRegistered 一个函数回调函数，在每个shard上注册函数时被调用。这是初始化非序列化对象(如网络连接)的好地方。</li>
</ul>
<p><strong>注意，可以将更多参数传递给 register函数，这些参数取决于 reader，详见 Readers 说明。</strong></p>
<h4 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h4><p>函数的执行产生零条或多条结果记录。结果由函数最后一次操作和最后一次操作之前的任何记录组成。</p>
<p>结果存储在函数的执行上下文中。</p>
<h3 id="Readers"><a href="#Readers" class="headerlink" title="Readers"></a>Readers</h3><p>Reader 是任何 RedisGears 函数必须执行的第一步，每个函数都有一个 Reader。Reader 读取数据并从中生成输入记录(Input)。输入记录由函数使用。</p>
<table>
<thead>
<tr>
<th align="left">Reader</th>
<th align="left">Output</th>
<th align="left">Batch</th>
<th align="left">Event</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/readers.html#keysreader">KeysReader</a></td>
<td align="left">Redis keys and values</td>
<td align="left"><strong>Yes</strong></td>
<td align="left"><strong>Yes</strong></td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/readers.html#keysonlyreader">KeysOnlyReader</a></td>
<td align="left">Redis keys</td>
<td align="left"><strong>Yes</strong></td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/readers.html#streamreader">StreamReader</a></td>
<td align="left">Redis Stream messages</td>
<td align="left"><strong>Yes</strong></td>
<td align="left"><strong>Yes</strong></td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/readers.html#pythonreader">PythonReader</a></td>
<td align="left">Arbitrary</td>
<td align="left"><strong>Yes</strong></td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/readers.html#shardsidreader">ShardsIDReader</a></td>
<td align="left">Shard ID</td>
<td align="left"><strong>Yes</strong></td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/readers.html#commandreader">CommandReader</a></td>
<td align="left">Command arguments</td>
<td align="left">No</td>
<td align="left"><strong>Yes</strong></td>
</tr>
</tbody></table>
<h3 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h3><p>操作(Operation)是 RedisGears 函数的构建块。可采用不同的操作类型实现多种结果，满足各种数据处理需求。</p>
<p>操作可以有零个或多个参数来控制其操作。根据操作的类型参数，可以是语言原生数据类型和函数回调。</p>
<table>
<thead>
<tr>
<th align="left">Operation</th>
<th align="left">Description</th>
<th align="left">Type</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#map">Map</a></td>
<td align="left">Maps 1:1</td>
<td align="left">Local</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#flatmap">FlatMap</a></td>
<td align="left">Maps 1:N</td>
<td align="left">Local</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#foreach">ForEach</a></td>
<td align="left">Does something for each record</td>
<td align="left">Local</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#filter">Filter</a></td>
<td align="left">Filters records</td>
<td align="left">Local</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#accumulate">Accumulate</a></td>
<td align="left">Maps N:1</td>
<td align="left">Local</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#localgroupby">LocalGroupBy</a></td>
<td align="left">Groups records by key (many-to-less) <code>extractor</code> + <code>reducer</code></td>
<td align="left">Local</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#limit">Limit</a></td>
<td align="left">Limits the number of records</td>
<td align="left">Local</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#collect">Collect</a></td>
<td align="left">Shuffles all records to one engine</td>
<td align="left">Global</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#repartition">Repartition</a></td>
<td align="left">Shuffles records between all engines</td>
<td align="left">Global</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#groupby">GroupBy</a></td>
<td align="left">Groups records by key (many-to-less) <code>repartition</code>+<code>extractor</code>+<code>reducer</code></td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#batchgroupby">BatchGroupBy</a></td>
<td align="left">Groups records by key (many-to-less)<code>repartition</code>+<code>extractor</code>+<code>batch reducer</code></td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#sort">Sort</a></td>
<td align="left">Sorts records <code>aggregate</code>+<code>local sort</code>+<code>flatmap</code></td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#distinct">Distinct</a></td>
<td align="left">Makes distinct records</td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#aggregate">Aggregate</a></td>
<td align="left">Aggregates records (many-to-one) <code>accumulator</code>+<code>collect</code>+<code>accumulator</code></td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#aggregateby">AggregateBy</a></td>
<td align="left">Aggregates records by key (many-to-less) <code>extractor</code>+<code>reducer</code>+<code>repartition</code>+<code>extractor</code>+<code>reducer</code></td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#count">Count</a></td>
<td align="left">Counts records <code>aggregate</code>(local counting + global suming)</td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#countby">CountBy</a></td>
<td align="left">Counts records by key <code>aggregate</code> (extractor + local counting + global suming)</td>
<td align="left">Sugar</td>
</tr>
<tr>
<td align="left"><a href="https://oss.redislabs.com/redisgears/operations.html#avg">Avg</a></td>
<td align="left">Computes the average <code>aggregate</code>(global sum + global count + local map)</td>
<td align="left">Sugar</td>
</tr>
</tbody></table>
<h4 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h4><h5 id="Local"><a href="#Local" class="headerlink" title="Local"></a>Local</h5><p>本地(Local)操作的执行是在以独立模式或集群模式部署的 RedisGears 引擎中执行的。</p>
<p>当在独立模式下使用时，只有一个引擎在本地执行所有数据上的所有操作。</p>
<p>当再集群模式下使用时，该操作将分布到所有分片。每个分片的引擎也在本地执行操作。然而，分片的引擎只能处理集群对它们进行分区的数据。</p>
<h5 id="Global"><a href="#Global" class="headerlink" title="Global"></a>Global</h5><p>全局(Global)操作只在集群 RedisGears 环境的上下文中相关。这些是收集(collect)和重分区(repartition)操作，用于在分片之间转移记录。</p>
<h5 id="Sugar"><a href="#Sugar" class="headerlink" title="Sugar"></a>Sugar</h5><p>Sugar 操作是实用程序操作。这些是通过基本操作和相关回调在内部实现的。</p>
<h5 id="Callback"><a href="#Callback" class="headerlink" title="Callback"></a>Callback</h5><p>Callback 用于在 API 所使用的语言中调用函数(回调函数)。</p>
<h5 id="Extractor"><a href="#Extractor" class="headerlink" title="Extractor"></a>Extractor</h5><p>Extractor 是一个回调函数，它接收输入记录(record)作为参数。它返回从记录中提取的值(value)。返回值应该是本机字符串(Native String)。</p>
<h5 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h5><p>Mapper 是一个回调函数，它接收输入记录(record)作为参数。它必须返回一个输出记录(record)。</p>
<h5 id="Expander"><a href="#Expander" class="headerlink" title="Expander"></a>Expander</h5><p>Expander 是一个回调函数，它接收输入记录(record)，必须返回一个或多个输出记录(record)。</p>
<h5 id="Processor"><a href="#Processor" class="headerlink" title="Processor"></a>Processor</h5><p>Processor 是一个回调函数，它接收输入记录(record)，它不该返回任何东西。</p>
<h5 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h5><p>Filter 是一个回调函数，它接收输入记录(record)，它必须返回一个布尔值(boolean)。</p>
<h5 id="Accumulator"><a href="#Accumulator" class="headerlink" title="Accumulator"></a>Accumulator</h5><p>Accumulator 是一个回调函数，它接收输入记录和累加器变量。它将输入聚集到累加器变量中，累加器变量存储函数调用之间的状态。函数必须在每次调用后返回累加器的更新值。</p>
<h5 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h5><p>Reducer 是一个回调函数，它接收一个键、一个输入和一个称为累加器的变量。它的执行类似于 Accumulator 回调，不同之处在于它为每个 reduced 的键维护一个累加器。</p>
<h5 id="Batch-Reducer"><a href="#Batch-Reducer" class="headerlink" title="Batch Reducer"></a>Batch Reducer</h5><p>Batch Reducer 是一个回调函数，它接收一个键和一个输入记录列表。它的执行类似于 reducer 回调，不同之处在于它的输入是一个记录列表，而不是单个记录。它将为这些记录返回一个累加器值。</p>
<hr>
<h3 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h3><p>RedisGears 是通过 Redis 客户端发送给服务器的命令来运行的。</p>
<h4 id="Registration-1"><a href="#Registration-1" class="headerlink" title="Registration"></a>Registration</h4><h5 id="RG-DUMPREGISTRATIONS"><a href="#RG-DUMPREGISTRATIONS" class="headerlink" title="RG.DUMPREGISTRATIONS"></a>RG.DUMPREGISTRATIONS</h5><blockquote>
<p>用来输出函数注册列表</p>
</blockquote>
<h5 id="RG-UNREGISTER"><a href="#RG-UNREGISTER" class="headerlink" title="RG.UNREGISTER "></a>RG.UNREGISTER <id></h5><blockquote>
<p>用来取消某个函数的注册。</p>
</blockquote>
<h4 id="EXECUTION"><a href="#EXECUTION" class="headerlink" title="EXECUTION"></a>EXECUTION</h4><h5 id="RG-PYEXECUTE-““-UNBLOCKING-REQUIREMENTS-“-…”"><a href="#RG-PYEXECUTE-““-UNBLOCKING-REQUIREMENTS-“-…”" class="headerlink" title="RG.PYEXECUTE ““ [UNBLOCKING] [REQUIREMENTS “ …”]"></a>RG.PYEXECUTE “<function>“ [UNBLOCKING] [REQUIREMENTS “<dep> …”]</h5><blockquote>
<p>用于执行 Python 函数</p>
</blockquote>
<h5 id="RG-DUMPEXECUTIONS-1"><a href="#RG-DUMPEXECUTIONS-1" class="headerlink" title="RG.DUMPEXECUTIONS"></a>RG.DUMPEXECUTIONS</h5><blockquote>
<p>用于输出函数执行列表。执行列表的长度由 <code>MaxExecutions</code>配置选项限制。</p>
</blockquote>
<h5 id="RG-GETEXECUTION-SHARD-CLUSTER"><a href="#RG-GETEXECUTION-SHARD-CLUSTER" class="headerlink" title="RG.GETEXECUTION  [SHARD|CLUSTER]"></a>RG.GETEXECUTION <id> [SHARD|CLUSTER]</h5><blockquote>
<p>用于获取函数执行细节：执行计划，步骤等</p>
</blockquote>
<h5 id="RG-GETRESULTS-1"><a href="#RG-GETRESULTS-1" class="headerlink" title="RG.GETRESULTS "></a>RG.GETRESULTS <id></h5><blockquote>
<p>用于获取函数的执行结果及错误信息</p>
</blockquote>
<h5 id="RG-GETRESULTSBLOCKING-1"><a href="#RG-GETRESULTSBLOCKING-1" class="headerlink" title="RG.GETRESULTSBLOCKING "></a>RG.GETRESULTSBLOCKING <id></h5><blockquote>
<p>取消函数在后台（UNBLOCKING）执行。取消执行的客户端被阻塞，直到函数执行结束，然后发送任何结果和错误。</p>
</blockquote>
<h5 id="RG-DROPEXECUTION"><a href="#RG-DROPEXECUTION" class="headerlink" title="RG.DROPEXECUTION "></a>RG.DROPEXECUTION <id></h5><blockquote>
<p>用于删除一个函数的执行。</p>
</blockquote>
<h5 id="RG-ABORTEXECUTION"><a href="#RG-ABORTEXECUTION" class="headerlink" title="RG.ABORTEXECUTION "></a>RG.ABORTEXECUTION <id></h5><blockquote>
<p>在运行过程中中止函数的执行。</p>
</blockquote>
<h4 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h4><h5 id="RG-TRIGGER-arg-…"><a href="#RG-TRIGGER-arg-…" class="headerlink" title="RG.TRIGGER  [arg …]"></a>RG.TRIGGER <trigger> [arg …]</h5><blockquote>
<p>用来触发已注册的 CommandReader 函数的执行。</p>
</blockquote>
<h4 id="Global-1"><a href="#Global-1" class="headerlink" title="Global"></a>Global</h4><h5 id="RG-CONFIGGET-…"><a href="#RG-CONFIGGET-…" class="headerlink" title="RG.CONFIGGET  […]"></a>RG.CONFIGGET <key> […]</h5><blockquote>
<p>返回一个或多个内置配置或用户定义选项的值。</p>
</blockquote>
<h5 id="RG-CONFIGSET-…"><a href="#RG-CONFIGSET-…" class="headerlink" title="RG.CONFIGSET   […]"></a>RG.CONFIGSET <key> <value> […]</h5><blockquote>
<p>设置一个或多个内置配置或用户定义选项的值。</p>
</blockquote>
<h5 id="RG-PYSTATS"><a href="#RG-PYSTATS" class="headerlink" title="RG.PYSTATS"></a>RG.PYSTATS</h5><blockquote>
<p>从 Python 解释器返回内存使用统计信息。</p>
</blockquote>
<h5 id="RG-PYDUMPREQS-version-1-0-1"><a href="#RG-PYDUMPREQS-version-1-0-1" class="headerlink" title="RG.PYDUMPREQS (version 1.0.1)"></a>RG.PYDUMPREQS (version 1.0.1)</h5><blockquote>
<p>返回所有可用 Python 依赖的列表(包含关于每个依赖的信息)。</p>
</blockquote>
<h5 id="RG-INFOCLUSTER"><a href="#RG-INFOCLUSTER" class="headerlink" title="RG.INFOCLUSTER"></a>RG.INFOCLUSTER</h5><blockquote>
<p>显示集群信息。</p>
</blockquote>
<h5 id="RG-REFRESHCLUSTER"><a href="#RG-REFRESHCLUSTER" class="headerlink" title="RG.REFRESHCLUSTER"></a>RG.REFRESHCLUSTER</h5><blockquote>
<p>刷新节点的集群拓扑视图。<strong>需要在集群的每个节点执行</strong></p>
</blockquote>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><p>RedisGears 提供了配置选项来控制它的操作。这些选项可以在模块启动时设置，在某些情况下也可以在运行时设置。</p>
<p><strong>Bootstrap Configuration</strong> 在加载 Redis Module 时配置，<strong>Runtime Configuration</strong> 在运行时配置（详见命令：<code>RG.CONFIGSET &lt;key&gt; &lt;value&gt; [...]</code> 、<code>RG.CONFIGGET &lt;key&gt; [...]</code>）。</p>
<table>
<thead>
<tr>
<th>配置项</th>
<th>说明</th>
<th>期望值</th>
<th>默认值</th>
<th>运行时可配置性</th>
</tr>
</thead>
<tbody><tr>
<td>MaxExecutions</td>
<td>MaxExecutions 配置选项控制将保存在执行列表中的最大执行次数。<br />一旦达到这个阈值，就会按照创建顺序(FIFO)从列表中删除旧的执行。<br />只有已经完成的执行(例如“完成”或“中止”状态)被删除。</td>
<td>Integer</td>
<td>1000</td>
<td>Supported</td>
</tr>
<tr>
<td>MaxExecutionsPerRegistration</td>
<td>MaxExecutionsPerRegistration 配置选项控制每个注册保存在列表中的最大执行次数。<br />一旦达到这个阈值，该注册的旧执行将按创建顺序(FIFO)从列表中删除。<br />只有已经完成的执行(例如“完成”或“中止”状态)被删除。</td>
<td>Integer</td>
<td>100</td>
<td>Supported</td>
</tr>
<tr>
<td>ProfileExecutions</td>
<td>ProfileExecutions 配置选项控制是否对执行进行分析。对性能损耗较大，建议用于调试操作。</td>
<td>0 (disabled)<br />1 (enabled)</td>
<td>0</td>
<td>Supported</td>
</tr>
<tr>
<td>PythonAttemptTraceback</td>
<td>PythonAttemptTraceback 配置选项控制引擎是否试图为 Python 运行时错误产生堆栈跟踪。</td>
<td>0 (disabled)<br />1 (enabled)</td>
<td>1</td>
<td>Supported</td>
</tr>
<tr>
<td>DownloadDeps</td>
<td>DownloadDeps 配置选项控制 RedisGears 是否会尝试下载缺少的 Python 依赖项。</td>
<td>0 (disabled)<br />1 (enabled)</td>
<td>1</td>
<td>Not Supported</td>
</tr>
<tr>
<td>DependenciesUrl</td>
<td>DependenciesUrl 配置选项控制 RedisGears 试图从何处下载其 Python 依赖项。</td>
<td>URL-like string</td>
<td>与RedisGears版本有关</td>
<td>Not Supported</td>
</tr>
<tr>
<td>DependenciesSha256</td>
<td>DependenciesSha256 配置选项指定 Python 依赖项的 SHA256 哈希值。<br />在下载依赖项之后，将验证此值，如果不匹配，将停止服务器的启动。</td>
<td>String</td>
<td>与RedisGears版本有关</td>
<td>Not Supported</td>
</tr>
<tr>
<td>PythonInstallationDir</td>
<td>PythonInstallationDir 配置选项指定了 RedisGears 的 Python 依赖项的路径。</td>
<td>String</td>
<td>/var/opt/redislabs/modules/rg</td>
<td>Not Supported</td>
</tr>
<tr>
<td>CreateVenv</td>
<td>CreateVenv 配置选项控制引擎是否创建虚拟 Python 环境。</td>
<td>0 (disabled)<br />1 (enabled)</td>
<td>0</td>
<td>Not Supported</td>
</tr>
<tr>
<td>ExecutionThreads</td>
<td>ExecutionThreads 配置选项控制将要执行的线程数。</td>
<td>Integer &gt; 0</td>
<td>3</td>
<td>Not Supported</td>
</tr>
<tr>
<td>ExecutionMaxIdleTime</td>
<td>ExecutionMaxIdleTime 配置选项控制中止执行之前的最大空闲时间(以毫秒为单位)。空闲时间意味着执行没有进展。空闲时间的主要原因是在等待来自另一个失败(即崩溃)碎片的记录时被阻塞的执行。在这种情况下，执行将在指定的时间限制后中止。当执行再次开始进行时，将重置空闲计时器。</td>
<td>Integer &gt; 0</td>
<td>5 seconds</td>
<td>Supported</td>
</tr>
<tr>
<td>PythonInstallReqMaxIdleTime<br /><strong>1.0.1</strong></td>
<td>PythonInstallReqMaxIdleTime 配置选项控制 Python 依赖安装中止之前的最大空闲时间(以毫秒为单位)。“空闲时间”表示安装没有进展。空闲时间的主要原因与ExecutionMaxIdleTime 相同。</td>
<td>Integer &gt; 0</td>
<td>30000</td>
<td>Supported</td>
</tr>
<tr>
<td>SendMsgRetries<br /><strong>1.0.1</strong></td>
<td>SendMsgRetries 配置选项控制在 RedisGears 的分片之间发送消息的最大重试次数。当消息被发送，而 shard 在确认之前断开连接，或者当它返回一个错误时，该消息将被重新发送，直到达到这个阈值。设置为0表示不限制重试次数。</td>
<td>Integer &gt;= 0</td>
<td>3</td>
<td>Supported</td>
</tr>
</tbody></table>
<h2 id="Examples-2"><a href="#Examples-2" class="headerlink" title="Examples"></a>Examples</h2><p>RedisGears Examples: <a href="https://oss.redislabs.com/redisgears/examples.html">https://oss.redislabs.com/redisgears/examples.html</a></p>
<h2 id="Clients"><a href="#Clients" class="headerlink" title="Clients"></a>Clients</h2><p>RedisGears 是一个 Redis 模块，所以需要 Redis 客户端来操作它。任何支持发送原始 Redis 命令的客户端都可以使用。</p>
<p>Redis Clients: <a href="https://redis.io/clients">https://redis.io/clients</a></p>
<p>RedisGears-specific clients: <a href="https://github.com/RedisGears/redisgears-py">https://github.com/RedisGears/redisgears-py</a></p>
<h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><h3 id="Isolation-Technics-隔离技术"><a href="#Isolation-Technics-隔离技术" class="headerlink" title="Isolation Technics - 隔离技术"></a>Isolation Technics - 隔离技术</h3><h4 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h4><ul>
<li>全局字典(当前版本支持)</li>
<li>子解释器(当前版本出现不兼容某些库而未启用，后续版本提供开关支持</li>
</ul>
<h2 id="Samples"><a href="#Samples" class="headerlink" title="Samples"></a>Samples</h2><h3 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h3><h4 id="RedisGears-Cluster-1"><a href="#RedisGears-Cluster-1" class="headerlink" title="RedisGears Cluster"></a>RedisGears Cluster</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## RedisGears Cluster</span><br><span class="line"># docker run -p 30001:30001 -p 30002:30002 -p 30003:30003 --name rgc redislabs&#x2F;rgcluster:latest</span><br><span class="line">docker run -p 30001:30001 -p 30002:30002 -p 30003:30003 --name rgc redislabs&#x2F;rgcluster:1.2.1</span><br></pre></td></tr></table></figure>


<h4 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## mysql </span><br><span class="line">docker run --name rgmysql -e MYSQL_ROOT_PASSWORD&#x3D;root -p 3306:3306 -d mysql:8.0</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># root</span><br><span class="line">mysql -p </span><br><span class="line"># Enter password: &#96;root&#96;</span><br><span class="line"></span><br><span class="line"># show databases;</span><br><span class="line"># DROP USER &#39;rguser&#39;@&#39;%&#39;;</span><br><span class="line"></span><br><span class="line">create database rgdb;</span><br><span class="line">create user &#39;rguser&#39;@&#39;%&#39; identified by &#39;rguser&#39;;</span><br><span class="line"></span><br><span class="line"># mysql 8.0 syntax</span><br><span class="line">grant all privileges on rgdb.* TO &#39;rguser&#39;@&#39;%&#39;;</span><br><span class="line">flush privileges;</span><br><span class="line">exit;</span><br><span class="line"></span><br><span class="line">mysql -u rguser -p;</span><br><span class="line">use rgdb;</span><br><span class="line">CREATE TABLE IF NOT EXISTS &#96;person&#96;(</span><br><span class="line">   &#96;id&#96; VARCHAR(100),</span><br><span class="line">   &#96;first&#96; VARCHAR(100),</span><br><span class="line">   &#96;last&#96; VARCHAR(40),</span><br><span class="line">   &#96;age&#96; INT,</span><br><span class="line">   PRIMARY KEY ( &#96;id&#96; )</span><br><span class="line">)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;</span><br><span class="line">describe person;</span><br></pre></td></tr></table></figure>
<h4 id="Monitor-UI"><a href="#Monitor-UI" class="headerlink" title="Monitor UI"></a>Monitor UI</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Monitor UI</span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;RedisGears&#x2F;RedisGearsMonitor.git</span><br><span class="line">cd RedisGearsMonitor</span><br><span class="line"></span><br><span class="line">npm install</span><br><span class="line">node main.js --port 30001</span><br><span class="line"></span><br><span class="line"># http:&#x2F;&#x2F;localhost:9001&#x2F;</span><br></pre></td></tr></table></figure>


<h4 id="Run-Recipe"><a href="#Run-Recipe" class="headerlink" title="Run Recipe"></a>Run Recipe</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## run recipe</span><br><span class="line"># pip3 install gears-cli</span><br><span class="line"># gears-cli --host &lt;host&gt; --port &lt;post&gt; --password &lt;password&gt; run example.py REQUIREMENTS rgsync PyMySQL cryptography</span><br><span class="line"># gears-cli run --host localhost --port 30001 example.py REQUIREMENTS rgsync PyMySQL cryptography</span><br><span class="line"></span><br><span class="line">gears-cli run --host localhost --port 30001 example.py REQUIREMENTS git+https:&#x2F;&#x2F;gitlab.com&#x2F;shankai&#x2F;rgsync.git  PyMySQL cryptography</span><br><span class="line"></span><br><span class="line"># 这条是异常信息： failed running gear function (Failed install requirement on shard, check shard log for more info.)</span><br><span class="line"># OK 代表发布成功。</span><br><span class="line"># gears-cli run 之后，redisgears cluster 会动态加载相关模块。</span><br><span class="line"># Monitor UI 会显示 PersonsWriteBehind Registrations 相关状态信息。</span><br></pre></td></tr></table></figure>
<h5 id="example-py-WriteBehind-RGWriteThrough"><a href="#example-py-WriteBehind-RGWriteThrough" class="headerlink" title="example.py  (WriteBehind + RGWriteThrough)"></a>example.py  (WriteBehind + RGWriteThrough)</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> rgsync <span class="keyword">import</span> RGWriteBehind, RGWriteThrough</span><br><span class="line"><span class="keyword">from</span> rgsync.Connectors <span class="keyword">import</span> MySqlConnector, MySqlConnection</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Create MySQL connection object</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># connection = MySqlConnection(&#x27;demouser&#x27;, &#x27;Password123!&#x27;, &#x27;localhost:3306/test&#x27;)</span></span><br><span class="line">connection = MySqlConnection(<span class="string">&#x27;rguser&#x27;</span>, <span class="string">&#x27;rguser&#x27;</span>, <span class="string">&#x27;localhost:3306/rgdb&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Create MySQL persons connector</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">personsConnector = MySqlConnector(connection, <span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;id&#x27;</span>)</span><br><span class="line"></span><br><span class="line">personsMappings = &#123;</span><br><span class="line">	<span class="string">&#x27;first_name&#x27;</span>:<span class="string">&#x27;first&#x27;</span>,</span><br><span class="line">	<span class="string">&#x27;last_name&#x27;</span>:<span class="string">&#x27;last&#x27;</span>,</span><br><span class="line">	<span class="string">&#x27;age&#x27;</span>:<span class="string">&#x27;age&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">RGWriteBehind(GB,  keysPrefix=<span class="string">&#x27;person&#x27;</span>, mappings=personsMappings, connector=personsConnector, name=<span class="string">&#x27;PersonsWriteBehind&#x27;</span>,  version=<span class="string">&#x27;99.99.99&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># RGWriteThrough(GB, keysPrefix=&#x27;__&#x27;, mappings=personsMappings, connector=personsConnector, name=&#x27;PersonsWriteThrough&#x27;, version=&#x27;99.99.99&#x27;)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="演示操作"><a href="#演示操作" class="headerlink" title="演示操作"></a>演示操作</h3><h4 id="WriteBehind"><a href="#WriteBehind" class="headerlink" title="WriteBehind"></a>WriteBehind</h4><h5 id="hmset-不同操作完成后，在-mysql-rgdb-person-表中查看数据同步结果"><a href="#hmset-不同操作完成后，在-mysql-rgdb-person-表中查看数据同步结果" class="headerlink" title="hmset (不同操作完成后，在 mysql rgdb.person 表中查看数据同步结果)"></a><code>hmset</code> (不同操作完成后，在 mysql rgdb.person 表中查看数据同步结果)</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hmset person:1 first_name zhang last_name san age 21</span><br><span class="line">hmset person:2 first_name li last_name sisi age 18</span><br><span class="line"></span><br><span class="line">hmset person:10 first_name li last_name sisi age 18</span><br><span class="line"></span><br><span class="line">## 复制控制</span><br><span class="line"></span><br><span class="line">## 变更并同步(默认行为)</span><br><span class="line">hmset person:3 first_name li last_name sisi age 22 # &#x3D;</span><br><span class="line"></span><br><span class="line">## 变更不同步</span><br><span class="line">hmset person:3 first_name li last_name sisi age 50 # +</span><br><span class="line"># HGETALL person:3</span><br><span class="line"></span><br><span class="line">## 删除并同步</span><br><span class="line">hmset person:3 # ~</span><br><span class="line"></span><br><span class="line">hmset person:3 first_name li last_name sisi age 22 # &#x3D;</span><br><span class="line">## 删除不同步</span><br><span class="line">hmset person:3 # -</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h5 id="正好一次（源码有缺陷，mysql-connector-修复见-https-gitlab-com-shankai-rgsync）"><a href="#正好一次（源码有缺陷，mysql-connector-修复见-https-gitlab-com-shankai-rgsync）" class="headerlink" title="正好一次（源码有缺陷，mysql connector 修复见 https://gitlab.com/shankai/rgsync）"></a>正好一次（源码有缺陷，<code>mysql connector</code> 修复见 <code>https://gitlab.com/shankai/rgsync</code>）</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS &#96;exactlyonce&#96;(</span><br><span class="line">   &#96;id&#96; VARCHAR(100),</span><br><span class="line">   &#96;val&#96; VARCHAR(100),</span><br><span class="line">   PRIMARY KEY ( &#96;id&#96; )</span><br><span class="line">)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;</span><br><span class="line">describe exactlyonce;</span><br></pre></td></tr></table></figure>
<p><code>example.py</code> 文件内修改 personsConnector 实例化，添加 <code>exactlyOnceTableName</code> 参数值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">personsConnector &#x3D; MySqlConnector(connection, &#39;person&#39;, &#39;id&#39;, &#39;exactlyonce&#39;)</span><br></pre></td></tr></table></figure>


<h5 id="ACK"><a href="#ACK" class="headerlink" title="ACK"></a>ACK</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># </span><br><span class="line">hset person:007 first_name James last_name Bond age 43 # &#x3D;6ce0c902-30c2-4ac9-8342-2f04fb359a944412</span><br><span class="line"># XREAD BLOCK &lt;timeout&gt; STREAMS &#123;&lt;hash key&gt;&#125;&lt;uuid&gt; 0-0</span><br><span class="line">XREAD BLOCK 2000 STREAMS &#123;person:007&#125;6ce0c902-30c2-4ac9-8342-2f04fb359a944412 0-0</span><br></pre></td></tr></table></figure>


<h4 id="WriteThrough"><a href="#WriteThrough" class="headerlink" title="WriteThrough"></a>WriteThrough</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HSET __&#123;person:1&#125; first_name foo last_name bar age 20 # &#x3D;123456</span><br><span class="line"></span><br><span class="line">XREAD BLOCK 2000 STREAMS &#123;person:104&#125;123456 0-0</span><br></pre></td></tr></table></figure>
<p>(完)</p>
]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
        <tag>Python</tag>
        <tag>Stream</tag>
        <tag>Sync</tag>
        <tag>Recipe</tag>
        <tag>Redis Module</tag>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2021/04/30/golang-notes/</url>
    <content><![CDATA[<p>环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go env</span><br></pre></td></tr></table></figure>


<p>编译</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go build</span><br></pre></td></tr></table></figure>
<p>如果我们要生成不同平台架构的可执行程序，只要改变这两个环境变量就可以了，比如要生成Linux 64位的程序，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CGO_ENABLED&#x3D;0 GOOS&#x3D;linux GOARCH&#x3D;amd64 go build -o fence-benchmark</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>ChirpStack 笔记</title>
    <url>/2021/05/25/iot-chirpstack-notes/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="https://www.chirpstack.io/">https://www.chirpstack.io/</a></p>
<p>LoRaWAN®是一种低功耗、广域(LPWA)网络协议，设计用于在区域、国家或全球网络中将电池操作的“事物”无线连接到互联网，并针对物联网的关键需求，如双向通信、端到端安全性、移动性和本地化服务。</p>
<p>ChirpStack 为 LoRaWAN 网络提供开源组件。它们一起形成了一个现成的解决方案，包括用于设备管理的用户友好的 WEB 界面和用于集成的 API。模块化的体系结构使得在现有的基础设施中集成成为可能。所有组件都在MIT许可下许可，并可用于商业目的。提供了以下组件:</p>
<ul>
<li>ChirpStack网关桥：处理与 LoRaWAN 网关的通信。</li>
<li>ChirpStack网络服务器：一个 LoRaWAN 网络服务器的实现。</li>
<li>ChirpStack应用服务器：一个 LoRaWAN 应用服务器的实现。</li>
<li>ChirpStack Gateway OS：在基于树莓派(<em>Raspberry Pi</em>)的 LoRa 网关上运行(完整) ChirpStack栈的 Linux 操作系统。</li>
</ul>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="https://www.chirpstack.io/static/img/graphs/architecture.dot.png" alt="architecture"></p>
<h3 id="LoRaWAN-设备"><a href="#LoRaWAN-设备" class="headerlink" title="LoRaWAN 设备"></a>LoRaWAN 设备</h3><p>LoRaWAN设备(上图中未显示)是通过一个或多个 LoRa 网关向 ChirpStack 网络服务器发送数据的设备。例如，这些设备可以是测量空气质量、温度、湿度、位置的传感器…</p>
<h3 id="LoRa®网关"><a href="#LoRa®网关" class="headerlink" title="LoRa®网关"></a>LoRa®网关</h3><p>一个 LoRa 网关(通常)同时侦听 8 个或更多的通道，并将接收到的数据(从设备)转发到一个 LoRaWAN 网络服务器(在本例中是 ChirpStack 网络服务器)。运行在 LoRa 网关上负责接收和发送的软件称为包转发器(Packet Forwarder)。常见的实现是 <a href="https://github.com/Lora-net/packet_forwarder/">Semtech UDP Packet Forwarder</a> 和 <a href="https://doc.sm.tc/station/">Semtech Basic Station Packet Forwarder</a>.。</p>
<h3 id="ChirpStack-网关桥"><a href="#ChirpStack-网关桥" class="headerlink" title="ChirpStack 网关桥"></a>ChirpStack 网关桥</h3><p>ChirpStack 网关桥接器位于数据包转发器和 MQTT 代理之间。它将数据包转发器格式(如Semtech UDP数据包转发器协议)转换为数据格式，由 ChirpStack 组件使用。它还提供与各种云平台的集成，如 GCP 云物联网核心和 Azure 物联网枢纽。</p>
<h3 id="ChirpStack-网络服务器"><a href="#ChirpStack-网络服务器" class="headerlink" title="ChirpStack 网络服务器"></a>ChirpStack 网络服务器</h3><p>ChirpStack 网络服务器是一个 LoRaWAN 网络服务器，负责管理网络状态。它具有网络上设备激活的知识，并能够在设备想要加入网络时处理连接请求。</p>
<p>当数据被多个网关接收时，ChirpStack 网络服务器将删除这些重复数据，并将其作为一个有效负载转发到 ChirpStack 应用服务器。</p>
<p>当应用服务器需要将数据发送回设备时，ChirpStack 网络服务器将把这些项目保存在队列中，直到它能够发送到其中一个网关。</p>
<h3 id="ChirpStack应用服务器"><a href="#ChirpStack应用服务器" class="headerlink" title="ChirpStack应用服务器"></a>ChirpStack应用服务器</h3><p>ChirpStack 应用服务器是 LoRaWAN 应用服务器，与 ChirpStack 网络服务器兼容。它提供了一个 WEB 界面和 API，用于管理用户、组织、应用、网关和设备。</p>
<p>接收到的上行数据被转发到一个或多个已配置的集成。</p>
<h3 id="终端应用"><a href="#终端应用" class="headerlink" title="终端应用"></a>终端应用</h3><p>终端应用程序通过一个已配置的集成接收设备数据。它可以使用 ChirpStack 应用服务器 API 来调度设备的下行有效负载。终端应用程序的目的可能是分析、警报、数据可视化、触发操作……</p>
<h2 id="ChirpStack-Application-Server"><a href="#ChirpStack-Application-Server" class="headerlink" title="ChirpStack Application Server"></a>ChirpStack Application Server</h2><p>ChirpStack Application Server是一个开源的LoRaWAN®应用服务器，是 ChirpStack 开源 LoRaWAN 网络服务器堆栈的一部分。它负责 LoRaWAN 基础设施的设备“库存”部分，处理连接请求和应用程序有效负载的处理和加密。 </p>
<p>它提供了一个可以管理用户、组织、应用程序和设备的网络界面。为了与外部服务集成，它提供了 gRPC 和 RESTful API。</p>
<p>发送 和/或 接收的设备数据可以通过 MQTT、HTTP 或直接写入到 InfluxDB。</p>
<h3 id="有效载荷加密-解密"><a href="#有效载荷加密-解密" class="headerlink" title="有效载荷加密/解密"></a>有效载荷加密/解密</h3><p>ChirpStack Application Server 处理应用程序有效负载的加密和解密。它还保存每个设备的应用程序键，并在 OTAA 激活时处理 join-accept。这意味着有效载荷将被解密发送到集成，但在有效载荷被发送到 ChirpStack 网络服务器之前，网络服务器无法访问这些有效载荷。</p>
<h3 id="Web-界面"><a href="#Web-界面" class="headerlink" title="Web 界面"></a>Web 界面</h3><p>ChirpStack Application Server 提供了一个 Web 界面 (构建在提供的 RESTful API 之上)。这个 Web 界面可以用来管理用户、组织、应用程序和设备。</p>
<h3 id="用户授权"><a href="#用户授权" class="headerlink" title="用户授权"></a>用户授权</h3><p>使用 ChirpStack Application Server，可以授予用户全局的管理员权限，使他们成为组织的管理员，或者为他们分配组织内的仅查看权限。这使得在多租户环境中运行 ChirpStack Application Server 成为可能，在这种环境中，每个组织或团队只能访问他们自己的应用程序和设备。</p>
<h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>为了与外部服务集成，ChirpStack Application Server 提供了gRPC 和 RESTFul API，公开了与 Web 界面相同的功能。</p>
<h3 id="有效载荷和设备事件"><a href="#有效载荷和设备事件" class="headerlink" title="有效载荷和设备事件"></a>有效载荷和设备事件</h3><p>ChirpStack Application Server 提供了不同的方式发送和接收设备负载(例如MQTT, HTTP, InfluxDB，…)。</p>
<p>注意:下行负载也可以通过API进行调度。</p>
<h3 id="网关发现"><a href="#网关发现" class="headerlink" title="网关发现"></a>网关发现</h3><p>对于包含多个网关的网络，ChirpStack Application Server 提供了一个特性来测试网关的网络覆盖。通过向每个网关定期发送 “ping”，ChirpStack 应用服务器能够发现这些 ping 被同一网络中的其他网关接收的情况。采集到的数据以地图的形式显示在 Web 界面上。可以为每个 Network Server 启用和配置此功能。</p>
<h3 id="活动的帧日志-frame-logging"><a href="#活动的帧日志-frame-logging" class="headerlink" title="活动的帧日志(frame-logging)"></a>活动的帧日志(frame-logging)</h3><p>使用 ChirpStack Application Server，可以检查每个网关或设备的所有原始和加密的 LoRaWAN 帧。当打开网关或设备详细信息页面上的 LoRaWAN 帧标签时，将看到实时的所有帧。这也将允许您检查每个 LoRaWAN 帧的(加密)内容。</p>
<h3 id="活动的事件日志-event-logging"><a href="#活动的事件日志-event-logging" class="headerlink" title="活动的事件日志(event-logging)"></a>活动的事件日志(event-logging)</h3><p>使用 ChirpStack Application Server，可以从 Web 界面检查所有事件，而不需要使用 MQTT 客户端或构建集成。当打开实时事件日志标签上的设备详情，将看到所有实时 uplink，ack，join 和 error 事件。</p>
<h2 id="Startup"><a href="#Startup" class="headerlink" title="Startup"></a>Startup</h2><h3 id="certs-optional"><a href="#certs-optional" class="headerlink" title="certs (optional)"></a>certs (optional)</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf certs&#x2F;ca</span><br><span class="line">mkdir -p certs&#x2F;ca</span><br><span class="line">cfssl gencert -initca config&#x2F;ca-csr.json | cfssljson -bare certs&#x2F;ca&#x2F;ca</span><br><span class="line"></span><br><span class="line">mkdir -p certs&#x2F;mqtt&#x2F;server</span><br><span class="line">cfssl gencert -ca certs&#x2F;ca&#x2F;ca.pem -ca-key certs&#x2F;ca&#x2F;ca-key.pem -config config&#x2F;ca-config.json -profile server config&#x2F;mqtt&#x2F;server&#x2F;certificate.json | cfssljson -bare certs&#x2F;mqtt&#x2F;server&#x2F;mqtt-server</span><br><span class="line"></span><br><span class="line">cp certs&#x2F;ca&#x2F;* ~&#x2F;codebase&#x2F;oss&#x2F;chirpstack&#x2F;mqtt&#x2F;specs&#x2F;</span><br><span class="line">cp certs&#x2F;mqtt&#x2F;server&#x2F;* ~&#x2F;codebase&#x2F;oss&#x2F;chirpstack&#x2F;mqtt&#x2F;specs&#x2F;</span><br></pre></td></tr></table></figure>
<h3 id="mosquitto"><a href="#mosquitto" class="headerlink" title="mosquitto"></a>mosquitto</h3><p><a href="https://mosquitto.org/">https://mosquitto.org/</a></p>
<blockquote>
<p>mosquitto mqtt-broker</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -it -p 11883:1883 -p 19001:9001 -v ./oss/chirpstack/mqtt/mosquitto.conf:/mosquitto/config/mosquitto.conf -v ./oss/chirpstack/mqtt/specs:/usr/local/certs --name mqtt-broker eclipse-mosquitto</span><br><span class="line"></span><br><span class="line">docker exec -it mqtt-broker sh</span><br><span class="line"></span><br><span class="line">mosquitto_sub -d -v -h mqtt-broker -p 11883 -t test --cafile /usr/local/certs/ca.pem</span><br><span class="line">mosquitto_pub -d -h mqtt-broker -p 11883 -t test -m hellomqtt --cafile /usr/local/certs/ca.pem</span><br></pre></td></tr></table></figure>
<h3 id="chirpstack-docker"><a href="#chirpstack-docker" class="headerlink" title="chirpstack-docker"></a>chirpstack-docker</h3><p><a href="https://github.com/brocaar/chirpstack-docker">https://github.com/brocaar/chirpstack-docker</a></p>
<blockquote>
<p>docker-compose.yml</p>
<p>chirpstack-application-server.toml</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd chirpstack-docker</span><br><span class="line"></span><br><span class="line">docker-compose up</span><br><span class="line">docker-compose rm</span><br></pre></td></tr></table></figure>
<h3 id="chirpstack-simulator"><a href="#chirpstack-simulator" class="headerlink" title="chirpstack-simulator"></a>chirpstack-simulator</h3><h4 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;brocaar&#x2F;chirpstack-simulator</span><br></pre></td></tr></table></figure>
<h4 id="Build"><a href="#Build" class="headerlink" title="Build"></a>Build</h4><p>解决 proxy.golang.org 无法访问</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go env -w GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.cn</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go build -a -installsuffix cgo -ldflags &quot;-s -w -X main.version&#x3D;37a7e02&quot; -o build&#x2F;chirpstack-simulator cmd&#x2F;chirpstack-simulator&#x2F;main.go</span><br></pre></td></tr></table></figure>
<h4 id="Startup-1"><a href="#Startup-1" class="headerlink" title="Startup"></a>Startup</h4><p><code>chirpstack-simulator.toml</code> (修改配置文件，用于自动创建设备及模拟设备感知数据)</p>
<ul>
<li>jwt_token (Application Server API Keys)</li>
<li>service_profile_id (Application Server Service Profile)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;build&#x2F;chirpstack-simulator -c chirpstack-simulator.toml</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>MQTT</tag>
        <tag>LoRa</tag>
        <tag>LoRaWAN</tag>
        <tag>Iot</tag>
        <tag>Network Server</tag>
        <tag>Application Server</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2021/05/19/pmp-notes/</url>
    <content><![CDATA[<p>SPEMF</p>
<ul>
<li>START</li>
<li>PLAN</li>
<li>EXECUTE</li>
<li>MONITOR</li>
<li>FINISH</li>
</ul>
<h2 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h2><h3 id="S制定项目章程"><a href="#S制定项目章程" class="headerlink" title="S制定项目章程"></a>S制定项目章程</h3><h3 id="P制定项目管理计划"><a href="#P制定项目管理计划" class="headerlink" title="P制定项目管理计划"></a>P制定项目管理计划</h3><ul>
<li>子计划：9+1(需求)</li>
<li>基准: 范围、进度、成本</li>
<li>其他：变更管理、配置管理、绩效测量、生命周期、开发方法、管理审查</li>
</ul>
<p>![image-20210519101409876](/Users/shankai/Library/Application Support/typora-user-images/image-20210519101409876.png)</p>
<h3 id="E指导与管理项目工作"><a href="#E指导与管理项目工作" class="headerlink" title="E指导与管理项目工作"></a>E指导与管理项目工作</h3><h3 id="E管理项目知识"><a href="#E管理项目知识" class="headerlink" title="E管理项目知识"></a>E管理项目知识</h3><h2 id="范围"><a href="#范围" class="headerlink" title="范围"></a>范围</h2><p>范围基准</p>
<ul>
<li><p>项目范围说明书</p>
</li>
<li><p>WBS</p>
</li>
<li><p>WBS 词典</p>
</li>
<li><p>工作包</p>
</li>
<li><p>规划包</p>
</li>
</ul>
<p>收集需求</p>
<ul>
<li>需求文件</li>
<li>需求跟踪矩阵</li>
</ul>
<blockquote>
<p>需求跟踪矩阵</p>
</blockquote>
<p>需求跟踪矩阵提供了在整个项目生命周期中跟踪需求的一种方法，有助于确保需求文件中被批准的每项需求在项目结束的时候都能交付。应在需求跟踪矩阵中记录每个需求的相关属性，这些属性有助于明确每个需求的关键信息。为确保相关方满意，可能需要增加一些补充属性，如稳定性、复杂性和验收标准。</p>
<h2 id="进度"><a href="#进度" class="headerlink" title="进度"></a>进度</h2><p>进度压缩</p>
<ul>
<li>快速跟进（返工风险）</li>
<li>赶工（增加成本，改变关键路径）</li>
</ul>
<p>==<strong>进度基准？</strong>==</p>
<blockquote>
<p>RAM责任分配矩阵(Responsibility Assignment Matrix) </p>
</blockquote>
<p><strong>责任分配矩阵</strong>是用来对<a href="https://wiki.mbalib.com/wiki/%E9%A1%B9%E7%9B%AE%E5%9B%A2%E9%98%9F">项目团队</a>成员进行分工，明确其角色与职责的有效工具，通过这样的关系矩阵，项目团队每个成员的角色，也就是谁做什么，以及他们的职责，也就是谁决定什么，得到了直观地反映。项目的每个具体任务都能落实到参与项目的团队成员身上，确保了项目的事有人做，人有事干。</p>
<blockquote>
<p>RACI </p>
</blockquote>
<p>RAM显示每个工作包分配了哪些资源;</p>
<p>RACI 可以直接查某个资源承担了哪些工作(活动)，RACI更具体和清晰，便于团队成员可以了解自己承担的工作职责。</p>
<h3 id="排列活动顺序"><a href="#排列活动顺序" class="headerlink" title="排列活动顺序"></a>排列活动顺序</h3><p>确定和整合依赖关系</p>
<ul>
<li>强制性：法律或合同要求的</li>
<li>选择性：基于应用领域的最佳实践或某些特性</li>
<li>外部的：项目活动与非项目活动之间的依赖，这些依赖不在项目控制范围内</li>
<li>内部的：项目活动之间的紧前关系</li>
</ul>
<blockquote>
<p>资源平衡</p>
</blockquote>
<p>为了在资源需求与资源供给之间取得平衡，根据资源制约因素对开始日期和完成日期进行调整的一种技术。如果共享资源或关键资源只在特定时间可用，数量有限，或被过度分配，或为保持资源使用量处于均衡水平，就需要进行资源平衡。</p>
<h2 id="采购"><a href="#采购" class="headerlink" title="采购"></a>采购</h2><h3 id="合同类型"><a href="#合同类型" class="headerlink" title="合同类型"></a>合同类型</h3><ul>
<li>固定总价（FP）（明确定义需求，且不会出现重大范围变更的情况下使用）<ul>
<li>固定总价（FFP）（利好买方，风险在卖方）签订周期较长（核实范围），实施周期较短</li>
<li>总价+激励费用（FPIF）（完成目标给与奖励，有天花板，高于后由卖方承担）</li>
<li>总价+经济价格调整（FPEPA）（卖方履约时间紧，或受汇率影响较大的情况）</li>
</ul>
</li>
<li>工料（T&amp;M）：在无法快速编制出准确的工作说明书下扩充人员、聘请专家或寻求外部支持时。工料合同与固定单价合同相似。</li>
<li>成本补偿（CR）（工作范围预计会在合同执行期间发生重大变更，或项目存在较高风险时使用）<ul>
<li>固定费用（CPFF）为卖方履行合同发生的一切可列支成本，并向卖方支付一笔固定费用。</li>
<li>激励费用（CPIF）为卖方履行合同发生的一切可列支成本，并在卖方达到合同规定绩效时，支付预先确定的激励费用（无天花板）。买卖双方按预先商定的分摊比例分享利润或分担超支。</li>
<li>奖励费用（CPAF）为卖方报销一切合法成本，仅在卖方满足买方主观绩效标准下，支付大部分费用。不允许申诉。</li>
</ul>
</li>
</ul>
<blockquote>
<p>预期货币值(EMV) </p>
</blockquote>
<p>预期货币值，又称风险暴露值、风险期望值，是定量风险分析的一种技术，英文名为：ExpectedMonetaryValue，因此在计算使用中，通常用EMV来表示。机会的EMV通常表示为正值，而威胁的EMV则表示为负值。EMV是建立在风险中立的假设之上的，既不避险，也不冒险。因此，在审核一个项目时，经常会计算项目的EMV。</p>
<p>预期货币常和决策树一起使用，它是将特定情况下可能的风险造成的货币后果和发生概率相乘，此项目包含了风险和现金的考虑。正值表示机会，负值表示风险。每个可能结果的数值与发生机率相乘后相加，就可以计算出项目的EMV。</p>
<blockquote>
<p>质量成本（cost of quality）包括在产品生命周期中为预防不符合要求，为评估产品或服务是否符合要求，以及因未达到要求（返工），而发生的所有成本。</p>
</blockquote>
<p>一致性成本（cost of conformance），该成本是预防性的，在缺陷发生之前付出的，用于质量与要求或规范一致而付出的成本。</p>
<ul>
<li>预防成本</li>
<li>评估成本</li>
</ul>
<p>非一致性成本：<br>非一致性成本（cost of non-conformance），是由于质量与要求或者规范不一致而造成的成本。</p>
<ul>
<li>内部失败成本</li>
<li>外部失败成本</li>
</ul>
<blockquote>
<p>净现值(Net Present Value, NPV)</p>
</blockquote>
<p>净现值指未来资金(现金)流入(收入)现值与未来资金(现金)流出(支出)现值的差额。项目评估中净现值法的基本指标。未来的资金流入与资金流出均按预计折现率各个时期的现值系数换算为现值后，再确定其净现值。这种预计折现率是按企业的最低的投资收益率来确定的.是企业投资可以接受的最低界限。</p>
<blockquote>
<p>PERT （估算）？</p>
</blockquote>
<blockquote>
<p>投资回报率(ROI) 模二 162</p>
</blockquote>
<p>投资回报率（ROI）是指通过投资而应返回的价值，即企业从一项投资活动中得到的经济回报。它涵盖了企业的获利目标。利润和投入经营所必备的财产相关，因为管理人员必须通过投资和现有财产获得利润。投资可分为实业投资和金融投资两大类，人们平常所说的金融投资主要是指证券投资。</p>
<h2 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h2><h3 id="定性"><a href="#定性" class="headerlink" title="定性"></a>定性</h3><ul>
<li>概率和影响矩阵：威胁/机会、概率、影响值等。</li>
<li>风险数据质量评估：评估风险数据的质量、可靠性，是否有必要收集更好的数据。</li>
<li>风险分类：借助风险分解结构来构建风险分类。</li>
<li>风险登记册更新：包括概率、影响评估、优先级、风险分值、风险责任人、紧迫性、类别以及低优先级风险的观察清单或需要进一步分析的风险。</li>
</ul>
<h3 id="定量"><a href="#定量" class="headerlink" title="定量"></a>定量</h3><ul>
<li><p>敏感性分析</p>
</li>
<li><p>不确定性表现方式</p>
</li>
<li><p>决策树分析</p>
</li>
<li><p>成本风险模型</p>
</li>
</ul>
<blockquote>
<p>龙卷风图</p>
</blockquote>
<p>龙卷风图：是项目管理中用于在风险识别和定性分析之后，进行定量风险分析的技术—-敏感性分析技术中最常用的一种图表技术。</p>
<p>敏感性分析：敏感性分析有助于确定哪些风险对项目具有最大的潜在影响。它把所有其他不确定因素保持在基准值的条件下，考察项目的每项要素的不确定性对目标产生多大程度的影响。</p>
<h3 id="风险（威胁）应对策略"><a href="#风险（威胁）应对策略" class="headerlink" title="风险（威胁）应对策略"></a>风险（威胁）应对策略</h3><ul>
<li><p>上报：威胁超出项目范围，或提议的应对措施超出项目经理权限，应进行上报。</p>
</li>
<li><p>减轻：采取措施降低威胁发生的概率/影响。降低概率如：多次测试、原型法、可靠的卖方等；降低影响如：冗余部件、备胎等。</p>
</li>
<li><p>回避（规避）：适用于发生概率较高，且具有严重负面影响的高优先级威胁。改变计划或目标，彻底消除威胁，将它的发生概率降低到零。</p>
</li>
<li><p>转移：将应对威胁的责任转移给第三方，让第三方管理风险并承担威胁发生的影响。向承担威胁的一方支付风险转移费用。（例如：保险、履约保函、担保书、保证书、合同等）</p>
</li>
<li><p>接受：主动和被动。主动接受是建立应急储备，包括预留时间、资金或资源；被动接受只是定期对威胁进行审查，确保未发生重大改变。</p>
</li>
</ul>
<h3 id="机会应对策略"><a href="#机会应对策略" class="headerlink" title="机会应对策略"></a>机会应对策略</h3><ul>
<li>上报：机会不在项目范围内，或提议的应对措施超出了项目经理权限，应进行上报。</li>
<li>开拓：将特定机会出现的概率提高到 100%，确保肯定出现。</li>
<li>分享：将应对机会的责任转移给第三方，使其享有机会所带来的部分收益。（合伙、合作团队、合资企业等）</li>
<li>提高：可以提高机会出现的概率或决定潜在因素提高发生的影响。</li>
<li>接受：承认机会存在，但不主动采取措施。主动策略是建立应急储备，以便在机会出现时加以利用；被动策略只是定期对机会进行审查，确保未发生重大改变。</li>
</ul>
<h3 id="应对"><a href="#应对" class="headerlink" title="应对"></a>应对</h3><blockquote>
<p>权变措施</p>
</blockquote>
<p>权变措施是未经计划的应对措施，不利的风险发生时来不及进行计划分析工作，只能根据当时的情况马上采取措施。用于应对先前未识别出的新风险，或者被动接受的风险，在风险发生之前不采取任何措施。 变更请求包括：纠正措施、预防措施、缺陷补救 纠正措施：推荐的纠正措施包括应急计划和权变措施。是整体变更控制过程的依据之一。应急计划：接受项目风险的一种做法，事先计划好当接受的风险发生时，应该采取的具体步骤，例如制定备用的活动顺序。需要建立一定的应急储备，用于应对已知风险和已知—未知型风险，应急计划中同时规定风险触发因素，即出现何种征兆时执行应急计划。</p>
<p>风险审查会</p>
<ul>
<li>识别新的单个风险</li>
<li>重新评估当前风险</li>
<li>关闭已过时的风险</li>
</ul>
<p>风险审计是针对过程(HOW)的，审查是针对具体的风险(WHAT)。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><blockquote>
<p>团队建设阶段？</p>
</blockquote>
<ul>
<li>形成</li>
<li>震荡</li>
<li>规范 </li>
<li>成熟</li>
<li>解散</li>
</ul>
<h2 id="相关方"><a href="#相关方" class="headerlink" title="相关方"></a>相关方</h2><p>权利利益方格</p>
<p>相关方参与计划 ？</p>
<h2 id="沟通"><a href="#沟通" class="headerlink" title="沟通"></a>沟通</h2><h3 id="冲突管理"><a href="#冲突管理" class="headerlink" title="冲突管理"></a>冲突管理</h3><ul>
<li><p>撤退/回避：从实际或潜在冲突中退出，将问题推迟到准备充分的时候，或者将问题推给其他人员解决。</p>
</li>
<li><p>缓和/包容：强调一致而非差异；为维持和谐与关系而退让一步，考虑其他方的需要。 </p>
<p>（缓和(包容)是指强调冲突双方的共同点，同时回避冲突双方的差异点。例如，对于某个岛屿的主权归属争议，采用“搁置争议、共同开发”的方法。例如，项目经理要求两位团队成员为共同完成任务而不在意双方之间的私人矛盾。缓和(包容)是双赢的方法，双方都能得到一定的利益。但是，缓和(包容)只是部分地解决了冲突，被回避掉的差异仍然是客观存在的。）</p>
</li>
<li><p>妥协/调解：为了暂时或部分解决冲突，寻找能让各方都在一定程度上满意的方案，但这种方法有时会导致”双输“的局面。</p>
<p>（妥协(调解)是指一方主动让步，或双方主动各让一步，来达成永久或暂时解决冲突的协议。仅从双方都各让一步这一点来讲，妥协(调解)是一种双输的方法。注意：双输的方法不一定就是不好的方法。妥协(调解)其实是仅次于合作(解决问题)的、有效的冲突解决方法。对于陷入冲突的人来讲，妥协其实是一种能力。在非原则问题上，该妥协时就一定要妥协。妥协并非弱者的表现，而是强者的表现。只有强者才善于、敢于做出必要的妥协。妥协中的“让步”是主动让步，而不是被迫让步。）</p>
</li>
<li><p>强迫/命令：以牺牲其他方为代价，推行某一方的观点；只提供赢-输方案。通常是利用权力来强行解决紧急问题，这种方法通常会导致”赢输“局面。</p>
</li>
<li><p>合作/解决问题：综合考虑不同的观点和意见，采用合作的态度和开放式对话引导各方达成共识和承诺，这种方法可以带来双赢局面。</p>
</li>
</ul>
<p>问题</p>
<p>模 6-118</p>
<p>124</p>
<p>130</p>
<p>180</p>
]]></content>
  </entry>
  <entry>
    <title>The Things Network 笔记</title>
    <url>/2021/06/09/iot-thethingsnetwork-notes/</url>
    <content><![CDATA[<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><blockquote>
<p>Community</p>
</blockquote>
<h3 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## </span><br><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;TheThingsNetwork&#x2F;lorawan-stack.git</span><br><span class="line"></span><br><span class="line">## install</span><br><span class="line">https:&#x2F;&#x2F;www.thethingsindustries.com&#x2F;docs&#x2F;getting-started&#x2F;installation&#x2F;</span><br></pre></td></tr></table></figure>
<h3 id="Certificates"><a href="#Certificates" class="headerlink" title="Certificates"></a>Certificates</h3><h4 id="ca-json"><a href="#ca-json" class="headerlink" title="ca.json"></a>ca.json</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;names&quot;</span>: [</span><br><span class="line">    &#123;<span class="attr">&quot;C&quot;</span>: <span class="string">&quot;NL&quot;</span>, <span class="attr">&quot;ST&quot;</span>: <span class="string">&quot;Noord-Holland&quot;</span>, <span class="attr">&quot;L&quot;</span>: <span class="string">&quot;Amsterdam&quot;</span>, <span class="attr">&quot;O&quot;</span>: <span class="string">&quot;The Things Demo&quot;</span>&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Generate:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cfssl genkey -initca ca.json | cfssljson -bare ca</span><br></pre></td></tr></table></figure>
<h4 id="cert-json"><a href="#cert-json" class="headerlink" title="cert.json"></a>cert.json</h4><blockquote>
<p>change host</p>
</blockquote>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;hosts&quot;</span>: [<span class="string">&quot;thethings.example.com&quot;</span>],</span><br><span class="line">  <span class="attr">&quot;names&quot;</span>: [</span><br><span class="line">    &#123;<span class="attr">&quot;C&quot;</span>: <span class="string">&quot;NL&quot;</span>, <span class="attr">&quot;ST&quot;</span>: <span class="string">&quot;Noord-Holland&quot;</span>, <span class="attr">&quot;L&quot;</span>: <span class="string">&quot;Amsterdam&quot;</span>, <span class="attr">&quot;O&quot;</span>: <span class="string">&quot;The Things Demo&quot;</span>&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Generate:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cfssl gencert -ca ca.pem -ca-key ca-key.pem cert.json | cfssljson -bare cert</span><br></pre></td></tr></table></figure>


<h4 id="Configuration-Cert"><a href="#Configuration-Cert" class="headerlink" title="Configuration Cert"></a>Configuration Cert</h4><ul>
<li>docker-compose.yml</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    # If using custom certificates:</span><br><span class="line">    secrets:</span><br><span class="line">      - ca.pem</span><br><span class="line">      - cert.pem</span><br><span class="line">      - key.pem</span><br><span class="line"></span><br><span class="line"># If using custom certificates:</span><br><span class="line">secrets:</span><br><span class="line">  ca.pem:</span><br><span class="line">    file: .&#x2F;ca.pem</span><br><span class="line">  cert.pem:</span><br><span class="line">    file: .&#x2F;cert.pem</span><br><span class="line">  key.pem:</span><br><span class="line">    file: .&#x2F;key.pem</span><br></pre></td></tr></table></figure>
<ul>
<li>ttn-lw-stack-docker.yml</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># If using custom certificates:</span><br><span class="line">tls:</span><br><span class="line">  source: file</span><br><span class="line">  root-ca: &#x2F;run&#x2F;secrets&#x2F;ca.pem</span><br><span class="line">  certificate: &#x2F;run&#x2F;secrets&#x2F;cert.pem</span><br><span class="line">  key: &#x2F;run&#x2F;secrets&#x2F;key.pem</span><br><span class="line"></span><br><span class="line"># Let&#39;s encrypt for &quot;thethings.example.com&quot;</span><br><span class="line"># tls:</span><br><span class="line">#   source: &#39;acme&#39;</span><br><span class="line">#   acme:</span><br><span class="line">#     dir: &#39;&#x2F;var&#x2F;lib&#x2F;acme&#39;</span><br><span class="line">#     email: &#39;you@thethings.example.com&#39;</span><br><span class="line">#     hosts: [&#39;thethings.example.com&#39;]</span><br><span class="line">#     default-host: &#39;thethings.example.com&#39;</span><br></pre></td></tr></table></figure>




<h3 id="Up"><a href="#Up" class="headerlink" title="Up"></a>Up</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker-compose pull</span><br><span class="line">docker-compose run --rm stack is-db init</span><br><span class="line">docker-compose run --rm stack is-db create-admin-user --id admin --email your@email.com</span><br><span class="line"></span><br><span class="line">docker-compose run --rm stack is-db create-oauth-client \</span><br><span class="line">  --id cli \</span><br><span class="line">  --name &quot;Command Line Interface&quot; \</span><br><span class="line">  --owner admin \</span><br><span class="line">  --no-secret \</span><br><span class="line">  --redirect-uri &quot;local-callback&quot; \</span><br><span class="line">  --redirect-uri &quot;code&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># see config&#x2F;stack&#x2F;ttn-lw-stack-docker.yml</span><br><span class="line">CONSOLE_SECRET&#x3D;&quot;console&quot;</span><br><span class="line">SERVER_ADDRESS&#x3D;&quot;dev:1885&quot;</span><br><span class="line"></span><br><span class="line">docker-compose run --rm stack is-db create-oauth-client \</span><br><span class="line">  --id console \</span><br><span class="line">  --name &quot;Console&quot; \</span><br><span class="line">  --owner admin \</span><br><span class="line">  --secret &quot;$&#123;CONSOLE_SECRET&#125;&quot; \</span><br><span class="line">  --redirect-uri &quot;$&#123;SERVER_ADDRESS&#125;&#x2F;console&#x2F;oauth&#x2F;callback&quot; \</span><br><span class="line">  --redirect-uri &quot;&#x2F;console&#x2F;oauth&#x2F;callback&quot; \</span><br><span class="line">  --logout-redirect-uri &quot;$&#123;SERVER_ADDRESS&#125;&#x2F;console&quot; \</span><br><span class="line">  --logout-redirect-uri &quot;&#x2F;console&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="Override"><a href="#Override" class="headerlink" title="Override"></a>Override</h2><p>Things Stack 是一个实现 LoRaWAN 协议的网络服务器。</p>
<h3 id="什么是-Things-Stack"><a href="#什么是-Things-Stack" class="headerlink" title="什么是 Things Stack?"></a>什么是 Things Stack?</h3><p>The Things Stack是企业级的 LoRaWAN 网络服务器，建立在<a href="https://github.com/TheThingsNetwork/lorawan-stack">开源核心</a>之上。Things Stack允许您在自己的硬件或云上构建和管理 LoRaWAN 网络。</p>
<ul>
<li><p>TTS 是 The Things Stack, LoRaWAN Network Server Stack。Things Stack 目前是网络服务器实现的版本3，因此也被非正式地称为V3。</p>
</li>
<li><p>TTN 是 “物联网”(The Things Network)，它是一个全球协同物联网生态系统，使用 LoRaWAN 创建网络、设备和解决方案。The Things Network 运行着 The Things Stack Community Edition，这是一个众包、开放和去中心化的 LoRaWAN 网络。这个网络是一个很好的开始测试设备、应用程序和集成，并熟悉 LoRaWAN 的方法。</p>
</li>
<li><p>TTI 是 The Things Industries:该公司主要负责The Things Stack 的开发和文档编写。Things Industries 还提供具有额外企业功能的云托管和本地私有 LoRaWAN 网络，以及针对企业客户的高级支持计划。</p>
</li>
</ul>
<h2 id="Command-Line-Interface"><a href="#Command-Line-Interface" class="headerlink" title="Command-Line Interface"></a>Command-Line Interface</h2><p>…</p>
<h2 id="Console"><a href="#Console" class="headerlink" title="Console"></a>Console</h2><p>控制台是 LoRaWAN 的 Things Stack 的管理应用程序。它是一个 Web 应用程序，可以用来注册应用程序，终端设备或网关，监控网络流量，或配置网络相关选项等。</p>
<h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="Gateway-Server-MQTT"><a href="#Gateway-Server-MQTT" class="headerlink" title="Gateway Server MQTT"></a>Gateway Server MQTT</h3><p>MQTT 协议可用于开发自定义包转发器或网关桥接器，用于在网关和 The Things Stack 之间交换流量，或用于测试目的，方便地模拟网关流量。它是一个替代 Basic Station 和 Semtech UDP协议。</p>
<p>MQTT 是用于交换消息的服务器-客户机协议。客户端可以连接到服务器并发布特定主题下的消息(数据)。它们还可以订阅一个主题，从而接收在该主题下发布的所有消息(由其他客户机或MQTT服务器本身发布)。</p>
<p>网关服务器是 MQTT 服务器，网关作为 MQTT 客户端连接到网关服务器。连接的网关由用于身份验证的用户名标识。</p>
<h4 id="Protocol-Buffers"><a href="#Protocol-Buffers" class="headerlink" title="Protocol Buffers"></a>Protocol Buffers</h4><p>为了与 MQTT 协议通信，网关服务器和网关正在交换 Protocol Buffers。<a href="https://github.com/TheThingsNetwork/lorawan-stack/blob/v3.13/api/lorawan.proto">https://github.com/TheThingsNetwork/lorawan-stack/blob/v3.13/api/lorawan.proto</a></p>
<h4 id="Connecting-to-the-Gateway-Server"><a href="#Connecting-to-the-Gateway-Server" class="headerlink" title="Connecting to the Gateway Server"></a>Connecting to the Gateway Server</h4><p>通过身份验证的客户端可以只写访问以下主题：</p>
<ul>
<li>v3/&lt; Gateway -id&gt;@<tenant-id>/up:用于向网关服务器发送上行流量。</li>
<li>v3/<gateway-id>@<tenant-id>/status:向网关服务器发送网关状态消息。</li>
<li>v3/&lt; Gateway -id&gt;@<tenant-id>/down/ack:用于向网关服务器发送TxAck消息。</li>
</ul>
<p>客户端也获得只读访问，并应该订阅以下主题:</p>
<ul>
<li>v3/&lt; Gateway -id&gt;@<tenant-id>/down:网关服务器发布网关应该发送的下行消息。</li>
</ul>
<h4 id="Uplink-Messages"><a href="#Uplink-Messages" class="headerlink" title="Uplink Messages"></a>Uplink Messages</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ export GATEWAY_ID&#x3D;&quot;test-gtw@my-tenant&quot;</span><br><span class="line">$ export GATEWAY_API_KEY&#x3D;&quot;NNSXS.VEEBURF3KR77ZR...&quot; # API key with RIGHT_GATEWAY_LINK rights</span><br><span class="line">$ mosquitto_pub \</span><br><span class="line">    -h &quot;thethings.example.com&quot; -p 1882 \</span><br><span class="line">    -u &quot;$GATEWAY_ID&quot; -P &quot;$GATEWAY_API_KEY&quot; \</span><br><span class="line">    -t &quot;v3&#x2F;$GATEWAY_ID&#x2F;up&quot; -f test-uplink-message</span><br></pre></td></tr></table></figure>
<h4 id="Downlink-Messages"><a href="#Downlink-Messages" class="headerlink" title="Downlink Messages"></a>Downlink Messages</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ export GATEWAY_ID&#x3D;&quot;test-gtw@my-tenant&quot;</span><br><span class="line">$ export GATEWAY_API_KEY&#x3D;&quot;NNSXS.VEEBURF3KR77ZR...&quot; # API key with RIGHT_GATEWAY_LINK rights</span><br><span class="line">$ mosquitto_sub \</span><br><span class="line">    -h &quot;thethings.example.com&quot; -p 1882 \</span><br><span class="line">    -u &quot;$GATEWAY_ID&quot; -P &quot;$GATEWAY_API_KEY&quot; \</span><br><span class="line">    -t &quot;v3&#x2F;$GATEWAY_ID&#x2F;down&quot; -v</span><br></pre></td></tr></table></figure>
<h4 id="Gateway-Status-Messages"><a href="#Gateway-Status-Messages" class="headerlink" title="Gateway Status Messages"></a>Gateway Status Messages</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ export GATEWAY_ID&#x3D;&quot;test-gtw@my-tenant&quot;</span><br><span class="line">$ export GATEWAY_API_KEY&#x3D;&quot;NNSXS.VEEBURF3KR77ZR...&quot; # API key with RIGHT_GATEWAY_LINK rights</span><br><span class="line">$ mosquitto_pub \</span><br><span class="line">    -h &quot;thethings.example.com&quot; -p 1882 \</span><br><span class="line">    -u &quot;$GATEWAY_ID&quot; -P &quot;$GATEWAY_API_KEY&quot; \</span><br><span class="line">    -t &quot;v3&#x2F;$GATEWAY_ID&#x2F;status&quot; -f test-gateway-status</span><br></pre></td></tr></table></figure>
<h4 id="TxAck-Messages"><a href="#TxAck-Messages" class="headerlink" title="TxAck Messages"></a>TxAck Messages</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ export GATEWAY_ID&#x3D;&quot;test-gtw@my-tenant&quot;</span><br><span class="line">$ export GATEWAY_API_KEY&#x3D;&quot;NNSXS.VEEBURF3KR77ZR...&quot; # API key with RIGHT_GATEWAY_LINK rights</span><br><span class="line">$ mosquitto_pub \</span><br><span class="line">    -h &quot;thethings.example.com&quot; -p 1882 \</span><br><span class="line">    -u &quot;$GATEWAY_ID&quot; -P &quot;$GATEWAY_API_KEY&quot; \</span><br><span class="line">    -t &quot;v3&#x2F;$GATEWAY_ID&#x2F;down&#x2F;ack&quot; -f example-tx-ack</span><br></pre></td></tr></table></figure>


<h2 id="Working-with-Events"><a href="#Working-with-Events" class="headerlink" title="Working with Events"></a>Working with Events</h2><p>Things Stack 生成大量的事件，让你能够洞察正在发生的事情。可以订阅应用程序、网关、终端设备事件，以及用户、组织和 OAuth 客户端事件。</p>
<h3 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ttn-lw-cli events subscribe --gateway-id gtw1 --application-id app1</span><br></pre></td></tr></table></figure>


<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># create api key token</span><br><span class="line">ttn-lw-cli users api-key create \</span><br><span class="line">  --user-id admin \</span><br><span class="line">  --right-application-all \</span><br><span class="line">  --right-gateway-all</span><br><span class="line"></span><br><span class="line"># subscribe stream</span><br><span class="line">curl https:&#x2F;&#x2F;thethings.example.com&#x2F;api&#x2F;v3&#x2F;events \</span><br><span class="line">  -X POST \</span><br><span class="line">  -H &quot;Authorization: Bearer NNSXS.BR55PTYILPPVXY..&quot; \</span><br><span class="line">  -H &quot;Accept: text&#x2F;event-stream&quot; \</span><br><span class="line">  --data &#39;&#123;&quot;identifiers&quot;:[&#123;&quot;application_ids&quot;:&#123;&quot;application_id&quot;:&quot;app1&quot;&#125;&#125;,&#123;&quot;gateway_ids&quot;:&#123;&quot;gateway_id&quot;:&quot;gtw1&quot;&#125;&#125;]&#125;&#39;</span><br></pre></td></tr></table></figure>


<h2 id="Components"><a href="#Components" class="headerlink" title="Components"></a>Components</h2><h3 id="Application-Server"><a href="#Application-Server" class="headerlink" title="Application Server"></a>Application Server</h3><p>Application Server 处理 LoRaWAN 应用层，包括上行数据的解密和解码、下行队列和下行数据的编码和加密。</p>
<p>它托管一个用于流媒体应用程序数据的MQTT服务器，支持HTTP webhook以及发布/订阅集成。</p>
<p>应用程序可以通过多种协议和机制连接到 Application Server。</p>
<ul>
<li>MQTT Protocol</li>
</ul>
<p>应用程序可以通过 MQTT 交换 JSON 消息来连接到应用服务器。MQTT 在 TLS 上可用，为应用程序和应用服务器之间交换的消息提供机密性。</p>
<p>上行消息不仅包含数据上行消息，而且还包含不同主题的 join-accept 和 downlink 事件。</p>
<ul>
<li>HTTP Webhooks</li>
</ul>
<p>应用程序可以通过 HTTP webhook 获取流 JSON 消息，并通过向应用服务器发出 HTTP 请求来调度下行消息。</p>
<p>与 MQTT 一样，可以配置所有上游消息，包括上行消息、加入接收事件和下行事件，每个都用于分隔 URL 路径。</p>
<ul>
<li>Pub/Sub Integrations</li>
</ul>
<p>应用程序还可以使用发布/订阅集成来处理流数据。这包括连接到外部 MQTT 服务器和 NATS 服务器。</p>
<ul>
<li>Message Processing</li>
</ul>
<p>Application Server 可以解码和编码由终端设备发送和接收的二进制有效负载。这允许使用结构化流数据，例如使用 MQTT 和 HTTP Webhook 的JSON对象，同时使用通过无线电传输的压缩二进制数据。</p>
<p>消息处理器可以是众所周知的格式或自定义脚本，可以在设备级别或针对整个应用程序进行设置。</p>
<h3 id="Network-Server"><a href="#Network-Server" class="headerlink" title="Network Server"></a>Network Server</h3><p>Network Server 负责处理 LoRaWAN 网络层，包括 MAC命令、区域参数和自适应数据速率(ADR)。</p>
<h4 id="Device-Management"><a href="#Device-Management" class="headerlink" title="Device Management"></a>Device Management</h4><p> 网络服务器为终端设备(End-Device)管理公开了 NsEndDeviceRegistry 服务。该服务的典型客户端有 Console 和 CLI。</p>
<p>网络服务器存储设备 MAC 配置、MAC状态 和网络会话密钥。</p>
<p>设备MAC配置变化可能会触发下行报文。</p>
<h4 id="Application-Downlink-Queue-Management-and-Linking"><a href="#Application-Downlink-Queue-Management-and-Linking" class="headerlink" title="Application Downlink Queue Management and Linking"></a>Application Downlink Queue Management and Linking</h4><p>网络服务器允许应用服务器推送、替换和列出应用下行链路，以及通过 gRPC API 链接应用。</p>
<p>改变应用程序下行队列可能会触发下行消息。</p>
<p>一旦链接建立，Network Server 将通过该链接向客户端发送特定于应用程序的上行消息。每个应用程序最多只能有一个活动链接。</p>
<p>如果链接不是活动的，但是 Network Server 有特定于应用程序的上行消息要发送，这些消息将在链接建立后排队并发送。</p>
<h4 id="Downlink-Scheduling"><a href="#Downlink-Scheduling" class="headerlink" title="Downlink Scheduling"></a>Downlink Scheduling</h4><p>网络服务器维护内部下行任务队列。每个下行任务都有一个与之相关的执行时间，这些任务按升序排列。每当下行任务准备执行时，它就会尽快执行。</p>
<h5 id="Join-accept"><a href="#Join-accept" class="headerlink" title="Join-accept"></a>Join-accept</h5><p>如果存在一个挂起的会话，并且为该设备排队加入join-accept，它将被调度。</p>
<h5 id="Data-downlink"><a href="#Data-downlink" class="headerlink" title="Data downlink"></a>Data downlink</h5><p>如果一个挂起的会话不存在或已经发送了 Join-accept, Network Server 将尝试在活动会话中生成并调度数据下行。</p>
<h4 id="Uplink-Handing"><a href="#Uplink-Handing" class="headerlink" title="Uplink Handing"></a>Uplink Handing</h4><p>网络服务器通过 gRPC 从网关服务器接收上行链路。</p>
<p>网络服务器对接收到的上行链路进行处理。第一步是将上行链路与设备匹配。如果上行链路不能与网络服务器中存储的设备匹配，则丢弃上行链路。</p>
<h5 id="Join-Request"><a href="#Join-Request" class="headerlink" title="Join-Request"></a>Join-Request</h5><p>如果收到 Join-request:</p>
<ol>
<li>设备使用连接请求中出现的 DevEUI和 JoinEUI 对进行匹配，这是唯一标识设备的。</li>
<li>新的 <code>DevAddr</code> 被分配给设备，新的 MAC 状态被派生出来。</li>
<li>如果集群中存在 Join Server, Network Server 将向集群本地 Join Server 发送一个Join请求消息。</li>
<li>如果集群中不存在 Join Server，或者设备没有在集群本地 Join Server 中提供，网络服务器将向通过互操作性配置发现的 Join Server 发送一个 Join 请求消息。</li>
<li>如果一个 Join Server 接受了Join-request，设备可能会排队接收 Join-accept 消息，并向链接的 Application Server 发送特定于应用程序的上行消息，这些上行消息携带有关Join-accept 的信息。</li>
</ol>
<h5 id="Data-Uplink"><a href="#Data-Uplink" class="headerlink" title="Data Uplink"></a>Data Uplink</h5><p>如果收到数据上行：</p>
<ol>
<li>使用数据上行链路中存在的 DevAddr 匹配设备。通过比较会话上下文和 MAC 状态进行匹配，并进行 MIC 检查。由于多个设备可能具有相同的 DevAddr，网络服务器在匹配设备之前可能需要通过多个存储设备。</li>
<li>网络服务器处理 MAC 命令，如果这样的命令存在于帧中，并相应地更新 MAC 状态。</li>
<li>如果数据上行配置了ADR 位，Network Server 运行 ADR 算法，更新 MAC 状态。</li>
<li>如果数据上行链路处理成功，下行链路可能会为设备排队，一个或多个特定于应用程序的上行消息携带有关 Join-accept 的相关信息被发送到链接的应用服务器。</li>
</ol>
<h3 id="Identity-Server"><a href="#Identity-Server" class="headerlink" title="Identity Server"></a>Identity Server</h3><p>身份服务器提供了存储实体(如应用程序及其终端设备、网关、用户、组织、OAuth客户端和身份验证提供者)的注册中心。它还通过成员关系和API键管理访问控制。</p>
<h4 id="Entity-Registries"><a href="#Entity-Registries" class="headerlink" title="Entity Registries"></a>Entity Registries</h4><p>实体注册中心存储关于 Things Stack 中所有主要实体的公共信息。这包括名称、描述和属性(用户定义的键值对)。</p>
<h5 id="Users"><a href="#Users" class="headerlink" title="Users"></a>Users</h5><p>在 Identity Server 中注册的第一个实体通常是管理用户。用户可以通过提供电子邮件地址并选择用户ID和密码进行注册。这些信息以后可以用于登录。</p>
<p>用户ID是用户的唯一标识符。用户 ID 与组织 ID 在同一个命名空间中。这意味着不可能创建与现有组织具有相同ID的用户。出于安全原因，也不可能重用已删除用户或组织的ID。</p>
<p>用户可以是“admin”，这给了他们更高的权限。正常的注册过程不允许用户注册为 admin，这就是为什么入门指南使用不同的命令创建admin用户。</p>
<p>用户可以处于多个状态之一：请求、批准、拒绝、挂起等。用户的状态决定了用户是否能够执行操作，以及哪些操作。正常情况下，用户处于“批准”状态。如果 The Things Stack 被配置为需要新用户的管理批准，那么用户最初处于“请求”状态，管理用户可以将其更新为“批准”或“拒绝”状态。如果用户行为不当，也可能被管理员挂起。</p>
<h5 id="Gateways"><a href="#Gateways" class="headerlink" title="Gateways"></a>Gateways</h5><p>网关可以通过选择一个ID和可选地注册网关的EUI来注册。注册后，可以创建一个API密钥；网关可以使用它的ID(或EUI)和API密钥一起使用 The Things Stack 进行身份验证。</p>
<p>为了保证网关的正常运行，需要设置频率规划ID，并设置网关是否需要满足占空比。</p>
<p>如果网关能够与网关配置服务器通信，则可以在网关注册表中设置网关服务器地址和固件更新设置。</p>
<p>网关注册表还存储有关网关天线的信息，如位置和增益。</p>
<h5 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h5><p>应用程序用于在一个地方组织多个终端设备的注册和流量。应用程序通常对应于处于相同部署或相同类型的终端设备集合。</p>
<h5 id="End-Devices"><a href="#End-Devices" class="headerlink" title="End Devices"></a>End Devices</h5><p>Identity Server 中的终端设备注册表只存储终端设备的元数据，允许  Console 和 CLI 等客户端在应用程序中列出终端设备。它通常存储有关终端设备的品牌、模型、硬件、固件和位置的元数据。它还存储了 Network Server、Application Server 和Join Server的地址，以便 Console 和 CLI 等客户机知道存储终端设备的其他属性的位置。</p>
<h5 id="Organizations"><a href="#Organizations" class="headerlink" title="Organizations"></a>Organizations</h5><p>组织用于创建多个用户组，并方便地为整个用户组分配权限。</p>
<p>组织ID是组织的唯一标识符。组织id与用户id在相同的命名空间中。这意味着不可能创建具有与现有用户相同ID的组织。出于安全原因，也不可能重用已删除用户或组织的ID。</p>
<h5 id="OAuth-Clients"><a href="#OAuth-Clients" class="headerlink" title="OAuth Clients"></a>OAuth Clients</h5><p>可以在 OAuth 注册表中注册外部 OAuth 客户端。OAuth 客户端使用客户端ID和秘密进行注册。</p>
<p>与用户一样，OAuth客户机可以处于多种状态中的一种。非admin用户创建的OAuth客户端需要admin用户审批。</p>
<p>官方的OAuth客户端可以被标记为“背书”，或者可以为所有用户预先授权。</p>
<h5 id="Authentication-Providers"><a href="#Authentication-Providers" class="headerlink" title="Authentication Providers"></a>Authentication Providers</h5><p>联邦身份验证提供者可以在身份验证提供者注册中心中注册。身份验证提供者使用ID、名称和提供者配置注册。</p>
<p>身份验证提供者用于允许 Identity Server 从外部身份提供者(如OpenID Connect提供者)获得用户的身份。</p>
<h4 id="Entity-Access"><a href="#Entity-Access" class="headerlink" title="Entity Access"></a>Entity Access</h4><p>标识服务器负责对实体的访问控制。</p>
<h5 id="Memberships"><a href="#Memberships" class="headerlink" title="Memberships"></a>Memberships</h5><p>成员资格定义了用户或组织对另一个实体拥有的权利。最简单的成员关系是用户是应用程序或网关的直接成员(或合作者)。成员资格的权限表明允许用户对应用程序或网关做什么。</p>
<p>间接成员关系是指用户是某个组织的成员，而该组织是某个应用程序或网关的成员。在这种情况下，用户-组织成员关系的权限与组织-应用或组织-网关成员关系的权限相交，计算出该用户的有效权限。</p>
<h5 id="API-Keys"><a href="#API-Keys" class="headerlink" title="API Keys"></a>API Keys</h5><p>对于大多数实体，都可以创建API Keys。这些 API Keys 允许您代表实体调用 API。API 密钥不会过期，但是可以撤销 API 密钥。</p>
<p>API键具有相关联的权限。这意味着可以创建一个应用程序API密钥，该密钥可以用来读取有关终端设备的信息，但不能看到根密钥，也不能进行更改。</p>
<p>可以合并成员资格和API密钥，例如，您可以创建一个组织API密钥，该密钥具有列出组织成员所在的应用程序的权利，以及读取这些应用程序中终端设备信息的权利。</p>
<h4 id="OAuth"><a href="#OAuth" class="headerlink" title="OAuth"></a>OAuth</h4><p>Identity Server 是 OAuth 2.0 服务器。用户可以授权 OAuth 客户机访问他们的数据、管理授权，甚至管理单个访问令牌。</p>
<h3 id="Join-Server"><a href="#Join-Server" class="headerlink" title="Join Server"></a>Join Server</h3><p>连接服务器处理 LoRaWAN 连接流，包括网络和应用服务器身份验证和会话密钥生成。</p>
<h4 id="Join-Procedure"><a href="#Join-Procedure" class="headerlink" title="Join Procedure"></a>Join Procedure</h4><p>连接服务器通过 gRPC 接收来自网络服务器的加入请求，如果加入请求验证通过，则为注册设备发出加入接收。</p>
<p>如果接受了一个连接请求，Join Server将派生会话安全上下文，该上下文包含会话密钥，并由会话密钥 ID 标识。使用分别在网络服务器和应用服务器之间共享的密钥加密密钥(KEKs)， Join Servers 加密派生的网络和应用程序会话密钥，并将会话密钥以加密的形式包含在 Join-accept 中。</p>
<h4 id="Device-Management-1"><a href="#Device-Management-1" class="headerlink" title="Device Management"></a>Device Management</h4><p>Join Servers 公开JsEndDeviceRegistry 服务用于终端设备管理。该服务的典型客户端有 Console 和 CLI。</p>
<p>Join Servers 存储设备根和会话密钥。</p>
<h4 id="Session-Key-Retrieval"><a href="#Session-Key-Retrieval" class="headerlink" title="Session Key Retrieval"></a>Session Key Retrieval</h4><p>Join Servers 公开 rpc 以检索给定会话密钥ID的会话密钥。</p>
<h4 id="Interoperability"><a href="#Interoperability" class="headerlink" title="Interoperability"></a>Interoperability</h4><p>Join Servers 公开了LoRaWAN后端接口 1.0 规范中定义的 AS-JS、vNS-JS 和 hNS-JS 服务。</p>
<h3 id="Gateway-Server"><a href="#Gateway-Server" class="headerlink" title="Gateway Server"></a>Gateway Server</h3><p>网关服务器维护与支持基站、UDP、MQTT 和 gRPC 协议的网关的连接。上行流量直接或间接转发给网络服务器，下行流量由网关调度。</p>
<h4 id="Connective"><a href="#Connective" class="headerlink" title="Connective"></a>Connective</h4><p>网关可以通过多种协议连接到网关服务器。</p>
<ul>
<li>Basic Station Protocol</li>
</ul>
<p>网关可以通过基站 LNS 协议与网关服务器连接。建议使用此协议连接网关。</p>
<ul>
<li>UDP Protocol</li>
</ul>
<p>网关可以通过 UDP 协议连接到网关服务器。与每条消息一起发送的 EUI 用于标识网关。</p>
<p>如果在标识服务器中找到具有此 EUI 的网关，则消息与此网关相关。否则，根据网络配置，上行链路可能被路由或丢弃。但是，由于无法识别其区域参数，网络将不会向此网关发送下行链路。</p>
<p>旧版本的数据包转发器实现 UDP 协议没有实现任何排队系统下行链路，导致数据包丢失，因为 SX130x 集中器不缓冲多个下行链路。因此，对于 UDP 协议，Things Stack 实现了向下发送到网关的延迟，这意味着它们将由集中器发出。您可以每个网关单独禁用此功能，例如，如果网关和网关服务器之间的RTT过高。</p>
<ul>
<li>MQTT Protocol</li>
</ul>
<p>网关可以通过 MQTT 交换 Protocol Buffer 连接到网关服务器。MQTT 可在TLS上使用，提供网关和网络之间交换的消息的机密性。与使用 JSON 编码的 UDP 协议相比，使用 Protocol Buffer 的编码减少了带宽的使用。技术细节请参见网关服务器MQTT协议。</p>
<p>实现 MQTT 协议的包转发器(Packet forwarders)特定于Things Stack。</p>
<h4 id="Gateway-Information"><a href="#Gateway-Information" class="headerlink" title="Gateway Information"></a>Gateway Information</h4><p>当连接网关时，网关服务器会统计与网关交换的消息以及网关发送的状态消息。这些统计数据可以通过网关服务器的gRPC和HTTP api来检索。看到Gs服务。</p>
<h4 id="Communication-with-Network-Server"><a href="#Communication-with-Network-Server" class="headerlink" title="Communication with Network Server"></a>Communication with Network Server</h4><p>网关服务器的主要功能是维护与网关的连接，并作为网关和网络服务器之间的中继。</p>
<h5 id="Uplink-Messages-1"><a href="#Uplink-Messages-1" class="headerlink" title="Uplink Messages"></a>Uplink Messages</h5><p>当网关服务器接收数据上行消息时，根据设备的 DevAddr 和配置的转发表决定发送到哪个 Network Server。连接请求被路由到所有已配置的端点。端点可以是集群的 gRPC 网络服务器，或者是中间流量路由机制。</p>
<h5 id="Downlink-Messages-1"><a href="#Downlink-Messages-1" class="headerlink" title="Downlink Messages"></a>Downlink Messages</h5><p>网络服务器可以请求下行消息的传输。网关服务器尝试基于所选网关、发送消息的时间和 LoRaWAN 设置(下行链路类、RX1延迟和RX1/RX2数据速率和频率)来调度消息。</p>
<p>网关服务器跟踪所有发送的和连接到它的网关将要发送的下行链路，包括基于消息大小和数据速率的准确广播时间。这使得 The Things Stack 能够进行智能调度。除了定时和 LoRaWAN 设置，网关服务器考虑到适用的限制，包括：</p>
<ul>
<li>调度冲突：如果一个下行链路的发送与另一个下行链路的发送重叠，则下行链路将被拒绝。</li>
<li>停飞时间：一些频带和频率计划有停飞时间限制，这意味着网关在发送下行链路后的一段时间内不能发射。</li>
<li>频宽比：一些国家，如欧洲国家，有频宽比限制，禁止一个设备在一定范围内排放超过一定百分比的时间。</li>
<li>停留时间：一些国家，如美国，受停留时间的规定，即传输的持续时间不能超过一定的限制。</li>
</ul>
<h2 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h2><h3 id="Port-Allocations"><a href="#Port-Allocations" class="headerlink" title="Port Allocations"></a>Port Allocations</h3><p>The following table lists the default ports used.</p>
<table>
<thead>
<tr>
<th><strong>Purpose</strong></th>
<th><strong>Protocol</strong></th>
<th><strong>Authentication</strong></th>
<th><strong>Port</strong></th>
<th><strong>Port (TLS)</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Gateway data</td>
<td><a href="https://github.com/Lora-net/packet_forwarder/blob/master/PROTOCOL.TXT">Semtech Packet Forwarder</a></td>
<td>None</td>
<td>1700 (UDP)</td>
<td>N/A</td>
</tr>
<tr>
<td>Gateway data</td>
<td>MQTT (V2)</td>
<td>API key, token</td>
<td>1881</td>
<td>8881</td>
</tr>
<tr>
<td>Gateway data</td>
<td>MQTT</td>
<td>API key, token</td>
<td>1882</td>
<td>8882</td>
</tr>
<tr>
<td>Application data, events</td>
<td>MQTT</td>
<td>API key, token</td>
<td>1883</td>
<td>8883</td>
</tr>
<tr>
<td>Management, data, events</td>
<td>gRPC</td>
<td>API key, token</td>
<td>1884</td>
<td>8884</td>
</tr>
<tr>
<td>Management</td>
<td>HTTP</td>
<td>API key, token</td>
<td>1885</td>
<td>8885</td>
</tr>
<tr>
<td>Backend Interfaces</td>
<td>HTTP</td>
<td>Custom</td>
<td>N/A</td>
<td>8886</td>
</tr>
<tr>
<td>LNS</td>
<td>Web Sockets</td>
<td>Auth Token, Custom</td>
<td>1887</td>
<td>8887</td>
</tr>
<tr>
<td>Tabs Hubs LNS</td>
<td>Web Sockets</td>
<td>Auth Token, Custom</td>
<td>1888</td>
<td>8888</td>
</tr>
</tbody></table>
<h3 id="Service-Discovery"><a href="#Service-Discovery" class="headerlink" title="Service Discovery"></a>Service Discovery</h3><p>The Things Stack supports discovering services using DNS SRV records. This is useful when dialing a cluster only by host name; the supported services and target host name and port are discovered using DNS.</p>
<p>To support service discovery for your The Things Stack cluster, configure DNS SRV records with the following services and protocols:</p>
<table>
<thead>
<tr>
<th><strong>Protocol</strong></th>
<th><strong>SRV Service</strong></th>
<th><strong>SRV Protocol</strong></th>
<th><strong>SRV Target</strong></th>
</tr>
</thead>
<tbody><tr>
<td>gRPC</td>
<td><code>ttn-v3-is-grpc</code></td>
<td><code>tcp</code></td>
<td>Identity Server</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-gs-grpc</code></td>
<td><code>tcp</code></td>
<td>Gateway Server</td>
</tr>
<tr>
<td>Semtech Packet Forwarder</td>
<td><code>ttn-v3-gs-udp</code></td>
<td><code>udp</code></td>
<td>Gateway Server</td>
</tr>
<tr>
<td>MQTT (V2)</td>
<td><code>ttn-v3-gs-mqttv2</code></td>
<td><code>tcp</code></td>
<td>Gateway Server</td>
</tr>
<tr>
<td>MQTT</td>
<td><code>ttn-v3-gs-mqtt</code></td>
<td><code>tcp</code></td>
<td>Gateway Server</td>
</tr>
<tr>
<td>Basic Station LNS</td>
<td><code>ttn-v3-gs-basicstationlns</code></td>
<td><code>tcp</code></td>
<td>Gateway Server</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-ns-grpc</code></td>
<td><code>tcp</code></td>
<td>Network Server</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-as-grpc</code></td>
<td><code>tcp</code></td>
<td>Application Server</td>
</tr>
<tr>
<td>MQTT</td>
<td><code>ttn-v3-as-mqtt</code></td>
<td><code>tcp</code></td>
<td>Application Server</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-js-grpc</code></td>
<td><code>tcp</code></td>
<td>Join Server</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-dtc-grpc</code></td>
<td><code>tcp</code></td>
<td>Device Template Converter</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-dcs-grpc</code></td>
<td><code>tcp</code></td>
<td>Device Claiming Server</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-gcs-grpc</code></td>
<td><code>tcp</code></td>
<td>Gateway Configuration Server</td>
</tr>
<tr>
<td>gRPC</td>
<td><code>ttn-v3-qrg-grpc</code></td>
<td><code>tcp</code></td>
<td>QR Code Generator</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>MQTT</tag>
        <tag>LoRa</tag>
        <tag>LoRaWAN</tag>
        <tag>Iot</tag>
        <tag>Network Server</tag>
        <tag>Application Server</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
</search>
